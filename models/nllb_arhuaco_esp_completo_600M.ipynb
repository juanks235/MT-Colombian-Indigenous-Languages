{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=0\n",
    "MODEL_USED=\"facebook/nllb-200-distilled-600M\"\n",
    "# MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_arhuaco_esp_completo_600m\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"arh_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"ayr_Latn\" # Central Aymara\n",
    "LANGUAGE_FILE=\"data/arh_completo.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"arh\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5785, 2)\n",
      "Index(['arh', 'esp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4628 entries, 339 to 860\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     4628 non-null   object\n",
      " 1   esp     4628 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 108.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Padán-arám ayekʉ pari ʉnnakʉn nu'kwe'ri, mazak...</td>\n",
       "      <td>Cuando yo regresaba de Parán Aram, se me murió...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>i'ngwi uga mowga kʉtow ʉnhakwʉya nariri, i'ngw...</td>\n",
       "      <td>éramos doce hermanos, hijos del mismo padre; u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>Awi krususe' asakayri: ʻEmari judíw zʉ rey gu...</td>\n",
       "      <td>—Si tú eres el rey de los judíos, sálvate a ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Ey uye' nʉngwari “posuri Sebá za'kinukʉngwa ni...</td>\n",
       "      <td>Isaac le puso el nombre de Sebá —es decir, «Ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>Ey ʉweri kʉtʉkʉnʉn ka'gʉmʉ a'bore pari profeta...</td>\n",
       "      <td>De este modo demuestran estar de acuerdo con l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "339   Padán-arám ayekʉ pari ʉnnakʉn nu'kwe'ri, mazak...   \n",
       "837   i'ngwi uga mowga kʉtow ʉnhakwʉya nariri, i'ngw...   \n",
       "4222  Awi krususe' asakayri: ʻEmari judíw zʉ rey gu...   \n",
       "387   Ey uye' nʉngwari “posuri Sebá za'kinukʉngwa ni...   \n",
       "4381  Ey ʉweri kʉtʉkʉnʉn ka'gʉmʉ a'bore pari profeta...   \n",
       "\n",
       "                                                    esp  \n",
       "339   Cuando yo regresaba de Parán Aram, se me murió...  \n",
       "837   éramos doce hermanos, hijos del mismo padre; u...  \n",
       "4222  —Si tú eres el rey de los judíos, sálvate a ti...  \n",
       "387   Isaac le puso el nombre de Sebá —es decir, «Ju...  \n",
       "4381  De este modo demuestran estar de acuerdo con l...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 578 entries, 2201 to 457\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     578 non-null    object\n",
      " 1   esp     577 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>Altarzey nari ga'kʉnamʉ mikʉnchunhʉnʉngwa ni y...</td>\n",
       "      <td>¡Ciegos! ¿Qué es más importante, la ofrenda o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>Awi nʉngwari winʉkʉriwiya ɉinari ɉiwʉ chukutar...</td>\n",
       "      <td>Cuando los discípulos llegaron a la otra orill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>Josese'ri: —“Máykʉnʉ kúkwʉri, máykʉnʉ ɉwía, za...</td>\n",
       "      <td>José le dijo:—Esta es la interpretación: los t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Iwa mari migwia ɉina gwasi umʉn me'kawiri ka'g...</td>\n",
       "      <td>Y a ti, te doy una franja de tierra mayor que ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>Jesuse'ri:—“Nʉpaw kinkiri chiwa powru Israeri ...</td>\n",
       "      <td>Jesús entonces dijo:—Dios me ha enviado solame...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "2201  Altarzey nari ga'kʉnamʉ mikʉnchunhʉnʉngwa ni y...   \n",
       "2225  Awi nʉngwari winʉkʉriwiya ɉinari ɉiwʉ chukutar...   \n",
       "1652  Josese'ri: —“Máykʉnʉ kúkwʉri, máykʉnʉ ɉwía, za...   \n",
       "354   Iwa mari migwia ɉina gwasi umʉn me'kawiri ka'g...   \n",
       "2518  Jesuse'ri:—“Nʉpaw kinkiri chiwa powru Israeri ...   \n",
       "\n",
       "                                                    esp  \n",
       "2201  ¡Ciegos! ¿Qué es más importante, la ofrenda o ...  \n",
       "2225  Cuando los discípulos llegaron a la otra orill...  \n",
       "1652  José le dijo:—Esta es la interpretación: los t...  \n",
       "354   Y a ti, te doy una franja de tierra mayor que ...  \n",
       "2518  Jesús entonces dijo:—Dios me ha enviado solame...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 579 entries, 3303 to 2299\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     579 non-null    object\n",
      " 1   esp     579 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>Uye'ki Jesuse' yow winʉkʉkariri: —“Ʉɉway ikʉ s...</td>\n",
       "      <td>Entonces Jesús los reunió y les dijo:—Como muy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>á ka'mʉkanʉya ɉinari: —“Eymari Juan Bautista e...</td>\n",
       "      <td>y comentó con sus cortesanos:—Este es Juan el ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>Ey uye' nʉngwa reyri i'ngweygwi gunamʉ winga's...</td>\n",
       "      <td>Volvió a enviarles más criados, con este encar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>Ʉwe'ki miwiri, inʉ achwʉn, awiri ey kʉno'kwʉn ...</td>\n",
       "      <td>En cuanto a ustedes, felices sus ojos por lo q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Ka'se' inu a'chuiakumuyeykazey nari,jwi anni'k...</td>\n",
       "      <td>regalias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "3303  Uye'ki Jesuse' yow winʉkʉkariri: —“Ʉɉway ikʉ s...   \n",
       "2715  á ka'mʉkanʉya ɉinari: —“Eymari Juan Bautista e...   \n",
       "1897  Ey uye' nʉngwa reyri i'ngweygwi gunamʉ winga's...   \n",
       "2389  Ʉwe'ki miwiri, inʉ achwʉn, awiri ey kʉno'kwʉn ...   \n",
       "179   Ka'se' inu a'chuiakumuyeykazey nari,jwi anni'k...   \n",
       "\n",
       "                                                    esp  \n",
       "3303  Entonces Jesús los reunió y les dijo:—Como muy...  \n",
       "2715  y comentó con sus cortesanos:—Este es Juan el ...  \n",
       "1897  Volvió a enviarles más criados, con este encar...  \n",
       "2389  En cuanto a ustedes, felices sus ojos por lo q...  \n",
       "179                                            regalias  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>arh</th>\n",
       "      <th>arh_words</th>\n",
       "      <th>arh_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>Los discípulos se acercaron a Jesús y le pregu...</td>\n",
       "      <td>[Los, discípulos, se, acercaron, a, Jesús, y, ...</td>\n",
       "      <td>[▁Los, ▁discíp, ulos, ▁se, ▁acer, car, on, ▁a,...</td>\n",
       "      <td>Kʉriwiya ɉinari Jesú kʉnasiri: —“¿Yari ga'kʉna...</td>\n",
       "      <td>[Kʉriwiya, ɉinari, Jesú, kʉnasiri, :, —, “, ¿,...</td>\n",
       "      <td>[▁K, ʉ, ri, wiya, ▁, ɉ, in, ari, ▁Jesú, ▁k, ʉ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>Allí, con nosotros, había un joven hebreo, sie...</td>\n",
       "      <td>[Allí, ,, con, nosotros, ,, había, un, joven, ...</td>\n",
       "      <td>[▁Al, lí, ,, ▁con, ▁nosotros, ,, ▁había, ▁un, ...</td>\n",
       "      <td>Ey uye'ri ʉya'ba'gwi i'ngwi kwi'ma hebrew kʉns...</td>\n",
       "      <td>[Ey, uye, ', ri, ʉya, ', ba, ', gwi, i, ', ngw...</td>\n",
       "      <td>[▁Ey, ▁uye, ', ri, ▁, ʉ, ya, ', ba, ', g, wi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>En Iconio acudieron también a la sinagoga judí...</td>\n",
       "      <td>[En, Iconio, acudieron, también, a, la, sinago...</td>\n",
       "      <td>[▁En, ▁Ic, onio, ▁ac, udi, eron, ▁también, ▁a,...</td>\n",
       "      <td>Pabluri Bernawerisindi, Ikoniw winkinkumey nʉn...</td>\n",
       "      <td>[Pabluri, Bernawerisindi, ,, Ikoniw, winkinkum...</td>\n",
       "      <td>[▁Pab, l, uri, ▁Berna, wer, is, indi, ,, ▁Ik, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>Entonces Pedro exclamó:—¡Amigo, no sé qué está...</td>\n",
       "      <td>[Entonces, Pedro, exclamó, :, —, ¡, Amigo, ,, ...</td>\n",
       "      <td>[▁Entonces, ▁Pedro, ▁exc, lam, ó, :, —, ¡, Am,...</td>\n",
       "      <td>Pedruse'ri: —“¡Inʉ ey nʉgwʉgín neki na'zanu g...</td>\n",
       "      <td>[Pedruse, ', ri, :, —, “, ¡, Inʉ, ey, nʉgwʉgi,...</td>\n",
       "      <td>[▁Ped, r, use, ', ri, :, ▁, —“, ¡, In, ʉ, ▁ey,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>voy a hacer justicia a esta viuda para evitar ...</td>\n",
       "      <td>[voy, a, hacer, justicia, a, esta, viuda, para...</td>\n",
       "      <td>[▁voy, ▁a, ▁hacer, ▁justicia, ▁a, ▁esta, ▁vi, ...</td>\n",
       "      <td>ema samayʉ gunʉ na'gakʉn nakamʉsin kwa na'kusa...</td>\n",
       "      <td>[ema, samayʉ, gunʉ, na, ', gakʉn, nakamʉsin, k...</td>\n",
       "      <td>[▁ema, ▁samay, ʉ, ▁gun, ʉ, ▁na, ', gak, ʉ, n, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    esp  \\\n",
       "2383  Los discípulos se acercaron a Jesús y le pregu...   \n",
       "1241  Allí, con nosotros, había un joven hebreo, sie...   \n",
       "5224  En Iconio acudieron también a la sinagoga judí...   \n",
       "4588  Entonces Pedro exclamó:—¡Amigo, no sé qué está...   \n",
       "3979  voy a hacer justicia a esta viuda para evitar ...   \n",
       "\n",
       "                                              esp_words  \\\n",
       "2383  [Los, discípulos, se, acercaron, a, Jesús, y, ...   \n",
       "1241  [Allí, ,, con, nosotros, ,, había, un, joven, ...   \n",
       "5224  [En, Iconio, acudieron, también, a, la, sinago...   \n",
       "4588  [Entonces, Pedro, exclamó, :, —, ¡, Amigo, ,, ...   \n",
       "3979  [voy, a, hacer, justicia, a, esta, viuda, para...   \n",
       "\n",
       "                                               esp_toks  \\\n",
       "2383  [▁Los, ▁discíp, ulos, ▁se, ▁acer, car, on, ▁a,...   \n",
       "1241  [▁Al, lí, ,, ▁con, ▁nosotros, ,, ▁había, ▁un, ...   \n",
       "5224  [▁En, ▁Ic, onio, ▁ac, udi, eron, ▁también, ▁a,...   \n",
       "4588  [▁Entonces, ▁Pedro, ▁exc, lam, ó, :, —, ¡, Am,...   \n",
       "3979  [▁voy, ▁a, ▁hacer, ▁justicia, ▁a, ▁esta, ▁vi, ...   \n",
       "\n",
       "                                                    arh  \\\n",
       "2383  Kʉriwiya ɉinari Jesú kʉnasiri: —“¿Yari ga'kʉna...   \n",
       "1241  Ey uye'ri ʉya'ba'gwi i'ngwi kwi'ma hebrew kʉns...   \n",
       "5224  Pabluri Bernawerisindi, Ikoniw winkinkumey nʉn...   \n",
       "4588  Pedruse'ri: —“¡Inʉ ey nʉgwʉgín neki na'zanu g...   \n",
       "3979  ema samayʉ gunʉ na'gakʉn nakamʉsin kwa na'kusa...   \n",
       "\n",
       "                                              arh_words  \\\n",
       "2383  [Kʉriwiya, ɉinari, Jesú, kʉnasiri, :, —, “, ¿,...   \n",
       "1241  [Ey, uye, ', ri, ʉya, ', ba, ', gwi, i, ', ngw...   \n",
       "5224  [Pabluri, Bernawerisindi, ,, Ikoniw, winkinkum...   \n",
       "4588  [Pedruse, ', ri, :, —, “, ¡, Inʉ, ey, nʉgwʉgi,...   \n",
       "3979  [ema, samayʉ, gunʉ, na, ', gakʉn, nakamʉsin, k...   \n",
       "\n",
       "                                               arh_toks  \n",
       "2383  [▁K, ʉ, ri, wiya, ▁, ɉ, in, ari, ▁Jesú, ▁k, ʉ,...  \n",
       "1241  [▁Ey, ▁uye, ', ri, ▁, ʉ, ya, ', ba, ', g, wi, ...  \n",
       "5224  [▁Pab, l, uri, ▁Berna, wer, is, indi, ,, ▁Ik, ...  \n",
       "4588  [▁Ped, r, use, ', ri, :, ▁, —“, ¡, In, ʉ, ▁ey,...  \n",
       "3979  [▁ema, ▁samay, ʉ, ▁gun, ʉ, ▁na, ', gak, ʉ, n, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243398/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>arh_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>arh_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.769700</td>\n",
       "      <td>70.777700</td>\n",
       "      <td>26.177200</td>\n",
       "      <td>36.199700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.782825</td>\n",
       "      <td>32.307254</td>\n",
       "      <td>12.679293</td>\n",
       "      <td>17.633959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>438.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>494.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks      arh_toks     esp_words     arh_words\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean      32.769700     70.777700     26.177200     36.199700\n",
       "std       15.782825     32.307254     12.679293     17.633959\n",
       "min        1.000000      2.000000      1.000000      1.000000\n",
       "25%       23.000000     49.000000     18.000000     25.000000\n",
       "50%       31.000000     67.000000     25.000000     34.000000\n",
       "75%       40.000000     88.000000     32.000000     45.000000\n",
       "max      438.000000    730.000000    330.000000    494.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2518412970065553\n",
      "1.9552012861985042\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ad701eee7e49399830550498d2bb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4376\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Mowga uga kʉgi' mikʉnisiri ku'kinʉnkwe, mibu'gʉmʉ ɉina chʉka'ri i'ngwi uga ma'keywa kʉtow kʉgi', iwa ana'nuga mekʉchwiri chinhwa kʉgi' na'zasanʉkwa'bari diwʉn diwʉn ʉnté nʉnʉkʉre'gawi nʉzoyana gun nʉndi,\",\n",
       " \"Ey anʉwe'ki Inʉ ɉuna keywʉ paperise'ri ka'si eymí na'me mikʉga'siwin key keywʉ nʉsakuku emperadorse'ri kuga'sʉninzari nʉkʉnanu' na'me zʉn ema'ba miwikunakaki nu'kwari na'nó, ʉwe'ki rey Agripase' gun ingumʉn mikunakaki nu'kwʉndi, ey awi má na'zasisakiri ingumʉn Inʉ ka'sʉkwey nʉkʉnanʉngwasi.\",\n",
       " \"Jesuse'ri ino'kwa gun uye'ri: —“Du anazʉnase' ki medikuri kʉɉunʉnno, a'mʉchʉn nugase' zʉndi kʉɉunu' kinʉnno.\",\n",
       " \"Uye'ki Pabluse'ri, ʉnkucho'su nari zweykwasirigʉn, awiri me'zʉnákʉchʉ niku' nanʉngwasirigʉn, na'ba, akowna' zani'nige ikʉ katigu kanʉngwasirigʉn nenʉn keywʉ kʉwasey ie'ri, Féliri ingʉ amʉka' igakumeyri: —“Iwagwi wʉ ʉnzori, eygwi ingumʉn ey awkwey nʉkʉnʉnnige', mikʉkanʉn nukʉnʉngwa ni” Pabluri kʉyana.\",\n",
       " \"Uye'ri Jesuse' keywʉ winʉkey ie'ri: —“Aseykumʉyari ʉya ingʉ tá wazoyʉn mika'w neyka ki ey ayo, miwichʉka gundi Niwipawri profeta Isaía ga'kʉnamʉ a'wesi a'sana yeykari tá yeyka nanu'kinʉnno:‘Ema powruri du gun winʉwasa'ino,ʉwe'ki ʉnhanugwese' kinkiri peykʉ winnakʉchʉ zʉn gun ey riyʉndi,\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "s = random.sample(texts_with_unk, 5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace 𝓕𝔯𝔞𝔫𝔠𝔢𝔰𝔠𝔞 by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf52581c81864eab84c55ea8847f2f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3437\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653126710ef1410cb4fc61ed1c56ec24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_arhuaco_esp_completo_600m/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_arhuaco_esp_completo_600m/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8192\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: naiʉwkeru'ygsmzoh,cd.tɉp\"báEíJ:-NlAéúóIMSP¿?U;ɄKfjLGB()D!¡RTYFĆZñHOWɈʻʼÉvÁÍ1#x438\\29657+\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_arhuaco_esp_completo_600m/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 5785 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=897981\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=105\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 5785 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=532824\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 32135 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 5785\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 25000\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 25000 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12468 obj=14.9535 num_tokens=69162 num_tokens/piece=5.54716\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=10195 obj=11.9478 num_tokens=69781 num_tokens/piece=6.84463\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9001 obj=11.851 num_tokens=70133 num_tokens/piece=7.79169\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8887 obj=11.8125 num_tokens=70310 num_tokens/piece=7.91156\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_arhuaco_esp_completo_600m/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_arhuaco_esp_completo_600m/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**13,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-07 00:08:23--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‘/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py’\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-03-07 00:08:23 (2.97 MB/s) - ‘/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py’ saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256204 262858\n",
      "6653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 00:08:27.023601: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-07 00:08:27.209463: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-07 00:08:27.941898: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-07 00:08:27.942017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-07 00:08:27.942023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 262858. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15feaf3706044b29b6c062ad7d956ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6653 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262858\n",
      "['zul_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256203 + len(added_vocab) + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'arh_Latn', '<mask>']\n",
      "[262856, 262857, 262858]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256202 + len(added_vocab) + 2, 256202 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262857 262672\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 262859. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(262859, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([\"Ey anawi nʉngwa Niwipawsin rimaseynari anʉmʉsesi keywʉ kʉriwiya ɉina rinʉnekʉ eygwi ʉnnase'ri, kwa ʉnde'riwanu' rinari gunti chʉwi ʉnwinʉnkʉnisi, kʉmʉsin ʉndiwa'na awaki ʉndinu'na.\"], ['Después de orar, se levantó y se acercó a sus discípulos. Los encontró dormidos, vencidos por la tristeza,'], 'arh_Latn', 'spa_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9462747cd849be8b980b5f21921bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.190073013305664\n",
      "1000 5.131381028175354\n",
      "2000 3.3973619129657746\n",
      "3000 2.852134324789047\n",
      "4000 2.453072914481163\n",
      "5000 2.1119867748618124\n",
      "6000 1.830887212872505\n",
      "7000 1.5471724071502686\n",
      "8000 1.3330060949027538\n",
      "9000 1.1109682891070842\n",
      "10000 0.9673907795250416\n",
      "11000 0.813227304905653\n",
      "12000 0.7114589656591416\n",
      "13000 0.6110138708651066\n",
      "14000 0.5388254130110145\n",
      "15000 0.4845659437701106\n",
      "16000 0.42970735858380793\n",
      "17000 0.3762495531141758\n",
      "18000 0.3331413685642183\n",
      "19000 0.2897382208369672\n",
      "20000 0.2776409318000078\n",
      "21000 0.24627264761179685\n",
      "22000 0.21262927614711224\n",
      "23000 0.19848256150074303\n",
      "24000 0.17071885754168034\n",
      "25000 0.15194940933957696\n",
      "26000 0.13688114558160305\n",
      "27000 0.11830744071118533\n",
      "28000 0.10284679153934122\n",
      "29000 0.09410758235957474\n",
      "30000 0.08675725552812219\n",
      "31000 0.07678101523127406\n",
      "32000 0.0716032311907038\n",
      "33000 0.06354825538350269\n",
      "34000 0.05971529140789062\n",
      "35000 0.0544157952577807\n",
      "36000 0.05024221531674266\n",
      "37000 0.04897024030191824\n",
      "38000 0.04661069460166618\n",
      "39000 0.04368029218865559\n",
      "40000 0.040613850014749917\n",
      "41000 0.03987353688105941\n",
      "42000 0.037060742933303116\n",
      "43000 0.035935600377852095\n",
      "44000 0.03481885704630986\n",
      "45000 0.03422481483640149\n",
      "46000 0.03313793050311506\n",
      "47000 0.031649957872461526\n",
      "48000 0.029789360215421765\n",
      "49000 0.029692397730890663\n",
      "50000 0.028118288320023565\n",
      "51000 0.028006835835287347\n",
      "52000 0.027043222741922363\n",
      "53000 0.026349114628741517\n",
      "54000 0.024773108914960176\n",
      "55000 0.024794667599140667\n",
      "56000 0.02472613836801611\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['- \"Iwari miwisin, awiri miwi tana ɉinasin, ga\\'kʉnamʉ miwikʉya uweykari ayey ʉnchunha awnʉngwa ni zʉn miwikeywin,']\n",
      "['- Miren, yo establezco mi alianza con ustedes, con sus descendientes,']\n",
      "['- Voy a poner a prueba esta alianza que establezco para siempre con ustedes y con todos los animales que los han acompañado:']\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.4G\n",
      "4.0K drwxrwxr-x 2 americasnlp americasnlp 4.0K Mar  7 00:17 .\n",
      "4.0K drwxrwxr-x 5 americasnlp americasnlp 4.0K Mar  7 02:30 ..\n",
      "972K -rw-rw-r-- 1 americasnlp americasnlp 971K Mar  7 00:08 all_texts_file.csv\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  896 Mar  7 07:34 config.json\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  184 Mar  7 07:34 generation_config.json\n",
      "2.4G -rw-rw-r-- 1 americasnlp americasnlp 2.4G Mar  7 07:34 pytorch_model.bin\n",
      "4.8M -rw-rw-r-- 1 americasnlp americasnlp 4.8M Mar  7 07:34 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp 3.5K Mar  7 07:34 special_tokens_map.json\n",
      "376K -rw-rw-r-- 1 americasnlp americasnlp 373K Mar  7 00:08 spm_16k.model\n",
      "148K -rw-rw-r-- 1 americasnlp americasnlp 148K Mar  7 00:08 spm_16k.vocab\n",
      "4.8M -rw-rw-r-- 1 americasnlp americasnlp 4.8M Mar  7 00:08 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  570 Mar  7 07:34 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cantos amorosos, cantaones amorosos, cantaones amorosos, cantaones amorosos, cantaones amorosos, cantaones amorosos, cantaones amorosos, cantos amorosos']\n"
     ]
    }
   ],
   "source": [
    "t = \"las canciones de amor me gustan mucho\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"ga'kunamu uraku jeyz tinsana zungwa zaka'cho'si zu'nwayeri\"]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['muy satisfactorio también sentir la vitalidad de estos pueblos antiguos']\n"
     ]
    }
   ],
   "source": [
    "t = \"kuyakuyllawan takitam anchata kuyani\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seleccionaron equipos de planeación']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38857f96ba74acc88030b85a6299ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2423d174ab499f874494e362e26a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 6.00 27.2/6.5/3.4/2.2 (BP = 1.000 ratio = 1.046 hyp_len = 15742 ref_len = 15047)\n",
      "chrF2++ = 23.04\n",
      "BLEU = 8.29 29.3/10.1/5.1/3.1 (BP = 1.000 ratio = 1.025 hyp_len = 14365 ref_len = 14019)\n",
      "chrF2++ = 33.28\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "      <th>arh_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>Na'no'kwa zʉn awiri nʉkʉriwia awʉnki, nʉn kinkiri, anugwe rʉnrʉn na'nisiri, awʉnkawa na'zʉna nek...</td>\n",
       "      <td>¡Vengan a mí todos los que están cansados y agobiados, y yo les daré descanso!</td>\n",
       "      <td>\"Miwiri pin umʉnkʉniku' nari nikamʉ re'masi anuga'na ɉinase'ri, ɉwé miwinmi'kusow, ʉwe'ki nʉndi ...</td>\n",
       "      <td>Yo los amo y también a mis discípulos, y no tengo a nadie que los instruya. Yo no he venido a ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>inʉri kʉriwiya ɉina eyki winʉwiukwa kawa'me, ey awi winʉmasʉya'bari: —“Ikʉ zʉ Gʉmʉsinʉ warinzanʉ...</td>\n",
       "      <td>porque estaba dedicado a instruir a sus discípulos. Les explicaba que el Hijo del hombre iba a s...</td>\n",
       "      <td>Awi nʉngwari Jesuri: - \"Ikʉ zʉ gʉmʉsinʉ warin zanʉri ikʉ romanu ɉinase' ipʉnhákumey, agwaka a'wn...</td>\n",
       "      <td>Sí, Padre, así lo has querido tú. Y añadiré que el Hijo del hombre tiene que entregarse a las au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Ʉweri, ɉwí ʉnniwekʉpana awaki nuga'me gun Kanaán pari eygwi ɉwí ʉnmekʉn gun ana'na nʉndi. ¿Azini...</td>\n",
       "      <td>Si vinimos desde Canaán a devolver el dinero que encontramos en la boca de nuestros costales, ¿p...</td>\n",
       "      <td>\"Bema neki Kanaán pari sanuse' ɉwíri eygwi ʉnnaka uyʉn, ¿ey ʉndi má kinkiri mi zurumakʉ pari oru...</td>\n",
       "      <td>Porque no se venden tesoros que constrúen riquezas en el cielo. ¿No se venden tesoros que constr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>Ey uye'ri saserdoti zʉ sakuku ɉinari, umʉnte wina'rizʉna ɉinasin winʉnkʉncho'sʉn keywʉ rizoriri,...</td>\n",
       "      <td>Estos se reunieron con los ancianos del pueblo, y entre todos acordaron sobornar a los soldados</td>\n",
       "      <td>Ey uye' nʉngwari saserdoti zʉ sakuku ɉina awiri umʉnte wina'zʉna ɉina powruse' winʉnni'kumana ɉi...</td>\n",
       "      <td>De igual manera, los jefes de los sacerdotes y los ancianos del pueblo tomaron el acuerdo de mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>i'ngwiri masitesin keywʉ zoyanáɉuri, saserdoti zʉ sakuku ʉmʉn a'zʉna zʉ gunamʉ ná kukwʉ durigʉ...</td>\n",
       "      <td>Y uno de ellos dio un golpe al criado del sumo sacerdote y le cortó la oreja derecha.</td>\n",
       "      <td>Ey ʉwasindi i'ngwi saserdoti ɉina zʉ sakuku umʉn a'zʉna zʉ gunamʉ kukwʉ kʉbeykí keywʉ nu'nari,</td>\n",
       "      <td>Una vez llegaron a Jerusalén, el sumo sacerdote tuvo pleno miedo y se sentó detrás a cierta dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5686</th>\n",
       "      <td>Nʉgʉmʉsinʉ ɉina, Kakʉ ɉwa'kuma awaki nuga'me miwise'ri miwika'siwin. Achʉná ɉina, kʉtʉkʉnʉn inʉ ...</td>\n",
       "      <td>Les escribo a ustedes, los mayores, porque conocen al que existe desde el principio. Les escribo...</td>\n",
       "      <td>Ka'gʉmʉse' du nanu' nari winkwʉya zana awiri, ikʉnha'se' winuniga nʉngwa a'w nanʉnʉngwa me'zanʉk...</td>\n",
       "      <td>Hijos míos, estamos aquí para anunciarles la buena nueva referente a Jesús, el Señor. Y no neces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>Ey uye' nʉngwa Niwipaw Niwisakukuse'ri: —“¿Inʉ tikiriri nʉnʉniri mikey i'e? ¿Kwa kʉn mʉga gu' ná...</td>\n",
       "      <td>Entonces Dios, el Señor, le preguntó:—¿Y quién te dijo que estabas desnudo? ¿Acaso has comido de...</td>\n",
       "      <td>Ey uye' nʉngwa Niwipaw Niwisakukuri eymí keywʉ kʉyana: - \"¿Inʉri mʉkʉ kʉnu'nari nʉnu'nare? kʉn i...</td>\n",
       "      <td>Entonces Dios, el Señor, replicó: - ¿Qué has hecho? ¿No te he servido yo por espacio alguno,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>Jesuse' keywʉ winʉkey ie'ri: —“Báy eygwi ʉɉwʉn mʉchey zóya awʉndi, eymekʉ ayeygwi ga'kʉnamʉ zaka...</td>\n",
       "      <td>y, cuando lo encontraron, le dijeron:—Todos están buscándote.</td>\n",
       "      <td>awi winchwa keywʉ uye'ri: - \"Wintona ɉinari miwisin minakʉngwa nari golu'nʉn zʉn ey winyʉngwa gu...</td>\n",
       "      <td>Jesús les contestó: - Sí, muchacho, soy yo, porque no saben ni el día ni la hora [de la venida d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>apawse'ri eymí zʉn nikʉn nuga ʉnchwʉndi gunamʉ mowga mowga niga, katigu kanʉyáy awi zʉndi katigu...</td>\n",
       "      <td>Entonces lo castigará severamente dándole un lugar entre los hipócritas. Allí llorará y le rechi...</td>\n",
       "      <td>Ey unige'ri mowga mowga aniga ɉinase'gwi anʉnhurakakʉ ʉnzoya zʉn ʉngwa gun neri, eymekʉri chʉwí ...</td>\n",
       "      <td>Dos hombres estarán entonces trabajando en el campo; a uno se lo llevarán y dejarán al otro]. As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>Awi nʉngwari i'ba Galilea meyna rizwein rinuse'ri Jesuse'ri:—“Ikʉ zʉ Gʉmʉsinʉri cheyrwa ɉinase' ...</td>\n",
       "      <td>Pero este género de demonios solo sale por medio de oración y ayuno]. omiten este versículo.Jesú...</td>\n",
       "      <td>Ʉwe'ki eyma anugwe gʉnsinna ɉina kinkiri Niwipawsin rimasayʉn awiri marʉneykʉ rinisi zʉn aga'sʉk...</td>\n",
       "      <td>Todos quedaron allí sentados hasta el punto de preguntarse unos a otros: - ¿Qué está pasando aqu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      arh  \\\n",
       "1807  Na'no'kwa zʉn awiri nʉkʉriwia awʉnki, nʉn kinkiri, anugwe rʉnrʉn na'nisiri, awʉnkawa na'zʉna nek...   \n",
       "2932  inʉri kʉriwiya ɉina eyki winʉwiukwa kawa'me, ey awi winʉmasʉya'bari: —“Ikʉ zʉ Gʉmʉsinʉ warinzanʉ...   \n",
       "622   Ʉweri, ɉwí ʉnniwekʉpana awaki nuga'me gun Kanaán pari eygwi ɉwí ʉnmekʉn gun ana'na nʉndi. ¿Azini...   \n",
       "2025  Ey uye'ri saserdoti zʉ sakuku ɉinari, umʉnte wina'rizʉna ɉinasin winʉnkʉncho'sʉn keywʉ rizoriri,...   \n",
       "4578  i'ngwiri masitesin keywʉ zoyanáɉuri, saserdoti zʉ sakuku ʉmʉn a'zʉna zʉ gunamʉ ná kukwʉ durigʉ...   \n",
       "5686  Nʉgʉmʉsinʉ ɉina, Kakʉ ɉwa'kuma awaki nuga'me miwise'ri miwika'siwin. Achʉná ɉina, kʉtʉkʉnʉn inʉ ...   \n",
       "1128  Ey uye' nʉngwa Niwipaw Niwisakukuse'ri: —“¿Inʉ tikiriri nʉnʉniri mikey i'e? ¿Kwa kʉn mʉga gu' ná...   \n",
       "3459  Jesuse' keywʉ winʉkey ie'ri: —“Báy eygwi ʉɉwʉn mʉchey zóya awʉndi, eymekʉ ayeygwi ga'kʉnamʉ zaka...   \n",
       "1859  apawse'ri eymí zʉn nikʉn nuga ʉnchwʉndi gunamʉ mowga mowga niga, katigu kanʉyáy awi zʉndi katigu...   \n",
       "2008  Awi nʉngwari i'ba Galilea meyna rizwein rinuse'ri Jesuse'ri:—“Ikʉ zʉ Gʉmʉsinʉri cheyrwa ɉinase' ...   \n",
       "\n",
       "                                                                                                      esp  \\\n",
       "1807                       ¡Vengan a mí todos los que están cansados y agobiados, y yo les daré descanso!   \n",
       "2932  porque estaba dedicado a instruir a sus discípulos. Les explicaba que el Hijo del hombre iba a s...   \n",
       "622   Si vinimos desde Canaán a devolver el dinero que encontramos en la boca de nuestros costales, ¿p...   \n",
       "2025      Estos se reunieron con los ancianos del pueblo, y entre todos acordaron sobornar a los soldados   \n",
       "4578                Y uno de ellos dio un golpe al criado del sumo sacerdote y le cortó la oreja derecha.   \n",
       "5686  Les escribo a ustedes, los mayores, porque conocen al que existe desde el principio. Les escribo...   \n",
       "1128  Entonces Dios, el Señor, le preguntó:—¿Y quién te dijo que estabas desnudo? ¿Acaso has comido de...   \n",
       "3459                                        y, cuando lo encontraron, le dijeron:—Todos están buscándote.   \n",
       "1859  Entonces lo castigará severamente dándole un lugar entre los hipócritas. Allí llorará y le rechi...   \n",
       "2008  Pero este género de demonios solo sale por medio de oración y ayuno]. omiten este versículo.Jesú...   \n",
       "\n",
       "                                                                                           arh_translated  \\\n",
       "1807  \"Miwiri pin umʉnkʉniku' nari nikamʉ re'masi anuga'na ɉinase'ri, ɉwé miwinmi'kusow, ʉwe'ki nʉndi ...   \n",
       "2932  Awi nʉngwari Jesuri: - \"Ikʉ zʉ gʉmʉsinʉ warin zanʉri ikʉ romanu ɉinase' ipʉnhákumey, agwaka a'wn...   \n",
       "622   \"Bema neki Kanaán pari sanuse' ɉwíri eygwi ʉnnaka uyʉn, ¿ey ʉndi má kinkiri mi zurumakʉ pari oru...   \n",
       "2025  Ey uye' nʉngwari saserdoti zʉ sakuku ɉina awiri umʉnte wina'zʉna ɉina powruse' winʉnni'kumana ɉi...   \n",
       "4578       Ey ʉwasindi i'ngwi saserdoti ɉina zʉ sakuku umʉn a'zʉna zʉ gunamʉ kukwʉ kʉbeykí keywʉ nu'nari,   \n",
       "5686  Ka'gʉmʉse' du nanu' nari winkwʉya zana awiri, ikʉnha'se' winuniga nʉngwa a'w nanʉnʉngwa me'zanʉk...   \n",
       "1128  Ey uye' nʉngwa Niwipaw Niwisakukuri eymí keywʉ kʉyana: - \"¿Inʉri mʉkʉ kʉnu'nari nʉnu'nare? kʉn i...   \n",
       "3459  awi winchwa keywʉ uye'ri: - \"Wintona ɉinari miwisin minakʉngwa nari golu'nʉn zʉn ey winyʉngwa gu...   \n",
       "1859  Ey unige'ri mowga mowga aniga ɉinase'gwi anʉnhurakakʉ ʉnzoya zʉn ʉngwa gun neri, eymekʉri chʉwí ...   \n",
       "2008  Ʉwe'ki eyma anugwe gʉnsinna ɉina kinkiri Niwipawsin rimasayʉn awiri marʉneykʉ rinisi zʉn aga'sʉk...   \n",
       "\n",
       "                                                                                           esp_translated  \n",
       "1807  Yo los amo y también a mis discípulos, y no tengo a nadie que los instruya. Yo no he venido a ll...  \n",
       "2932  Sí, Padre, así lo has querido tú. Y añadiré que el Hijo del hombre tiene que entregarse a las au...  \n",
       "622   Porque no se venden tesoros que constrúen riquezas en el cielo. ¿No se venden tesoros que constr...  \n",
       "2025  De igual manera, los jefes de los sacerdotes y los ancianos del pueblo tomaron el acuerdo de mat...  \n",
       "4578  Una vez llegaron a Jerusalén, el sumo sacerdote tuvo pleno miedo y se sentó detrás a cierta dist...  \n",
       "5686  Hijos míos, estamos aquí para anunciarles la buena nueva referente a Jesús, el Señor. Y no neces...  \n",
       "1128         Entonces Dios, el Señor, replicó: - ¿Qué has hecho? ¿No te he servido yo por espacio alguno,  \n",
       "3459  Jesús les contestó: - Sí, muchacho, soy yo, porque no saben ni el día ni la hora [de la venida d...  \n",
       "1859  Dos hombres estarán entonces trabajando en el campo; a uno se lo llevarán y dejarán al otro]. As...  \n",
       "2008  Todos quedaron allí sentados hasta el punto de preguntarse unos a otros: - ¿Qué está pasando aqu...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
