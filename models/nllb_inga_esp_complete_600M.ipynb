{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=0\n",
    "MODEL_USED=\"models/nllb_quechua_esp_v4_600M\"\n",
    "# MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_inga_esp_complete_600M\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"ing_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"quechua_Latn\" # Quechua Transferr Learning\n",
    "LANGUAGE_FILE=\"data/ing_completo.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"ing\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3260, 2)\n",
      "Index(['esp', 'ing'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2608 entries, 2951 to 3174\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   esp     2608 non-null   object\n",
      " 1   ing     2608 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 61.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>ing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>tunichii</td>\n",
       "      <td>derrumbar (algo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>chukari</td>\n",
       "      <td>asfixiante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>aparecer</td>\n",
       "      <td>kawarii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>se distribuye</td>\n",
       "      <td>rasiunarii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>volverse delgado</td>\n",
       "      <td>ñañuiai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   esp               ing\n",
       "2951          tunichii  derrumbar (algo)\n",
       "2555           chukari        asfixiante\n",
       "2509          aparecer           kawarii\n",
       "3017     se distribuye        rasiunarii\n",
       "1459  volverse delgado           ñañuiai"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 326 entries, 1620 to 2825\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   esp     326 non-null    object\n",
      " 1   ing     326 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 7.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>ing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>hilado</td>\n",
       "      <td>puchkaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>detener</td>\n",
       "      <td>kidachii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>trastrabillando</td>\n",
       "      <td>wingu wingu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>cualquier</td>\n",
       "      <td>maikanpas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>delgadito</td>\n",
       "      <td>amchishitu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  esp          ing\n",
       "1620           hilado    puchkaska\n",
       "1027          detener     kidachii\n",
       "2281  trastrabillando  wingu wingu\n",
       "2870        cualquier    maikanpas\n",
       "291         delgadito   amchishitu"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 326 entries, 2643 to 442\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   esp     326 non-null    object\n",
      " 1   ing     326 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 7.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>ing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>bramar</td>\n",
       "      <td>ramai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>doscientos</td>\n",
       "      <td>iskai patsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>salir lana</td>\n",
       "      <td>milmaiai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>los derechos indígenas sólo se contemplaban en...</td>\n",
       "      <td>nukanchipa runakuna, chi achka iachag pangakun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>las autoridades garantizarán la adecuada y efe...</td>\n",
       "      <td>nukanchipa alli iuiaikunata kaugsachispa, wiña...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    esp  \\\n",
       "2643                                             bramar   \n",
       "764                                          doscientos   \n",
       "1352                                         salir lana   \n",
       "51    los derechos indígenas sólo se contemplaban en...   \n",
       "178   las autoridades garantizarán la adecuada y efe...   \n",
       "\n",
       "                                                    ing  \n",
       "2643                                              ramai  \n",
       "764                                         iskai patsa  \n",
       "1352                                           milmaiai  \n",
       "51    nukanchipa runakuna, chi achka iachag pangakun...  \n",
       "178   nukanchipa alli iuiaikunata kaugsachispa, wiña...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "499822a8-f5de-4475-bd7b-aae3668f5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f9ad22-d9c3-4b3e-9bc5-e67b263c36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "379b1605-5ead-443a-9b43-2b7f5a54cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', '<mask>', 'quechua_Latn']\n",
      "[262576, 262578, 262577]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([262576, 262577, 262578])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', 'quechua_Latn', '<mask>'])) # [256202, 256203, 256204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2270130-3f49-4ae1-a27f-f947af629f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer, new_lang=\"quechua_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e522da1-81a8-45d5-93c7-cfadc901b780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'quechua_Latn', '<mask>']\n",
      "[262576, 262577, 262578]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([262576, 262577, 262578])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', 'quechua_Latn', '<mask>'])) # [256202, 256203, 256204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>ing</th>\n",
       "      <th>ing_words</th>\n",
       "      <th>ing_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>la ley establecerá las formas de coordinación ...</td>\n",
       "      <td>[la, ley, establecerá, las, formas, de, coordi...</td>\n",
       "      <td>[▁la, ▁ley, ▁establecer, á, ▁las, ▁formas, ▁de...</td>\n",
       "      <td>maikan nukanchi pandarispa kaugsanakugpika, nu...</td>\n",
       "      <td>[maikan, nukanchi, pandarispa, kaugsanakugpika...</td>\n",
       "      <td>[▁ma, ikan, ▁n, ukan, chi, ▁pand, aris, pa, ▁k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>barro</td>\n",
       "      <td>[barro]</td>\n",
       "      <td>[▁bar, ro]</td>\n",
       "      <td>turu</td>\n",
       "      <td>[turu]</td>\n",
       "      <td>[▁turu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>duro</td>\n",
       "      <td>[duro]</td>\n",
       "      <td>[▁duro]</td>\n",
       "      <td>sinchi</td>\n",
       "      <td>[sinchi]</td>\n",
       "      <td>[▁sinchi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>kusaska</td>\n",
       "      <td>[kusaska]</td>\n",
       "      <td>[▁kus, aska]</td>\n",
       "      <td>asado</td>\n",
       "      <td>[asado]</td>\n",
       "      <td>[▁as, ado]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>volverse anémico</td>\n",
       "      <td>[volverse, anémico]</td>\n",
       "      <td>[▁vol, verse, ▁an, ém, ico]</td>\n",
       "      <td>killuiai</td>\n",
       "      <td>[killuiai]</td>\n",
       "      <td>[▁kil, lu, iai]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    esp  \\\n",
       "189   la ley establecerá las formas de coordinación ...   \n",
       "2610                                              barro   \n",
       "3058                                               duro   \n",
       "2553                                            kusaska   \n",
       "2496                                   volverse anémico   \n",
       "\n",
       "                                              esp_words  \\\n",
       "189   [la, ley, establecerá, las, formas, de, coordi...   \n",
       "2610                                            [barro]   \n",
       "3058                                             [duro]   \n",
       "2553                                          [kusaska]   \n",
       "2496                                [volverse, anémico]   \n",
       "\n",
       "                                               esp_toks  \\\n",
       "189   [▁la, ▁ley, ▁establecer, á, ▁las, ▁formas, ▁de...   \n",
       "2610                                         [▁bar, ro]   \n",
       "3058                                            [▁duro]   \n",
       "2553                                       [▁kus, aska]   \n",
       "2496                        [▁vol, verse, ▁an, ém, ico]   \n",
       "\n",
       "                                                    ing  \\\n",
       "189   maikan nukanchi pandarispa kaugsanakugpika, nu...   \n",
       "2610                                               turu   \n",
       "3058                                             sinchi   \n",
       "2553                                              asado   \n",
       "2496                                           killuiai   \n",
       "\n",
       "                                              ing_words  \\\n",
       "189   [maikan, nukanchi, pandarispa, kaugsanakugpika...   \n",
       "2610                                             [turu]   \n",
       "3058                                           [sinchi]   \n",
       "2553                                            [asado]   \n",
       "2496                                         [killuiai]   \n",
       "\n",
       "                                               ing_toks  \n",
       "189   [▁ma, ikan, ▁n, ukan, chi, ▁pand, aris, pa, ▁k...  \n",
       "2610                                            [▁turu]  \n",
       "3058                                          [▁sinchi]  \n",
       "2553                                         [▁as, ado]  \n",
       "2496                                    [▁kil, lu, iai]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_311752/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>ing_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>ing_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.203100</td>\n",
       "      <td>4.545000</td>\n",
       "      <td>2.664000</td>\n",
       "      <td>2.088400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.967234</td>\n",
       "      <td>10.580764</td>\n",
       "      <td>6.937472</td>\n",
       "      <td>4.910254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>131.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks      ing_toks     esp_words     ing_words\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean       4.203100      4.545000      2.664000      2.088400\n",
       "std        8.967234     10.580764      6.937472      4.910254\n",
       "min        1.000000      1.000000      1.000000      1.000000\n",
       "25%        2.000000      2.000000      1.000000      1.000000\n",
       "50%        2.000000      2.000000      1.000000      1.000000\n",
       "75%        3.000000      3.000000      2.000000      1.000000\n",
       "max      131.000000    163.000000    100.000000     74.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.57774024024024\n",
      "2.1763072208389196\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0340a51fb44723825a944cd6759ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# s = random.sample(texts_with_unk, 5)\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace 𝓕𝔯𝔞𝔫𝔠𝔢𝔰𝔠𝔞 by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9b197ef25f4e648b68e95efb1ab266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7775c3ee1f364488bae1b4577562a520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_inga_esp_complete_600M/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_inga_esp_complete_600M/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2048\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: aiuknshcrplmgtwd,bñejoáyfzAxv()19:qT;P80C3í2W6-5\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_inga_esp_complete_600M/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 3260 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=50485\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=64\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 3260 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=29624\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 6320 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 3260\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 3732\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 3732 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2788 obj=13.0774 num_tokens=7234 num_tokens/piece=2.59469\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2355 obj=11.4577 num_tokens=7283 num_tokens/piece=3.09257\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2153 obj=11.2994 num_tokens=7350 num_tokens/piece=3.41384\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2118 obj=11.233 num_tokens=7405 num_tokens/piece=3.49622\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_inga_esp_complete_600M/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_inga_esp_complete_600M/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**11,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-15 19:42:15--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‘/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py’\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-15 19:42:15 (84.9 MB/s) - ‘/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py’ saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "fix_tokenizer(tokenizer, new_lang=\"quechua_Latn\")\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262579 263837\n",
      "1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 19:42:17.962101: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 19:42:18.135237: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-15 19:42:18.853052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-15 19:42:18.853111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-15 19:42:18.853116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 263837. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbd52a232bf443493e3e25dbfd26b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "fix_tokenizer(tokenizer_old, new_lang=\"quechua_Latn\")\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f20fc584-27fa-4d8f-b0ec-57936d69c98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'quechua_Latn', '<mask>']\n",
      "[262576, 262577, 262578]\n",
      "['urku', 'lisinsia', '▁willarai']\n",
      "[263834, 3, 263836]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_old.convert_ids_to_tokens([262576, 262577, 262578])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "print(tokenizer_old.convert_tokens_to_ids(['zul_Latn', 'quechua_Latn', '<mask>'])) # [256202, 256203, 256204]\n",
    "\n",
    "fix_tokenizer(tokenizer, new_lang=\"quechua_Latn\")\n",
    "print(tokenizer.convert_ids_to_tokens([263137, 263138, 263139])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', 'quechua_Cyrl', '<mask>'])) # [256202, 256203, 256204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263837\n",
      "1258\n",
      "['lisinsia', '▁willarai']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(len(added_vocab))\n",
    "print(tokenizer.convert_ids_to_tokens([263138, 263139]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quechua_Latn', 'ing_Latn', '<mask>']\n",
      "[263835, 263836, 263837]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([262576 + len(added_vocab) + 1, 262576 + len(added_vocab) + 2, 262576 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['quechua_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263836 263835\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 263838. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(263838, 1024)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['kuchillu'], ['cuchillo'], 'ing_Latn', 'spa_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3ef586ae0645b59b557b1d68fb8bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.277602672576904\n",
      "1000 4.400586699008942\n",
      "2000 1.647396609544754\n",
      "3000 0.8376787638813257\n",
      "4000 0.47226350666582584\n",
      "5000 0.32155112781748174\n",
      "6000 0.2456098491800949\n",
      "7000 0.19989903125027195\n",
      "8000 0.16227175561664625\n",
      "9000 0.13480244848364964\n",
      "10000 0.12098119097342715\n",
      "11000 0.10337147637782619\n",
      "12000 0.09162986964336596\n",
      "13000 0.08352887795539572\n",
      "14000 0.08147093646996655\n",
      "15000 0.07408731288358103\n",
      "16000 0.07185788752138615\n",
      "17000 0.06637712298991391\n",
      "18000 0.06578890951216454\n",
      "19000 0.06363818973419257\n",
      "20000 0.059918874552822673\n",
      "21000 0.05925618591229431\n",
      "22000 0.057542106979642994\n",
      "23000 0.05411406857118709\n",
      "24000 0.054317063146358126\n",
      "25000 0.05435483730322448\n",
      "26000 0.054474176948686365\n",
      "27000 0.052352993999636964\n",
      "28000 0.05393847317970358\n",
      "29000 0.04930145579352393\n",
      "30000 0.05202772203669883\n",
      "31000 0.05025345226572244\n",
      "32000 0.04745320771954721\n",
      "33000 0.04870716783542593\n",
      "34000 0.04828225708474929\n",
      "35000 0.04497251131335361\n",
      "36000 0.047520073045729076\n",
      "37000 0.046444822476689296\n",
      "38000 0.04566375157828588\n",
      "39000 0.045157858798469536\n",
      "40000 0.04748357945094176\n",
      "41000 0.046087418394410634\n",
      "42000 0.04573183283567778\n",
      "43000 0.04191743356917141\n",
      "44000 0.043084459311503454\n",
      "45000 0.045634020689092725\n",
      "46000 0.04247345724181287\n",
      "47000 0.044661638768349804\n",
      "48000 0.04257958675851842\n",
      "49000 0.04248369688457751\n",
      "50000 0.04363256965552136\n",
      "51000 0.04385293878489392\n",
      "52000 0.04094254114362775\n",
      "53000 0.04144489096397956\n",
      "54000 0.040551094067675875\n",
      "55000 0.04321778522092791\n",
      "56000 0.041424148423669975\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ñagcharii']\n",
      "['peinarse']\n",
      "['agacharse']\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.4G\n",
      "4.0K drwxrwxr-x  2 americasnlp americasnlp 4.0K Mar 15 19:47 .\n",
      "4.0K drwxr-xr-x 14 americasnlp americasnlp 4.0K Mar 15 19:40 ..\n",
      " 56K -rw-rw-r--  1 americasnlp americasnlp  53K Mar 15 19:42 all_texts_file.csv\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  895 Mar 16 00:16 config.json\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  184 Mar 16 00:16 generation_config.json\n",
      "2.4G -rw-rw-r--  1 americasnlp americasnlp 2.4G Mar 16 00:16 pytorch_model.bin\n",
      "4.8M -rw-rw-r--  1 americasnlp americasnlp 4.8M Mar 16 00:16 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp 3.5K Mar 16 00:16 special_tokens_map.json\n",
      "264K -rw-rw-r--  1 americasnlp americasnlp 263K Mar 15 19:42 spm_16k.model\n",
      " 32K -rw-rw-r--  1 americasnlp americasnlp  32K Mar 15 19:42 spm_16k.vocab\n",
      "4.8M -rw-rw-r--  1 americasnlp americasnlp 4.8M Mar 15 19:42 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  570 Mar 16 00:16 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "# fix_tokenizer(tokenizer)\n",
    "# print(tokenizer.convert_ids_to_tokens([262576 + len(added_vocab) + 1, 262576 + len(added_vocab) + 2, 262576 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "# print(tokenizer.convert_tokens_to_ids(['quechua_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8638736c-e6c6-43db-a297-633cdbe77ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer, new_lang=\"quechua_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5a9edd1-ac18-4b94-920b-bdd6dee27d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.convert_ids_to_tokens([263137, 263138, 263139])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "# print(tokenizer.convert_tokens_to_ids(['zul_Latn', 'quechua_Latn', '<mask>'])) # [256202, 256203, 256204]\n",
    "fix_tokenizer(tokenizer)\n",
    "# print(tokenizer.convert_ids_to_tokens([263137, 263138])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "# print(tokenizer.convert_tokens_to_ids(['zul_Latn', 'quechua_Cyrl', '<mask>'])) # [256202, 256203, 256204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb200680-2c26-4a60-a34c-ae5fe7b5c575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁willarai', 'chumbilli']\n",
      "[263836, 263837]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([263139, 263140])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids([LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f83cab4b-fb4e-4c8e-a3aa-47f4fa2e054e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ing_Latn'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGUAGE_TARGET_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chalai sutikankunami: mateo chundur, isidoro chasoy chasoy, domingo tandioy chasoy (paikunakla puiblupi tianakuskami kankuna), maria esperanza jacanamijoy jansasoy, jaime pena jamioy (paikunaka puiblupi tianakuskata katiraigkunami kankuna), blanca chindoy']\n"
     ]
    }
   ],
   "source": [
    "t = \"Muchas de las centenares de especies se usan ornamentalmente\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chalai']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a partir de 1993 entrará a regir lo dispuesto en el artículo 357 de la constitución, sobre participación de los municipios en los ingresos corrientes de la nación']\n"
     ]
    }
   ],
   "source": [
    "t = \"achka iachag pangakunapa wawami tukuikunatami iuka rigsingapa kai alpapi apispa\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en los establecimientos del estado ninguna persona podrá ser obligada a actuar contra su conciencia']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e672c289ef2a4ddcb5eaea53110a4c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504189b1cb034308ab3c28a346fce39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 1.27 18.8/2.1/0.4/0.2 (BP = 0.997 ratio = 0.997 hyp_len = 996 ref_len = 999)\n",
      "chrF2++ = 20.43\n",
      "BLEU = 3.08 18.4/3.5/1.7/0.8 (BP = 1.000 ratio = 1.109 hyp_len = 919 ref_len = 829)\n",
      "chrF2++ = 27.21\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ing</th>\n",
       "      <th>esp</th>\n",
       "      <th>ing_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>bandarii</td>\n",
       "      <td>se divide</td>\n",
       "      <td>chaugpirii</td>\n",
       "      <td>partirse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>wigsa</td>\n",
       "      <td>estómago</td>\n",
       "      <td>wigsa</td>\n",
       "      <td>estómago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>sisu</td>\n",
       "      <td>parásito blanco</td>\n",
       "      <td>lanku parisma</td>\n",
       "      <td>¡Oiga!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>animarii</td>\n",
       "      <td>animarse</td>\n",
       "      <td>convenir</td>\n",
       "      <td>convenir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>llulluiai</td>\n",
       "      <td>volverse tierno</td>\n",
       "      <td>llulluiai</td>\n",
       "      <td>volverse tierno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>kallamba</td>\n",
       "      <td>hongo</td>\n",
       "      <td>iana añangu</td>\n",
       "      <td>liso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>wawa chaparu</td>\n",
       "      <td>apenas enmontado</td>\n",
       "      <td>tulaska</td>\n",
       "      <td>potrero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>ukucha</td>\n",
       "      <td>ratón</td>\n",
       "      <td>shiguina ukucha</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>warmi chundur</td>\n",
       "      <td>chundur</td>\n",
       "      <td>jinti chundur</td>\n",
       "      <td>planta medicinal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>chi nukanchikikin agllaskakunaka iukankunami allilla rigsinga u chikuna rurai puriskakuna kanga</td>\n",
       "      <td>en las entidades territoriales habrá también consejos de planeación, según lo determine la ley</td>\n",
       "      <td>tiq sqaidoine imamlansleidoilsi</td>\n",
       "      <td>el hecho de haberme enfrentado a esta dura tarea, sin una experiencia previa en traducción, me d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  ing  \\\n",
       "3019                                                                                         bandarii   \n",
       "2272                                                                                            wigsa   \n",
       "1837                                                                                             sisu   \n",
       "313                                                                                          animarii   \n",
       "1220                                                                                        llulluiai   \n",
       "905                                                                                          kallamba   \n",
       "2258                                                                                     wawa chaparu   \n",
       "2063                                                                                           ukucha   \n",
       "2223                                                                                    warmi chundur   \n",
       "203   chi nukanchikikin agllaskakunaka iukankunami allilla rigsinga u chikuna rurai puriskakuna kanga   \n",
       "\n",
       "                                                                                                 esp  \\\n",
       "3019                                                                                       se divide   \n",
       "2272                                                                                        estómago   \n",
       "1837                                                                                 parásito blanco   \n",
       "313                                                                                         animarse   \n",
       "1220                                                                                 volverse tierno   \n",
       "905                                                                                            hongo   \n",
       "2258                                                                                apenas enmontado   \n",
       "2063                                                                                           ratón   \n",
       "2223                                                                                         chundur   \n",
       "203   en las entidades territoriales habrá también consejos de planeación, según lo determine la ley   \n",
       "\n",
       "                       ing_translated  \\\n",
       "3019                       chaugpirii   \n",
       "2272                            wigsa   \n",
       "1837                    lanku parisma   \n",
       "313                          convenir   \n",
       "1220                        llulluiai   \n",
       "905                       iana añangu   \n",
       "2258                          tulaska   \n",
       "2063                  shiguina ukucha   \n",
       "2223                    jinti chundur   \n",
       "203   tiq sqaidoine imamlansleidoilsi   \n",
       "\n",
       "                                                                                           esp_translated  \n",
       "3019                                                                                             partirse  \n",
       "2272                                                                                             estómago  \n",
       "1837                                                                                               ¡Oiga!  \n",
       "313                                                                                              convenir  \n",
       "1220                                                                                      volverse tierno  \n",
       "905                                                                                                  liso  \n",
       "2258                                                                                              potrero  \n",
       "2063                                                                                              abdomen  \n",
       "2223                                                                                     planta medicinal  \n",
       "203   el hecho de haberme enfrentado a esta dura tarea, sin una experiencia previa en traducción, me d...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776cf77-7387-40e4-8941-ab345fb844ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
