{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=0\n",
    "# MODEL_USED=\"facebook/nllb-200-distilled-600M\"\n",
    "MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_arhuaco_esp_completo_1_3B\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"arh_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"ayr_Latn\" # Central Aymara\n",
    "LANGUAGE_FILE=\"data/arh_completo.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"arh\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5785, 2)\n",
      "Index(['arh', 'esp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4628 entries, 339 to 860\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     4628 non-null   object\n",
      " 1   esp     4628 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 108.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Pad√°n-ar√°m ayek â pari  ânnak ân nu'kwe'ri, mazak...</td>\n",
       "      <td>Cuando yo regresaba de Par√°n Aram, se me muri√≥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>i'ngwi uga mowga k âtow  ânhakw âya nariri, i'ngw...</td>\n",
       "      <td>√©ramos doce hermanos, hijos del mismo padre; u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>Awi krususe' asakayri:  ªEmari judiÃÅw z â rey gu...</td>\n",
       "      <td>‚ÄîSi t√∫ eres el rey de los jud√≠os, s√°lvate a ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Ey uye' n ângwari ‚Äúposuri Seb√° za'kinuk ângwa ni...</td>\n",
       "      <td>Isaac le puso el nombre de Seb√° ‚Äîes decir, ¬´Ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>Ey  âweri k ât âk ân ân ka'g âm â a'bore pari profeta...</td>\n",
       "      <td>De este modo demuestran estar de acuerdo con l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "339   Pad√°n-ar√°m ayek â pari  ânnak ân nu'kwe'ri, mazak...   \n",
       "837   i'ngwi uga mowga k âtow  ânhakw âya nariri, i'ngw...   \n",
       "4222  Awi krususe' asakayri:  ªEmari judiÃÅw z â rey gu...   \n",
       "387   Ey uye' n ângwari ‚Äúposuri Seb√° za'kinuk ângwa ni...   \n",
       "4381  Ey  âweri k ât âk ân ân ka'g âm â a'bore pari profeta...   \n",
       "\n",
       "                                                    esp  \n",
       "339   Cuando yo regresaba de Par√°n Aram, se me muri√≥...  \n",
       "837   √©ramos doce hermanos, hijos del mismo padre; u...  \n",
       "4222  ‚ÄîSi t√∫ eres el rey de los jud√≠os, s√°lvate a ti...  \n",
       "387   Isaac le puso el nombre de Seb√° ‚Äîes decir, ¬´Ju...  \n",
       "4381  De este modo demuestran estar de acuerdo con l...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 578 entries, 2201 to 457\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     578 non-null    object\n",
      " 1   esp     577 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>Altarzey nari ga'k ânam â mik ânchunh ân ângwa ni y...</td>\n",
       "      <td>¬°Ciegos! ¬øQu√© es m√°s importante, la ofrenda o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>Awi n ângwari win âk âriwiya …âinari …âiw â chukutar...</td>\n",
       "      <td>Cuando los disc√≠pulos llegaron a la otra orill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>Josese'ri: ‚Äî‚ÄúM√°yk ân â k√∫kw âri, m√°yk ân â …âw√≠a, za...</td>\n",
       "      <td>Jos√© le dijo:‚ÄîEsta es la interpretaci√≥n: los t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Iwa mari migwia …âina gwasi um ân me'kawiri ka'g...</td>\n",
       "      <td>Y a ti, te doy una franja de tierra mayor que ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>Jesuse'ri:‚Äî‚ÄúN âpaw kinkiri chiwa powru Israeri ...</td>\n",
       "      <td>Jes√∫s entonces dijo:‚ÄîDios me ha enviado solame...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "2201  Altarzey nari ga'k ânam â mik ânchunh ân ângwa ni y...   \n",
       "2225  Awi n ângwari win âk âriwiya …âinari …âiw â chukutar...   \n",
       "1652  Josese'ri: ‚Äî‚ÄúM√°yk ân â k√∫kw âri, m√°yk ân â …âw√≠a, za...   \n",
       "354   Iwa mari migwia …âina gwasi um ân me'kawiri ka'g...   \n",
       "2518  Jesuse'ri:‚Äî‚ÄúN âpaw kinkiri chiwa powru Israeri ...   \n",
       "\n",
       "                                                    esp  \n",
       "2201  ¬°Ciegos! ¬øQu√© es m√°s importante, la ofrenda o ...  \n",
       "2225  Cuando los disc√≠pulos llegaron a la otra orill...  \n",
       "1652  Jos√© le dijo:‚ÄîEsta es la interpretaci√≥n: los t...  \n",
       "354   Y a ti, te doy una franja de tierra mayor que ...  \n",
       "2518  Jes√∫s entonces dijo:‚ÄîDios me ha enviado solame...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 579 entries, 3303 to 2299\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     579 non-null    object\n",
      " 1   esp     579 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>Uye'ki Jesuse' yow win âk âkariri: ‚Äî‚Äú…Ñ…âway ik â s...</td>\n",
       "      <td>Entonces Jes√∫s los reuni√≥ y les dijo:‚ÄîComo muy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>√° ka'm âkan âya …âinari: ‚Äî‚ÄúEymari Juan Bautista e...</td>\n",
       "      <td>y coment√≥ con sus cortesanos:‚ÄîEste es Juan el ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>Ey uye' n ângwa reyri i'ngweygwi gunam â winga's...</td>\n",
       "      <td>Volvi√≥ a enviarles m√°s criados, con este encar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>…Ñwe'ki miwiri, in â achw ân, awiri ey k âno'kw ân ...</td>\n",
       "      <td>En cuanto a ustedes, felices sus ojos por lo q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Ka'se' inu a'chuiakumuyeykazey nari,jwi anni'k...</td>\n",
       "      <td>regalias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "3303  Uye'ki Jesuse' yow win âk âkariri: ‚Äî‚Äú…Ñ…âway ik â s...   \n",
       "2715  √° ka'm âkan âya …âinari: ‚Äî‚ÄúEymari Juan Bautista e...   \n",
       "1897  Ey uye' n ângwa reyri i'ngweygwi gunam â winga's...   \n",
       "2389  …Ñwe'ki miwiri, in â achw ân, awiri ey k âno'kw ân ...   \n",
       "179   Ka'se' inu a'chuiakumuyeykazey nari,jwi anni'k...   \n",
       "\n",
       "                                                    esp  \n",
       "3303  Entonces Jes√∫s los reuni√≥ y les dijo:‚ÄîComo muy...  \n",
       "2715  y coment√≥ con sus cortesanos:‚ÄîEste es Juan el ...  \n",
       "1897  Volvi√≥ a enviarles m√°s criados, con este encar...  \n",
       "2389  En cuanto a ustedes, felices sus ojos por lo q...  \n",
       "179                                            regalias  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45229a4282bc458c95801172797a7b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa5b39696824010947c0f77342142c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914556bbcb7e4c72a7c50d8d8078a5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>arh</th>\n",
       "      <th>arh_words</th>\n",
       "      <th>arh_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>‚ÄîUn sembrador sali√≥ a sembrar su semilla. Al l...</td>\n",
       "      <td>[‚Äî, Un, sembrador, sali√≥, a, sembrar, su, semi...</td>\n",
       "      <td>[‚ñÅ, ‚Äî, Un, ‚ñÅsembr, ador, ‚ñÅsali√≥, ‚ñÅa, ‚ñÅsem, bra...</td>\n",
       "      <td>‚Äî‚ÄúI'ngwi  ânk âniga keyw â za…âuna  ânzarik ân zoyan...</td>\n",
       "      <td>[‚Äî, ‚Äú, I, ', ngwi,  ânk âniga, keyw â, za…âuna,  ân...</td>\n",
       "      <td>[‚ñÅ, ‚Äî‚Äú, I, ', ng, wi, ‚ñÅ,  â, nk,  â, niga, ‚ñÅkey,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>Pilato le pregunt√≥:‚Äî¬øEres t√∫ el rey de los jud...</td>\n",
       "      <td>[Pilato, le, pregunt√≥, :, ‚Äî, ¬ø, Eres, t√∫, el, ...</td>\n",
       "      <td>[‚ñÅPilato, ‚ñÅle, ‚ñÅpregunt, √≥, :, ‚Äî, ¬ø, E, res, ‚ñÅ...</td>\n",
       "      <td>Ey awi Pilatuse'ri: ‚Äî‚Äú¬øM√° ki jud√≠w …âina z â rey...</td>\n",
       "      <td>[Ey, awi, Pilatuse, ', ri, :, ‚Äî, ‚Äú, ¬ø, M√°, ki,...</td>\n",
       "      <td>[‚ñÅEy, ‚ñÅawi, ‚ñÅPilat, use, ', ri, :, ‚ñÅ, ‚Äî‚Äú, ¬ø, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>Los hijos de Elifaz fueron: Tem√°n, Omar, Sef√≥,...</td>\n",
       "      <td>[Los, hijos, de, Elifaz, fueron, :, Tem√°n, ,, ...</td>\n",
       "      <td>[‚ñÅLos, ‚ñÅhijos, ‚ñÅde, ‚ñÅEli, fa, z, ‚ñÅfueron, :, ‚ñÅ...</td>\n",
       "      <td>Awi n ângwa Elifa z â g âm âsin â …âinari: Tem√°n, Om...</td>\n",
       "      <td>[Awi, n ângwa, Elifa, z â, g âm âsin â, …âinari, :, ...</td>\n",
       "      <td>[‚ñÅAwi, ‚ñÅn,  â, ngwa, ‚ñÅEli, fa, ‚ñÅz,  â, ‚ñÅg,  â, m,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>Y bendijo Dios el d√≠a s√©ptimo y lo declar√≥ d√≠a...</td>\n",
       "      <td>[Y, bendijo, Dios, el, d√≠a, s√©ptimo, y, lo, de...</td>\n",
       "      <td>[‚ñÅY, ‚ñÅbendi, jo, ‚ñÅDios, ‚ñÅel, ‚ñÅd√≠a, ‚ñÅs√©, p, tim...</td>\n",
       "      <td>Ey awi Niwipawri koga …âw√≠ndi  ânka'guka awiri, ...</td>\n",
       "      <td>[Ey, awi, Niwipawri, koga, …âw√≠ndi,  ânka, ', gu...</td>\n",
       "      <td>[‚ñÅEy, ‚ñÅawi, ‚ñÅNi, wi, paw, ri, ‚ñÅkoga, ‚ñÅ, …â, w, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>Ya Mois√©s dijo al respecto: El Se√±or, el Dios ...</td>\n",
       "      <td>[Ya, Mois√©s, dijo, al, respecto, :, El, Se√±or,...</td>\n",
       "      <td>[‚ñÅYa, ‚ñÅMois√©s, ‚ñÅdijo, ‚ñÅal, ‚ñÅrespecto, :, ‚ñÅEl, ...</td>\n",
       "      <td>ey  âwaki eyma profeta a'no'ku' neykari powruse...</td>\n",
       "      <td>[ey,  âwaki, eyma, profeta, a, ', no, ', ku, ',...</td>\n",
       "      <td>[‚ñÅey, ‚ñÅ,  â, waki, ‚ñÅey, ma, ‚ñÅprofeta, ‚ñÅa, ', no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    esp  \\\n",
       "4022  ‚ÄîUn sembrador sali√≥ a sembrar su semilla. Al l...   \n",
       "3174  Pilato le pregunt√≥:‚Äî¬øEres t√∫ el rey de los jud...   \n",
       "1329  Los hijos de Elifaz fueron: Tem√°n, Omar, Sef√≥,...   \n",
       "1590  Y bendijo Dios el d√≠a s√©ptimo y lo declar√≥ d√≠a...   \n",
       "5016  Ya Mois√©s dijo al respecto: El Se√±or, el Dios ...   \n",
       "\n",
       "                                              esp_words  \\\n",
       "4022  [‚Äî, Un, sembrador, sali√≥, a, sembrar, su, semi...   \n",
       "3174  [Pilato, le, pregunt√≥, :, ‚Äî, ¬ø, Eres, t√∫, el, ...   \n",
       "1329  [Los, hijos, de, Elifaz, fueron, :, Tem√°n, ,, ...   \n",
       "1590  [Y, bendijo, Dios, el, d√≠a, s√©ptimo, y, lo, de...   \n",
       "5016  [Ya, Mois√©s, dijo, al, respecto, :, El, Se√±or,...   \n",
       "\n",
       "                                               esp_toks  \\\n",
       "4022  [‚ñÅ, ‚Äî, Un, ‚ñÅsembr, ador, ‚ñÅsali√≥, ‚ñÅa, ‚ñÅsem, bra...   \n",
       "3174  [‚ñÅPilato, ‚ñÅle, ‚ñÅpregunt, √≥, :, ‚Äî, ¬ø, E, res, ‚ñÅ...   \n",
       "1329  [‚ñÅLos, ‚ñÅhijos, ‚ñÅde, ‚ñÅEli, fa, z, ‚ñÅfueron, :, ‚ñÅ...   \n",
       "1590  [‚ñÅY, ‚ñÅbendi, jo, ‚ñÅDios, ‚ñÅel, ‚ñÅd√≠a, ‚ñÅs√©, p, tim...   \n",
       "5016  [‚ñÅYa, ‚ñÅMois√©s, ‚ñÅdijo, ‚ñÅal, ‚ñÅrespecto, :, ‚ñÅEl, ...   \n",
       "\n",
       "                                                    arh  \\\n",
       "4022  ‚Äî‚ÄúI'ngwi  ânk âniga keyw â za…âuna  ânzarik ân zoyan...   \n",
       "3174  Ey awi Pilatuse'ri: ‚Äî‚Äú¬øM√° ki jud√≠w …âina z â rey...   \n",
       "1329  Awi n ângwa Elifa z â g âm âsin â …âinari: Tem√°n, Om...   \n",
       "1590  Ey awi Niwipawri koga …âw√≠ndi  ânka'guka awiri, ...   \n",
       "5016  ey  âwaki eyma profeta a'no'ku' neykari powruse...   \n",
       "\n",
       "                                              arh_words  \\\n",
       "4022  [‚Äî, ‚Äú, I, ', ngwi,  ânk âniga, keyw â, za…âuna,  ân...   \n",
       "3174  [Ey, awi, Pilatuse, ', ri, :, ‚Äî, ‚Äú, ¬ø, M√°, ki,...   \n",
       "1329  [Awi, n ângwa, Elifa, z â, g âm âsin â, …âinari, :, ...   \n",
       "1590  [Ey, awi, Niwipawri, koga, …âw√≠ndi,  ânka, ', gu...   \n",
       "5016  [ey,  âwaki, eyma, profeta, a, ', no, ', ku, ',...   \n",
       "\n",
       "                                               arh_toks  \n",
       "4022  [‚ñÅ, ‚Äî‚Äú, I, ', ng, wi, ‚ñÅ,  â, nk,  â, niga, ‚ñÅkey,...  \n",
       "3174  [‚ñÅEy, ‚ñÅawi, ‚ñÅPilat, use, ', ri, :, ‚ñÅ, ‚Äî‚Äú, ¬ø, M...  \n",
       "1329  [‚ñÅAwi, ‚ñÅn,  â, ngwa, ‚ñÅEli, fa, ‚ñÅz,  â, ‚ñÅg,  â, m,...  \n",
       "1590  [‚ñÅEy, ‚ñÅawi, ‚ñÅNi, wi, paw, ri, ‚ñÅkoga, ‚ñÅ, …â, w, ...  \n",
       "5016  [‚ñÅey, ‚ñÅ,  â, waki, ‚ñÅey, ma, ‚ñÅprofeta, ‚ñÅa, ', no...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_245897/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>arh_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>arh_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.769700</td>\n",
       "      <td>70.777700</td>\n",
       "      <td>26.177200</td>\n",
       "      <td>36.199700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.782825</td>\n",
       "      <td>32.307254</td>\n",
       "      <td>12.679293</td>\n",
       "      <td>17.633959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>438.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>494.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks      arh_toks     esp_words     arh_words\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean      32.769700     70.777700     26.177200     36.199700\n",
       "std       15.782825     32.307254     12.679293     17.633959\n",
       "min        1.000000      2.000000      1.000000      1.000000\n",
       "25%       23.000000     49.000000     18.000000     25.000000\n",
       "50%       31.000000     67.000000     25.000000     34.000000\n",
       "75%       40.000000     88.000000     32.000000     45.000000\n",
       "max      438.000000    730.000000    330.000000    494.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2518412970065553\n",
      "1.9552012861985042\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1dec5fdfac451298487ba4d91316d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4376\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Ey awi niwisinam â  ânnika awiri mibu'g âm â …âinari niwisin k âsanika unige'ri, niwibu'g âm â …âinari miwisin k âs√° nikagwiri a'wkin ânno.\",\n",
       " \"Ey  âweri t√° kinkiri bek â nez ân ka'g âm âse' t âg ânsa ga'k ânam â duna zaka'cho'kum âyari ema a'mia in â uni'nari ayeygwi zaka'cho'kuma kinki aw ângwa na'n ânno, ey unige'ri ik âse'ri ag ânchona kinki  ânte' aw ângwa gun neri‚Äù win âk âyana.J√∫dari Jes√∫  ânwes ângwa a'zari re'tak ân nu'na(Mt. :-; Luk. :-)\",\n",
       " \"‚Äî‚ÄúNiwipaw ku'nawak â zan â aw ânkawa rek âkum ây ân,iwa ik â ka'se' zan â, Niwipawse' aguz âna …âinari, tan â zanam â‚Äù win âk ânan ângwa ni.\",\n",
       " \"‚Äî‚ÄúEma rienta powruse' w â winzori, ey awi eyk â akinkumanige'ri i'ngwi buru in âse' neki iasu'gwi neyka a'…âaÃÅ zan ângwa'ch â, ey unige'ri a'tisiri unaka awkwa.\",\n",
       " \"Niwipaw Niwisakukuse'ri: ‚Äî‚ÄúA'mia n âk ârigas√©y n âni'nach âkari, ana'nuga ak√≠n k ânk ân ân kw âya …âina gwasi m√° n âkin z ân du in â mikizwe'i nari keyw âri. √Åkwa ka' gey zun w âr âsi z ân n âkw ângwa ni.\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "s = random.sample(texts_with_unk, 5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace ùìïùîØùîûùî´ùî†ùî¢ùî∞ùî†ùîû by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751cde827fb14f2c8ee518f5c1248a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3437\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480949d9429b433aa86dd2c626178bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_arhuaco_esp_completo_1_3B/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_arhuaco_esp_completo_1_3B/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8192\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: nai âwkeru'ygsmzoh,cd.t…âp\"b√°E√≠J:-NlA√©√∫√≥IMSP¬ø?U;…ÑKfjLGB()D!¬°RTYFCÃÅZ√±HOW…à ª º√âv√Å√ç1#x438\\29657+\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_arhuaco_esp_completo_1_3B/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 5785 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=897981\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=105\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 5785 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=532824\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 32135 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 5785\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 25000\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 25000 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12468 obj=14.9535 num_tokens=69162 num_tokens/piece=5.54716\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=10195 obj=11.9478 num_tokens=69781 num_tokens/piece=6.84463\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9001 obj=11.851 num_tokens=70133 num_tokens/piece=7.79169\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8887 obj=11.8125 num_tokens=70310 num_tokens/piece=7.91156\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_arhuaco_esp_completo_1_3B/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_arhuaco_esp_completo_1_3B/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**13,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-07 11:59:25--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-07 11:59:25 (39.4 MB/s) - ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256204 262858\n",
      "6653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21cbb79c59b4ce5b8a2de794016eec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 11:59:29.490998: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-07 11:59:29.651666: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-07 11:59:30.391086: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-07 11:59:30.391210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-07 11:59:30.391217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d854e3797a4680be8d08673b173ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 262858. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ee5d4ce1014d07bfe6f1e564f8771b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6653 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262858\n",
      "['zul_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256203 + len(added_vocab) + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'arh_Latn', '<mask>']\n",
      "[262856, 262857, 262858]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256202 + len(added_vocab) + 2, 256202 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262857 262672\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 262859. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(262859, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['las personas-puentes iban a ser, en primer lugar, ind√≠genas ling√ºistas, formados casi todos en nuestro centro, pero tambi√©n maestros, promotores de salud, l√≠deres pol√≠ticos, en general gente con un mejor conocimiento del mundo blanco; los conocedores de la tradici√≥n ser√≠an seg√∫n los casos: mamos, pay√©s, chamanes, taitas y ancianos o sea l√≠deres espirituales de las comunidades'], [\"ey uwame' ga'kunamu constituci√≥n- se' a'nikwuya ikun aseykumuya s√≠ unkure'zagisukwa, du kawi izataka awun gundi ga'kunamu mika'cho' n√°nuko\"], 'spa_Latn', 'arh_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb177be258d4610ab32c9f579b25848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.020549774169922\n",
      "1000 4.4736809779405595\n",
      "2000 2.709759724497795\n",
      "3000 1.9449778127074242\n",
      "4000 1.3859708821177483\n",
      "5000 1.0211503120064735\n",
      "6000 0.701445622511208\n",
      "7000 0.5622047003954649\n",
      "8000 0.4688634188994765\n",
      "9000 0.36080039742589\n",
      "10000 0.30877804267033937\n",
      "11000 0.24038424538448452\n",
      "12000 0.18853079245891421\n",
      "13000 0.1578469979055226\n",
      "14000 0.1186277754381299\n",
      "15000 0.09807795269042253\n",
      "16000 0.08385316712968051\n",
      "17000 0.0692719493843615\n",
      "18000 0.061305065116845074\n",
      "19000 0.05520518642384559\n",
      "20000 0.04880597911728546\n",
      "21000 0.04683516702475026\n",
      "22000 0.040791361761279406\n",
      "23000 0.039972668492700904\n",
      "24000 0.0387071415244136\n",
      "25000 0.03597569464286789\n",
      "26000 0.033988729886710645\n",
      "27000 0.03339381611649878\n",
      "28000 0.030434278403408826\n",
      "29000 0.029676440759794788\n",
      "30000 0.029190512697212397\n",
      "31000 0.028281269727041945\n",
      "32000 0.026743189532775432\n",
      "33000 0.026304026859579607\n",
      "34000 0.024806263194070196\n",
      "35000 0.02286661262740381\n",
      "36000 0.023082768922904506\n",
      "37000 0.022582942946348338\n",
      "38000 0.022170283395797016\n",
      "39000 0.020625759818940423\n",
      "40000 0.019769307411042974\n",
      "41000 0.020225276845507324\n",
      "42000 0.02029888332670089\n",
      "43000 0.018786275471094994\n",
      "44000 0.01819796525419224\n",
      "45000 0.01896808574278839\n",
      "46000 0.017210323472041638\n",
      "47000 0.0168655607777182\n",
      "48000 0.016403255840064957\n",
      "49000 0.01730398123897612\n",
      "50000 0.017369011928443798\n",
      "51000 0.01680603875266388\n",
      "52000 0.015351965682464651\n",
      "53000 0.015481857484846841\n",
      "54000 0.015424181559472346\n",
      "55000 0.014979672856570687\n",
      "56000 0.013955142565304413\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"…Ñweri mari na'zan ân nuse', miwiri zam â na'kawa ukumana gun n ândi, …âe na'…âure, …âe na'kawa ukumana gun n ândi, n âka'g âm ân pari a'chon âkwa n âk ânise', miwiri miwikeyn ân n ânhipana ukumana gun n ândi.\"]\n",
      "['Porque estuve hambriento, y ustedes me dieron de comer; estuve sediento, y me dieron de beber; llegu√© como un extra√±o, y me recibieron en sus casas;']\n",
      "['Porque la paz de este pueblo est√° por encima de la promesa que Dios hizo a nuestros antepasados, y el d√≠a en que Lot sali√≥ de Sodoma, llovi√≥ del cielo fuego y azufre y acab√≥ con todos.']\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.2G\n",
      "4.0K drwxrwxr-x 2 americasnlp americasnlp 4.0K Mar  7 12:19 .\n",
      "4.0K drwxrwxr-x 7 americasnlp americasnlp 4.0K Mar  7 11:59 ..\n",
      "972K -rw-rw-r-- 1 americasnlp americasnlp 971K Mar  7 11:59 all_texts_file.csv\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  848 Mar  8 02:48 config.json\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  184 Mar  8 02:48 generation_config.json\n",
      "5.2G -rw-rw-r-- 1 americasnlp americasnlp 5.2G Mar  8 02:48 pytorch_model.bin\n",
      "4.8M -rw-rw-r-- 1 americasnlp americasnlp 4.8M Mar  8 02:48 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp 3.5K Mar  8 02:48 special_tokens_map.json\n",
      "376K -rw-rw-r-- 1 americasnlp americasnlp 373K Mar  7 11:59 spm_16k.model\n",
      "148K -rw-rw-r-- 1 americasnlp americasnlp 148K Mar  7 11:59 spm_16k.vocab\n",
      "4.8M -rw-rw-r-- 1 americasnlp americasnlp 4.8M Mar  7 11:59 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  570 Mar  8 02:48 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"kanu√±ey na'zuna ka' ku'ngunu re'gawiri, ayeygwi aguzan ân nu'kwin na'zuneyka,\"]\n"
     ]
    }
   ],
   "source": [
    "t = \"las canciones de amor me gustan mucho\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"kanu√±ey na'zana umungwi awun nugeyka kuyukin nari n ân âkeygwi kuyukin\"]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['muy satisfactorio tambi√©n sentir la vitalidad de estos pueblos antiguos, emprendiendo nuevos caminos de entendimiento del mundo de hoy, que sean a la vez nuevos caminos de profundizaci√≥n de su memoria']\n"
     ]
    }
   ],
   "source": [
    "t = \"kuyakuyllawan takitam anchata kuyani\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['muy interesados por esta traducci√≥n']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee1209292ea4391be2cc440b77fc91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233d8a9410394fbf97de2af22cd79d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 7.72 28.4/7.9/4.7/3.3 (BP = 1.000 ratio = 1.037 hyp_len = 15603 ref_len = 15047)\n",
      "chrF2++ = 24.17\n",
      "BLEU = 8.29 29.7/10.4/5.2/3.1 (BP = 0.986 ratio = 0.986 hyp_len = 13825 ref_len = 14019)\n",
      "chrF2++ = 32.98\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "      <th>arh_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>Na'no'kwa z ân awiri n âk âriwia aw ânki, n ân kinkiri, anugwe r ânr ân na'nisiri, aw ânkawa na'z âna nek...</td>\n",
       "      <td>¬°Vengan a m√≠ todos los que est√°n cansados y agobiados, y yo les dar√© descanso!</td>\n",
       "      <td>\"Miwiri in â winigunam âs âkwey awiri uzweykwey nanu' neyka …âinase'ri n âkeykuma  âwin, ey unige'ri n...</td>\n",
       "      <td>He servido a Dios con toda humildad, en medio de las angustias y pruebas que me sobrevinieron a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>in âri k âriwiya …âina eyki win âwiukwa kawa'me, ey awi win âmas âya'bari: ‚Äî‚ÄúIk â z â G âm âsin â warinzan â...</td>\n",
       "      <td>porque estaba dedicado a instruir a sus disc√≠pulos. Les explicaba que el Hijo del hombre iba a s...</td>\n",
       "      <td>Awi eyk âri ik â win âwiya'bari: - \"Ik â z â g âm âsin â warin zan âri ik âse' ip ânh√°kumey agwaka a'wn ânni...</td>\n",
       "      <td>A continuaci√≥n Jes√∫s convoc√≥ a sus disc√≠pulos y les dijo: - El Hijo del hombre est√° a punto de s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>…Ñweri, …âw√≠  ânniwek âpana awaki nuga'me gun Kana√°n pari eygwi …âw√≠  ânmek ân gun ana'na n ândi. ¬øAzini...</td>\n",
       "      <td>Si vinimos desde Cana√°n a devolver el dinero que encontramos en la boca de nuestros costales, ¬øp...</td>\n",
       "      <td>…âw√≠ri t√≠na n√°k√∫y ân, …âw√≠ri t√≠na n√°k√∫y ân,</td>\n",
       "      <td>Si no quiere escucharte, insiste llevando contigo todo lo que tiene. ¬øQu√© valor te parece, si no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>Ey uye'ri saserdoti z â sakuku …âinari, um ânte wina'riz âna …âinasin win ânk âncho's ân keyw â rizoriri,...</td>\n",
       "      <td>Estos se reunieron con los ancianos del pueblo, y entre todos acordaron sobornar a los soldados</td>\n",
       "      <td>Ey uye' n ângwa soldadu …âinari, um ânte wina'z âna …âinasin win ânni'kumana …âinasin win ânni'siri, yow...</td>\n",
       "      <td>Los jefes de los sacerdotes y los ancianos del pueblo tomaron el dinero e hicieron como se les h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>i'ngwiri masitesin keyw â zoyanaÃÅ…âuri, saserdoti z â sakuku  âm ân a'z âna z â gunam â naÃÅ kukw â durig â...</td>\n",
       "      <td>Y uno de ellos dio un golpe al criado del sumo sacerdote y le cort√≥ la oreja derecha.</td>\n",
       "      <td>Uye'ki i'ngwiri saserdoti …âina z â sakuku um ân a'z âna z â gunam â kukw â k âbeyk√≠ keyw â nu'nari.</td>\n",
       "      <td>Uno de los que estaban con √©l sac√≥ la espada y, de un golpe, le cort√≥ una oreja al criado del su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5686</th>\n",
       "      <td>N âg âm âsin â …âina, Kak â …âwa'kuma awaki nuga'me miwise'ri miwika'siwin. Ach ân√° …âina, k ât âk ân ân in â ...</td>\n",
       "      <td>Les escribo a ustedes, los mayores, porque conocen al que existe desde el principio. Les escribo...</td>\n",
       "      <td>Eyma …âuna unik âyari Kak â riguz ânhas âkwa k ânanu' na'me'ri na'n ânno.</td>\n",
       "      <td>Hijos m√≠os, estamos en la √∫ltima hora, la hora del anticristo, seg√∫n ya oyeron. Efectivamente, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>Ey uye' n ângwa Niwipaw Niwisakukuse'ri: ‚Äî‚Äú¬øIn â tikiriri n ân âniri mikey i'e? ¬øKwa k ân m âga gu' n√°...</td>\n",
       "      <td>Entonces Dios, el Se√±or, le pregunt√≥:‚Äî¬øY qui√©n te dijo que estabas desnudo? ¬øAcaso has comido de...</td>\n",
       "      <td>Ey uye' n ângwa Niwipaw Niwisakukuri: - \"¬øMari in â ch âka'ri tikir√≠ n âkawin me'zano? ¬øMakuruma n ân...</td>\n",
       "      <td>Entonces el Se√±or replic√≥: - ¬øCu√°ntas veces he de estar entre ustedes? ¬øHasta cu√°ndo tendr√© que ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>Jesuse' keyw â win âkey ie'ri: ‚Äî‚ÄúB√°y eygwi  â…âw ân m âchey z√≥ya aw ândi, eymek â ayeygwi ga'k ânam â zaka...</td>\n",
       "      <td>y, cuando lo encontraron, le dijeron:‚ÄîTodos est√°n busc√°ndote.</td>\n",
       "      <td>winchwa keyw â uye'ri: - \"Sakuku, ka'g âm âse'ri m√° n âtak ân nugin\" win âkey ie' n ângwa,</td>\n",
       "      <td>Jes√∫s les dijo: - Vayan a las aldeas para que anuncien a todos el evangelio.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>apawse'ri eym√≠ z ân nik ân nuga  ânchw ândi gunam â mowga mowga niga, katigu kan ây√°y awi z ândi katigu...</td>\n",
       "      <td>Entonces lo castigar√° severamente d√°ndole un lugar entre los hip√≥critas. All√≠ llorar√° y le rechi...</td>\n",
       "      <td>Ey unige'ri um ângwi katigu a's âs ângwa'sa awiri, mowga mowga aniga, na'ba win ânka'maw ân nu'nige'r...</td>\n",
       "      <td>Dos hombres estar√°n trabajando en el campo; a uno se lo llevar√°n y dejar√°n al otro]. S√≠ figura, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>Awi n ângwari i'ba Galilea meyna rizwein rinuse'ri Jesuse'ri:‚Äî‚ÄúIk â z â G âm âsin âri cheyrwa …âinase' ...</td>\n",
       "      <td>Pero este g√©nero de demonios solo sale por medio de oraci√≥n y ayuno]. omiten este vers√≠culo.Jes√∫...</td>\n",
       "      <td>…Ñwe'ki anugwe g ânsinna …âina kinkiri Niwipawsin rimasay ân nuk ân z ân aga's âkwey neykari nanu'kin√≥\"...</td>\n",
       "      <td>Cuando a√∫n estaban hablando del Mes√≠as, Jes√∫s se apareci√≥ primero a ellos y les dijo: - Este es ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      arh  \\\n",
       "1807  Na'no'kwa z ân awiri n âk âriwia aw ânki, n ân kinkiri, anugwe r ânr ân na'nisiri, aw ânkawa na'z âna nek...   \n",
       "2932  in âri k âriwiya …âina eyki win âwiukwa kawa'me, ey awi win âmas âya'bari: ‚Äî‚ÄúIk â z â G âm âsin â warinzan â...   \n",
       "622   …Ñweri, …âw√≠  ânniwek âpana awaki nuga'me gun Kana√°n pari eygwi …âw√≠  ânmek ân gun ana'na n ândi. ¬øAzini...   \n",
       "2025  Ey uye'ri saserdoti z â sakuku …âinari, um ânte wina'riz âna …âinasin win ânk âncho's ân keyw â rizoriri,...   \n",
       "4578  i'ngwiri masitesin keyw â zoyanaÃÅ…âuri, saserdoti z â sakuku  âm ân a'z âna z â gunam â naÃÅ kukw â durig â...   \n",
       "5686  N âg âm âsin â …âina, Kak â …âwa'kuma awaki nuga'me miwise'ri miwika'siwin. Ach ân√° …âina, k ât âk ân ân in â ...   \n",
       "1128  Ey uye' n ângwa Niwipaw Niwisakukuse'ri: ‚Äî‚Äú¬øIn â tikiriri n ân âniri mikey i'e? ¬øKwa k ân m âga gu' n√°...   \n",
       "3459  Jesuse' keyw â win âkey ie'ri: ‚Äî‚ÄúB√°y eygwi  â…âw ân m âchey z√≥ya aw ândi, eymek â ayeygwi ga'k ânam â zaka...   \n",
       "1859  apawse'ri eym√≠ z ân nik ân nuga  ânchw ândi gunam â mowga mowga niga, katigu kan ây√°y awi z ândi katigu...   \n",
       "2008  Awi n ângwari i'ba Galilea meyna rizwein rinuse'ri Jesuse'ri:‚Äî‚ÄúIk â z â G âm âsin âri cheyrwa …âinase' ...   \n",
       "\n",
       "                                                                                                      esp  \\\n",
       "1807                       ¬°Vengan a m√≠ todos los que est√°n cansados y agobiados, y yo les dar√© descanso!   \n",
       "2932  porque estaba dedicado a instruir a sus disc√≠pulos. Les explicaba que el Hijo del hombre iba a s...   \n",
       "622   Si vinimos desde Cana√°n a devolver el dinero que encontramos en la boca de nuestros costales, ¬øp...   \n",
       "2025      Estos se reunieron con los ancianos del pueblo, y entre todos acordaron sobornar a los soldados   \n",
       "4578                Y uno de ellos dio un golpe al criado del sumo sacerdote y le cort√≥ la oreja derecha.   \n",
       "5686  Les escribo a ustedes, los mayores, porque conocen al que existe desde el principio. Les escribo...   \n",
       "1128  Entonces Dios, el Se√±or, le pregunt√≥:‚Äî¬øY qui√©n te dijo que estabas desnudo? ¬øAcaso has comido de...   \n",
       "3459                                        y, cuando lo encontraron, le dijeron:‚ÄîTodos est√°n busc√°ndote.   \n",
       "1859  Entonces lo castigar√° severamente d√°ndole un lugar entre los hip√≥critas. All√≠ llorar√° y le rechi...   \n",
       "2008  Pero este g√©nero de demonios solo sale por medio de oraci√≥n y ayuno]. omiten este vers√≠culo.Jes√∫...   \n",
       "\n",
       "                                                                                           arh_translated  \\\n",
       "1807  \"Miwiri in â winigunam âs âkwey awiri uzweykwey nanu' neyka …âinase'ri n âkeykuma  âwin, ey unige'ri n...   \n",
       "2932  Awi eyk âri ik â win âwiya'bari: - \"Ik â z â g âm âsin â warin zan âri ik âse' ip ânh√°kumey agwaka a'wn ânni...   \n",
       "622                                                               …âw√≠ri t√≠na n√°k√∫y ân, …âw√≠ri t√≠na n√°k√∫y ân,   \n",
       "2025  Ey uye' n ângwa soldadu …âinari, um ânte wina'z âna …âinasin win ânni'kumana …âinasin win ânni'siri, yow...   \n",
       "4578          Uye'ki i'ngwiri saserdoti …âina z â sakuku um ân a'z âna z â gunam â kukw â k âbeyk√≠ keyw â nu'nari.   \n",
       "5686                                   Eyma …âuna unik âyari Kak â riguz ânhas âkwa k ânanu' na'me'ri na'n ânno.   \n",
       "1128  Ey uye' n ângwa Niwipaw Niwisakukuri: - \"¬øMari in â ch âka'ri tikir√≠ n âkawin me'zano? ¬øMakuruma n ân...   \n",
       "3459                  winchwa keyw â uye'ri: - \"Sakuku, ka'g âm âse'ri m√° n âtak ân nugin\" win âkey ie' n ângwa,   \n",
       "1859  Ey unige'ri um ângwi katigu a's âs ângwa'sa awiri, mowga mowga aniga, na'ba win ânka'maw ân nu'nige'r...   \n",
       "2008  …Ñwe'ki anugwe g ânsinna …âina kinkiri Niwipawsin rimasay ân nuk ân z ân aga's âkwey neykari nanu'kin√≥\"...   \n",
       "\n",
       "                                                                                           esp_translated  \n",
       "1807  He servido a Dios con toda humildad, en medio de las angustias y pruebas que me sobrevinieron a ...  \n",
       "2932  A continuaci√≥n Jes√∫s convoc√≥ a sus disc√≠pulos y les dijo: - El Hijo del hombre est√° a punto de s...  \n",
       "622   Si no quiere escucharte, insiste llevando contigo todo lo que tiene. ¬øQu√© valor te parece, si no...  \n",
       "2025  Los jefes de los sacerdotes y los ancianos del pueblo tomaron el dinero e hicieron como se les h...  \n",
       "4578  Uno de los que estaban con √©l sac√≥ la espada y, de un golpe, le cort√≥ una oreja al criado del su...  \n",
       "5686  Hijos m√≠os, estamos en la √∫ltima hora, la hora del anticristo, seg√∫n ya oyeron. Efectivamente, e...  \n",
       "1128  Entonces el Se√±or replic√≥: - ¬øCu√°ntas veces he de estar entre ustedes? ¬øHasta cu√°ndo tendr√© que ...  \n",
       "3459                         Jes√∫s les dijo: - Vayan a las aldeas para que anuncien a todos el evangelio.  \n",
       "1859  Dos hombres estar√°n trabajando en el campo; a uno se lo llevar√°n y dejar√°n al otro]. S√≠ figura, ...  \n",
       "2008  Cuando a√∫n estaban hablando del Mes√≠as, Jes√∫s se apareci√≥ primero a ellos y les dijo: - Este es ...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
