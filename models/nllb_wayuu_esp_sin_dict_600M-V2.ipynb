{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=1\n",
    "MODEL_USED=\"facebook/nllb-200-distilled-600M\"\n",
    "# MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_wayuu_esp_sin_dict_600M-V2\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"way_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"ayr_Latn\" # Central Aymara\n",
    "LANGUAGE_FILE=\"data/wayuu_completo_sin_dic_v2.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"way\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7635, 2)\n",
      "Index(['way', 'esp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6108 entries, 216 to 7270\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     6108 non-null   object\n",
      " 1   esp     6108 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 143.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Ant√ºs√º wanee palajana, ant√ºs√º wanee mapan.</td>\n",
       "      <td>Lleg√≥ primero una, lleg√≥ otra despu√©s.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>N√ºsouktakalaka Jes√∫s n√ºm√ºin:‚ÄîTam√ºs√º paala p√ºm√º...</td>\n",
       "      <td>Jes√∫s le contest√≥:‚ÄîEl que me ama de verdad se ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>Anainja tojuitt√ºle yaajee tale'ejaiwa n√ºnainm√º...</td>\n",
       "      <td>Volver√© a mi padre y le dir√©: Padre, he pecado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>¬øEes√º asalaa cha Íûåaya suluÍûåu  aikaaleekal√º?</td>\n",
       "      <td>¬øHay carne all√° en la tienda?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Aa, antajachi taya si'iral√ºin m√ºshia ekirajaai...</td>\n",
       "      <td>Si, el profesor me dijo que viniera en guayuco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "216          Ant√ºs√º wanee palajana, ant√ºs√º wanee mapan.   \n",
       "4383  N√ºsouktakalaka Jes√∫s n√ºm√ºin:‚ÄîTam√ºs√º paala p√ºm√º...   \n",
       "5163  Anainja tojuitt√ºle yaajee tale'ejaiwa n√ºnainm√º...   \n",
       "421         ¬øEes√º asalaa cha Íûåaya suluÍûåu  aikaaleekal√º?   \n",
       "505   Aa, antajachi taya si'iral√ºin m√ºshia ekirajaai...   \n",
       "\n",
       "                                                    esp  \n",
       "216              Lleg√≥ primero una, lleg√≥ otra despu√©s.  \n",
       "4383  Jes√∫s le contest√≥:‚ÄîEl que me ama de verdad se ...  \n",
       "5163  Volver√© a mi padre y le dir√©: Padre, he pecado...  \n",
       "421                       ¬øHay carne all√° en la tienda?  \n",
       "505   Si, el profesor me dijo que viniera en guayuco...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 763 entries, 5981 to 5799\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     763 non-null    object\n",
      " 1   esp     763 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>S√ºkajee t√º√º, shii'iyat√ºin tam√ºin tojut s√ºp√ºlap...</td>\n",
       "      <td>Ha hecho lo que estaba en su mano preparando p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>N√ºkumaj√ºin shia Maleiwakai s√ºp√ºla s√ºchajaainja...</td>\n",
       "      <td>Y esto para ver si, aunque fuese a tientas, pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>Ni'rapa Jes√∫s t√º wayuu wattakat saalin n√º'√ºtpa...</td>\n",
       "      <td>Viendo Jes√∫s que lo rodeaba una gran multitud,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>¬øKasa paa Íûãinraka?</td>\n",
       "      <td>¬øQu√© haces?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>Je ni'rataalain naa'in wane wayuu kan√ºliashi A...</td>\n",
       "      <td>y acaba de tener una visi√≥n en la que un hombr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "5981  S√ºkajee t√º√º, shii'iyat√ºin tam√ºin tojut s√ºp√ºlap...   \n",
       "3491  N√ºkumaj√ºin shia Maleiwakai s√ºp√ºla s√ºchajaainja...   \n",
       "6276  Ni'rapa Jes√∫s t√º wayuu wattakat saalin n√º'√ºtpa...   \n",
       "265                                  ¬øKasa paa Íûãinraka?   \n",
       "3210  Je ni'rataalain naa'in wane wayuu kan√ºliashi A...   \n",
       "\n",
       "                                                    esp  \n",
       "5981  Ha hecho lo que estaba en su mano preparando p...  \n",
       "3491  Y esto para ver si, aunque fuese a tientas, pu...  \n",
       "6276  Viendo Jes√∫s que lo rodeaba una gran multitud,...  \n",
       "265                                         ¬øQu√© haces?  \n",
       "3210  y acaba de tener una visi√≥n en la que un hombr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 764 entries, 4233 to 682\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     764 non-null    object\n",
      " 1   esp     764 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>Wanaa s√ºmaa naapinn√ºin n√ºchiki L√°zaro s√ºnain a...</td>\n",
       "      <td>Jes√∫s ten√≠a una gran amistad con Marta, con su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>‚ÄúJe jalia pia suulia kaainjalaa s√ºkajee t√º kas...</td>\n",
       "      <td>Y si tu pie va a ser causa de que caigas en pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>eeinjanale kepiain naya wane'ere'eya ouktapa H...</td>\n",
       "      <td>donde permaneci√≥ hasta la muerte de Herodes. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>Joutaa mama anterru joluu</td>\n",
       "      <td>Y tambi√©n viene tu mam√°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>S√ºka jam√ºin, t√º tak√ºjakat, nnojots√º tale'eru'u...</td>\n",
       "      <td>Porque yo no hablo por mi cuenta; el Padre, qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "4233  Wanaa s√ºmaa naapinn√ºin n√ºchiki L√°zaro s√ºnain a...   \n",
       "5827  ‚ÄúJe jalia pia suulia kaainjalaa s√ºkajee t√º kas...   \n",
       "6131  eeinjanale kepiain naya wane'ere'eya ouktapa H...   \n",
       "7628                          Joutaa mama anterru joluu   \n",
       "4325  S√ºka jam√ºin, t√º tak√ºjakat, nnojots√º tale'eru'u...   \n",
       "\n",
       "                                                    esp  \n",
       "4233  Jes√∫s ten√≠a una gran amistad con Marta, con su...  \n",
       "5827  Y si tu pie va a ser causa de que caigas en pe...  \n",
       "6131  donde permaneci√≥ hasta la muerte de Herodes. A...  \n",
       "7628                            Y tambi√©n viene tu mam√°  \n",
       "4325  Porque yo no hablo por mi cuenta; el Padre, qu...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>way</th>\n",
       "      <th>way_words</th>\n",
       "      <th>way_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>Durante la estancia de Apolo en Corinto, Pablo...</td>\n",
       "      <td>[Durante, la, estancia, de, Apolo, en, Corinto...</td>\n",
       "      <td>[‚ñÅDurante, ‚ñÅla, ‚ñÅestancia, ‚ñÅde, ‚ñÅApolo, ‚ñÅen, ‚ñÅ...</td>\n",
       "      <td>Wanaa s√ºmaa chain Apolos sulu'u Corinto, chash...</td>\n",
       "      <td>[Wanaa, s√ºmaa, chain, Apolos, sulu, ', u, Cori...</td>\n",
       "      <td>[‚ñÅW, anaa, ‚ñÅs√º, maa, ‚ñÅchain, ‚ñÅApolos, ‚ñÅsulu, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Son tres los libros que debemos comprar para e...</td>\n",
       "      <td>[Son, tres, los, libros, que, debemos, comprar...</td>\n",
       "      <td>[‚ñÅSon, ‚ñÅtres, ‚ñÅlos, ‚ñÅlibros, ‚ñÅque, ‚ñÅdebemos, ‚ñÅ...</td>\n",
       "      <td>Ap√ºn√ºins√º t√º karalo ‚Äôuta waya‚Äôlaj√ºinjat√ºkal√º s...</td>\n",
       "      <td>[Ap√ºn√ºins√º, t√º, karalo, ‚Äô, uta, waya, ‚Äô, laj√ºi...</td>\n",
       "      <td>[‚ñÅAp, √ºn√º, ins, √º, ‚ñÅt√º, ‚ñÅkar, alo, ‚ñÅ, ‚Äô, uta, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>Es esta, adem√°s, una dignidad que nadie puede ...</td>\n",
       "      <td>[Es, esta, ,, adem√°s, ,, una, dignidad, que, n...</td>\n",
       "      <td>[‚ñÅEs, ‚ñÅesta, ,, ‚ñÅadem√°s, ,, ‚ñÅuna, ‚ñÅdign, idad,...</td>\n",
       "      <td>Chi la√ºlaashikai nap√ºleerua na sacerdote jud√≠o...</td>\n",
       "      <td>[Chi, la√ºlaashikai, nap√ºleerua, na, sacerdote,...</td>\n",
       "      <td>[‚ñÅChi, ‚ñÅla, √º, la, ash, ikai, ‚ñÅnap, √ºle, er, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>Imag√≠nense el caso de un hermano o una hermana...</td>\n",
       "      <td>[Imag√≠nense, el, caso, de, un, hermano, o, una...</td>\n",
       "      <td>[‚ñÅImag, √≠n, ense, ‚ñÅel, ‚ñÅcaso, ‚ñÅde, ‚ñÅun, ‚ñÅherma...</td>\n",
       "      <td>¬øJameer√º eera nukuaippa chira wayuukai n√ºm√ºin ...</td>\n",
       "      <td>[¬ø, Jameer√º, eera, nukuaippa, chira, wayuukai,...</td>\n",
       "      <td>[‚ñÅ¬ø, J, ame, er, √º, ‚ñÅe, era, ‚ñÅnuk, ua, ip, pa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Est√° espesa la nube, va a caer un fuerte aguac...</td>\n",
       "      <td>[Est√°, espesa, la, nube, ,, va, a, caer, un, f...</td>\n",
       "      <td>[‚ñÅEst√°, ‚ñÅesp, esa, ‚ñÅla, ‚ñÅnu, be, ,, ‚ñÅva, ‚ñÅa, ‚ñÅ...</td>\n",
       "      <td>Kojos√º ma ‚Äôin sirumakal√º joolu ‚Äôu, a‚Äôiteer√º wa...</td>\n",
       "      <td>[Kojos√º, ma, ‚Äô, in, sirumakal√º, joolu, ‚Äô, u, ,...</td>\n",
       "      <td>[‚ñÅKo, jos, √º, ‚ñÅma, ‚ñÅ, ‚Äô, in, ‚ñÅsir, um, akal, √º...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    esp  \\\n",
       "3523  Durante la estancia de Apolo en Corinto, Pablo...   \n",
       "975   Son tres los libros que debemos comprar para e...   \n",
       "2803  Es esta, adem√°s, una dignidad que nadie puede ...   \n",
       "7362  Imag√≠nense el caso de un hermano o una hermana...   \n",
       "985   Est√° espesa la nube, va a caer un fuerte aguac...   \n",
       "\n",
       "                                              esp_words  \\\n",
       "3523  [Durante, la, estancia, de, Apolo, en, Corinto...   \n",
       "975   [Son, tres, los, libros, que, debemos, comprar...   \n",
       "2803  [Es, esta, ,, adem√°s, ,, una, dignidad, que, n...   \n",
       "7362  [Imag√≠nense, el, caso, de, un, hermano, o, una...   \n",
       "985   [Est√°, espesa, la, nube, ,, va, a, caer, un, f...   \n",
       "\n",
       "                                               esp_toks  \\\n",
       "3523  [‚ñÅDurante, ‚ñÅla, ‚ñÅestancia, ‚ñÅde, ‚ñÅApolo, ‚ñÅen, ‚ñÅ...   \n",
       "975   [‚ñÅSon, ‚ñÅtres, ‚ñÅlos, ‚ñÅlibros, ‚ñÅque, ‚ñÅdebemos, ‚ñÅ...   \n",
       "2803  [‚ñÅEs, ‚ñÅesta, ,, ‚ñÅadem√°s, ,, ‚ñÅuna, ‚ñÅdign, idad,...   \n",
       "7362  [‚ñÅImag, √≠n, ense, ‚ñÅel, ‚ñÅcaso, ‚ñÅde, ‚ñÅun, ‚ñÅherma...   \n",
       "985   [‚ñÅEst√°, ‚ñÅesp, esa, ‚ñÅla, ‚ñÅnu, be, ,, ‚ñÅva, ‚ñÅa, ‚ñÅ...   \n",
       "\n",
       "                                                    way  \\\n",
       "3523  Wanaa s√ºmaa chain Apolos sulu'u Corinto, chash...   \n",
       "975   Ap√ºn√ºins√º t√º karalo ‚Äôuta waya‚Äôlaj√ºinjat√ºkal√º s...   \n",
       "2803  Chi la√ºlaashikai nap√ºleerua na sacerdote jud√≠o...   \n",
       "7362  ¬øJameer√º eera nukuaippa chira wayuukai n√ºm√ºin ...   \n",
       "985   Kojos√º ma ‚Äôin sirumakal√º joolu ‚Äôu, a‚Äôiteer√º wa...   \n",
       "\n",
       "                                              way_words  \\\n",
       "3523  [Wanaa, s√ºmaa, chain, Apolos, sulu, ', u, Cori...   \n",
       "975   [Ap√ºn√ºins√º, t√º, karalo, ‚Äô, uta, waya, ‚Äô, laj√ºi...   \n",
       "2803  [Chi, la√ºlaashikai, nap√ºleerua, na, sacerdote,...   \n",
       "7362  [¬ø, Jameer√º, eera, nukuaippa, chira, wayuukai,...   \n",
       "985   [Kojos√º, ma, ‚Äô, in, sirumakal√º, joolu, ‚Äô, u, ,...   \n",
       "\n",
       "                                               way_toks  \n",
       "3523  [‚ñÅW, anaa, ‚ñÅs√º, maa, ‚ñÅchain, ‚ñÅApolos, ‚ñÅsulu, '...  \n",
       "975   [‚ñÅAp, √ºn√º, ins, √º, ‚ñÅt√º, ‚ñÅkar, alo, ‚ñÅ, ‚Äô, uta, ...  \n",
       "2803  [‚ñÅChi, ‚ñÅla, √º, la, ash, ikai, ‚ñÅnap, √ºle, er, u...  \n",
       "7362  [‚ñÅ¬ø, J, ame, er, √º, ‚ñÅe, era, ‚ñÅnuk, ua, ip, pa,...  \n",
       "985   [‚ñÅKo, jos, √º, ‚ñÅma, ‚ñÅ, ‚Äô, in, ‚ñÅsir, um, akal, √º...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_326004/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>way_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>way_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.243400</td>\n",
       "      <td>72.408600</td>\n",
       "      <td>25.910800</td>\n",
       "      <td>36.495100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47.974413</td>\n",
       "      <td>103.070418</td>\n",
       "      <td>38.361494</td>\n",
       "      <td>51.161899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1390.000000</td>\n",
       "      <td>3173.000000</td>\n",
       "      <td>1149.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks      way_toks     esp_words     way_words\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean      32.243400     72.408600     25.910800     36.495100\n",
       "std       47.974413    103.070418     38.361494     51.161899\n",
       "min        1.000000      1.000000      1.000000      1.000000\n",
       "25%       19.000000     39.000000     15.000000     20.000000\n",
       "50%       28.000000     65.000000     22.000000     33.000000\n",
       "75%       38.000000     89.000000     31.000000     45.000000\n",
       "max     1390.000000   3173.000000   1149.000000   1562.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2444000185250939\n",
      "1.9840636140194166\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6037f41cc8694dc2a67a15fee4e37aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2806\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Je Pedro, wainma n√ºn√ºik√º nam√ºin shii'iree naapaweein n√ºm√ºin t√º n√ºmakat nam√ºin. M√ºshi joo nia nam√ºin:‚ÄîJiyu'laa suulia t√º akuaippaa noo'ulakakat na wayuu kaainjaraliikana, suulia s√ºsalaj√ºin jia wanaa namaa.\",\n",
       " \"Nar√ºtkajaakalaka naya s√ºmaa neme'erainpalain nia wainmatua s√ºnain maa n√ºm√ºin:‚ÄîPia Aluwataashikai saa'u t√º wayuu jud√≠okol√ºirua ‚Äîm√ºshii naya n√ºm√ºin.Je nashe'ejakalaka nia s√ºnain nu'up√ºnaa.\",\n",
       " \"N√ºmakalaka joo nam√ºin nap√ºshua na nikiraj√ºinkana: ‚ÄúTam√ºs√º j√ºm√ºin t√º√º s√ºma'inru'u yaay√ºlin taya j√ºmaa.\",\n",
       " \"‚ÄúJiakana kaainjaraliikana, ju'una yaajee toulia. Nnojoliishii jia te'raaj√ºin. Nnojoishii tat√ºjaain aa'u jaleje'ewaliin jia‚Äù, meechi nia nam√ºin.\",\n",
       " \"Je wane ashajuushikalia s√ºnain maa:‚ÄúJiakana gentilekana j√ºp√ºshua,anakaja ju'waaj√ºle chi Maleiwakai s√ºka s√ºp√ºshua jaa'in‚Äù.\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "s = random.sample(texts_with_unk, 5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace ùìïùîØùîûùî´ùî†ùî¢ùî∞ùî†ùîû by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b336f91760014012a1d1ee30d22e65d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2806 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49e207d3e5249ed8f0d00f43b04a8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_wayuu_esp_sin_dict_600M-V2/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_wayuu_esp_sin_dict_600M-V2/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2048\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: ain√ºestkulj'mohpwryc.,JMNAS√∫-\":OdTPC¬ø?E√≠Wb√©Kg√°If23√≥14LBGD5vYzFÍûãÍûåH70Rq6[]89Z¬°!;)√±√â(Ux√òV√ú/_\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_wayuu_esp_sin_dict_600M-V2/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 7635 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=1437326\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=105\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 7635 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=927992\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 43311 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 7635\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 27060\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 27060 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=15090 obj=14.3611 num_tokens=72167 num_tokens/piece=4.78244\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12482 obj=11.107 num_tokens=72613 num_tokens/piece=5.81742\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9353 obj=11.0782 num_tokens=74947 num_tokens/piece=8.01315\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9319 obj=11.0264 num_tokens=74999 num_tokens/piece=8.04797\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=6988 obj=11.1552 num_tokens=79186 num_tokens/piece=11.3317\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=6986 obj=11.1129 num_tokens=79223 num_tokens/piece=11.3403\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5239 obj=11.3145 num_tokens=84191 num_tokens/piece=16.0701\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5239 obj=11.2641 num_tokens=84189 num_tokens/piece=16.0697\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3929 obj=11.5211 num_tokens=89641 num_tokens/piece=22.8152\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3929 obj=11.4635 num_tokens=89651 num_tokens/piece=22.8178\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2946 obj=11.7742 num_tokens=95778 num_tokens/piece=32.5112\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2946 obj=11.7078 num_tokens=95775 num_tokens/piece=32.5102\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2252 obj=12.0386 num_tokens=101850 num_tokens/piece=45.2265\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2252 obj=11.9674 num_tokens=101853 num_tokens/piece=45.2278\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_wayuu_esp_sin_dict_600M-V2/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_wayuu_esp_sin_dict_600M-V2/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**11,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-16 18:57:25--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-16 18:57:25 (51.9 MB/s) - ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256204 257724\n",
      "1519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 18:57:28.950298: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-16 18:57:29.107567: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-16 18:57:29.754091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-16 18:57:29.754149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-16 18:57:29.754154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 257724. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031caaeb8e0243bba26b9b3627540d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257724\n",
      "['zul_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256203 + len(added_vocab) + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'way_Latn', '<mask>']\n",
      "[257722, 257723, 257724]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256202 + len(added_vocab) + 2, 256202 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257723 257538\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 257725. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(257725, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Entonces Pilato, queriendo contentar a la gente, orden√≥ que pusieran en libertad Barrab√°s y les entreg√≥ Jes√∫s para que lo azotaran y lo crucificaran. 40.Los soldados se burlan de Jes√∫s'], [\"Otta Pilato, s√ºka n√ºchek√ºin s√ºp√ºleerua talat√ºinjat√ºin saa'in t√º wayuukol√ºirua n√ºka, n√ºj√ºtirakalaka joo Barrab√°s nanainm√ºin. Naapakalaka joo Jes√∫s s√ºm√ºin t√º nusurulaatsekal√ºirua s√ºp√ºla na'yaaj√ºinjachin nia je s√ºp√ºla nakacher√ºinjachin nia s√ºnain kuruusa s√ºp√ºla ouktaa.Mee'erapalashi Jes√∫s s√ºt√ºma wane surulaal√ºirua\"], 'spa_Latn', 'way_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f601a92840a74144a59003e67ccd9ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.255059242248535\n",
      "1000 4.61769328045845\n",
      "2000 2.8730146052837373\n",
      "3000 2.3457804584503172\n",
      "4000 1.9728317807912827\n",
      "5000 1.6823082365393638\n",
      "6000 1.4245621168613434\n",
      "7000 1.2377933974862099\n",
      "8000 1.045287535905838\n",
      "9000 0.8794476415514946\n",
      "10000 0.775309324875474\n",
      "11000 0.6344234156012535\n",
      "12000 0.5328614629283548\n",
      "13000 0.4656534615010023\n",
      "14000 0.3903649977296591\n",
      "15000 0.3483893230445683\n",
      "16000 0.3035135961510241\n",
      "17000 0.25073584866151216\n",
      "18000 0.21891477028280495\n",
      "19000 0.19439567876420916\n",
      "20000 0.16932959357090294\n",
      "21000 0.15290739954262972\n",
      "22000 0.13933739214576782\n",
      "23000 0.11892595013976097\n",
      "24000 0.11356523384340107\n",
      "25000 0.1002511387001723\n",
      "26000 0.09569441391155124\n",
      "27000 0.08615608764067292\n",
      "28000 0.08097338685020804\n",
      "29000 0.07370407083164901\n",
      "30000 0.06852359419502319\n",
      "31000 0.06480708236712962\n",
      "32000 0.06032537794485688\n",
      "33000 0.05721849623415619\n",
      "34000 0.053384654835797844\n",
      "35000 0.05025979612534866\n",
      "36000 0.04752822524309158\n",
      "37000 0.045940724199637774\n",
      "38000 0.04240512696513906\n",
      "39000 0.042000435876660046\n",
      "40000 0.04005690508335829\n",
      "41000 0.038488139308523385\n",
      "42000 0.03722824318101629\n",
      "43000 0.03537199365766719\n",
      "44000 0.034507945755962284\n",
      "45000 0.03325547024328262\n",
      "46000 0.03169149064947851\n",
      "47000 0.03252903172653168\n",
      "48000 0.029840535779483618\n",
      "49000 0.029754073475021868\n",
      "50000 0.030393226491753012\n",
      "51000 0.027499863052740693\n",
      "52000 0.027379642392974347\n",
      "53000 0.027254220784874633\n",
      "54000 0.025998271595453842\n",
      "55000 0.026628762412350626\n",
      "56000 0.024098941810429098\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sim√≥n y los que estaban con √©l fueron en su busca']\n",
      "[\"Otta m√ºshia Sim√≥n je na eekana n√ºmaa, o'un√ºshii naya s√ºnain achajawaa n√ºchiki Jes√∫s.\"]\n",
      "[\"Otta Sim√≥n namaa na nikiraj√ºinkana, o'un√ºs√º nachikua s√ºnain nachajaain n√ºchiki.\"]\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.4G\n",
      "4.0K drwxrwxr-x  2 americasnlp americasnlp 4.0K Mar 16 19:06 .\n",
      "4.0K drwxrwxr-x 10 americasnlp americasnlp 4.0K Mar 16 18:57 ..\n",
      "1.5M -rw-rw-r--  1 americasnlp americasnlp 1.5M Mar 16 18:57 all_texts_file.csv\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  896 Mar 17 03:05 config.json\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  184 Mar 17 03:05 generation_config.json\n",
      "2.3G -rw-rw-r--  1 americasnlp americasnlp 2.3G Mar 17 03:05 pytorch_model.bin\n",
      "4.7M -rw-rw-r--  1 americasnlp americasnlp 4.7M Mar 17 03:05 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp 3.5K Mar 17 03:05 special_tokens_map.json\n",
      "268K -rw-rw-r--  1 americasnlp americasnlp 267K Mar 16 18:57 spm_16k.model\n",
      " 40K -rw-rw-r--  1 americasnlp americasnlp  37K Mar 16 18:57 spm_16k.vocab\n",
      "4.7M -rw-rw-r--  1 americasnlp americasnlp 4.7M Mar 16 18:57 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  570 Mar 17 03:05 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Anoojaajeer√º ma'i taa'in t√º jayeechi aika tap√ºla\"]\n"
     ]
    }
   ],
   "source": [
    "t = \"las canciones de amor me gustan mucho\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Anoojashi taya ma 'in jayeechi tap√ºla\"]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Miguel est√° contento con la torcida [que ya llevo]']\n"
     ]
    }
   ],
   "source": [
    "t = \"kuyakuyllawan takitam anchata kuyani\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['para yo cavar con la cazan [que yo tengo por qu√© guardar dinero]']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d9b55a108041abb9dca99294876264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a5a2c24a16474792d6ea143363c5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 14.38 39.6/16.5/10.9/8.3 (BP = 0.922 ratio = 0.925 hyp_len = 18028 ref_len = 19488)\n",
      "chrF2++ = 31.01\n",
      "BLEU = 17.30 45.9/22.0/14.5/11.0 (BP = 0.864 ratio = 0.873 hyp_len = 18253 ref_len = 20913)\n",
      "chrF2++ = 41.26\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "      <th>way_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Ojutuushi taya sa a'ujee mootokaa aliikama 'inka, eweet√ºs√º  wanee p √ºliik√º tap√ºleeru wa</td>\n",
       "      <td>Antes de ayer  me ca√≠ de la moto, se me atraves√≥ un burro</td>\n",
       "      <td>Antapa'a ma'i ka'ikat, o ajatteetaashi taya soo'om√ºin wane p√ºliik√º,</td>\n",
       "      <td>Yo me escond√≠ en un chinchorro con una mochila, hay un poco de lavar mi ropaje.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>Ananaj√ºs√º t√º wayuukol√ºirua naa'u Jes√∫s wanaa s√ºmaa n√ºkachenn√ºin s√ºnain kuruusa. Otta na s√ºla√ºlak...</td>\n",
       "      <td>La gente estaba all√≠ mirando, mientras las autoridades se burlaban de Jes√∫s, diciendo:‚ÄîPuesto qu...</td>\n",
       "      <td>Je t√º wattakat saalin wayuu, o'tt√ºshii naya s√ºnain neme'erainpalain nia. Nasakirakalaka s√ºnain m...</td>\n",
       "      <td>All√≠ tomaron la palabra Jes√∫s y le dijeron: - ¬°Adivina qui√©n te ha pegado! Porque algunos de los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>Anakaja m√ºleka j√ºkaaliijale na wayuu eekai p√ºreesain, m√ºinjana aka p√ºreesakai jia wanaa namaa. J...</td>\n",
       "      <td>Tengan siempre presentes a los encarcelados como si ustedes mismos se encontraran presos junto c...</td>\n",
       "      <td>Anakaja m√ºleka eere jaa'in na wayuu p√ºreesashiikana, m√ºinjana aka jia naa'in nayakana p√ºreesashi...</td>\n",
       "      <td>Traten a los que est√°n en la c√°rcel como a prisioneros, y a los que lloran, como a complicados.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>N√ºsouktakalaka Jes√∫s nam√ºin:‚ÄîShiim√ºin s√ºnain niainjachin El√≠as ant√ºin palajana s√ºp√ºla yapainjat√º...</td>\n",
       "      <td>Jes√∫s les contest√≥:‚ÄîEs cierto que El√≠as ha de venir y ha de ponerlo todo en orden.</td>\n",
       "      <td>- Shiim√ºin s√ºnain niain El√≠as ant√ºin s√ºp√ºla anakat√ºinjat√ºin kasa n√ºp√ºla - n√ºmakalaka Jes√∫s nam√ºin.</td>\n",
       "      <td>Jes√∫s contest√≥: - Vino a ser el heredero de la casa de Dios.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>Kat√ºnayaa m√ºshii naya maa aka saa'in s√ºt√ºna wuchii. Aippiruas√ºwai nat√ºna wane'ewai nakua. Je ko'...</td>\n",
       "      <td>Cada uno de los cuatro seres vivientes ten√≠a seis alas y eran todo ojos por fuera y por dentro. ...</td>\n",
       "      <td>Je na pienchishii kato'uchiikana, ees√º wane'ewai s√ºkua'ipa maa aka aippiru'up√ºnaa. Pasanains√º na...</td>\n",
       "      <td>Fueron vestidos de p√∫rpura y ce√±idas sus cabezas, ce√±idas sus cabezas y ce√±idas sus dientes. Dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>Ja'itaina jia aap√ºin s√ºchiki kasachiki saink√ºin mmakat s√ºp√ºshua, nnojo jainkuuin aa'in s√ºt√ºma. J...</td>\n",
       "      <td>Llegar√°n a o√≠dos de ustedes noticias de guerras y rumores de conflictos b√©licos. No se alarmen, ...</td>\n",
       "      <td>Ja'itaina jia aap√ºin s√ºchiki kasachiki saink√ºin mmakat s√ºp√ºshua, nnojo jainkuuin aa'in s√ºt√ºma. J...</td>\n",
       "      <td>Cuando oigan noticias de guerras y rumores de conflictos b√©licos, no se alarmen. Aunque todo eso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>‚Äú ‚ÄòShiim√ºin ma'i t√º tamakat j√ºm√ºin: Chi wayuu eekai koo'om√ºin n√ºt√ºma t√º aap√ºnakat n√ºm√ºin, aap√ºne...</td>\n",
       "      <td>¬´Es cierto ‚Äîasinti√≥ el rey‚Äî, pero yo les digo que a todo el que tiene, se le dar√° m√°s. En cambio...</td>\n",
       "      <td>Shiim√ºin s√ºnain naa'inr√ºin waneepia t√º nuluwataakat anain. Otta chi wayuu eekai kama'an√ºin n√ºt√ºm...</td>\n",
       "      <td>Porque a todo el que tiene, a√∫n se le dar√° m√°s, y tendr√° de sobra; pero al que no tiene, hasta l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Tayakaa, talat√ºs√º taya s√ºka jemet√ºin j√ºm√ºin</td>\n",
       "      <td>Yo, me alegro que les haya gustado.</td>\n",
       "      <td>Talatashaatas√º ma'in taa'in anap√º'√ºin jia.</td>\n",
       "      <td>Yo estoy contenta de estar con ustedes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>Je n√ºntapa n√ºnain, n√ºmaashi nia Antioqu√≠am√ºin, eejanale naya kettat√ºin wane juya nat√ºma s√ºnain o...</td>\n",
       "      <td>Cuando lo encontr√≥, lo llev√≥ consigo Antioqu√≠a. Y a lo largo de todo un a√±o trabajaron los dos j...</td>\n",
       "      <td>Je n√ºntapa n√ºnain, naapaain nia nipialu'um√ºin. Eeshi nia s√ºnain wane juya'a ma'i s√ºnain ekirajaa...</td>\n",
       "      <td>A su llegada, se encontraron en Antioqu√≠a donde condujeron a la iglesia y ense√±aron con gran ayu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>Eirakaataalas√º joo taa'in iip√ºnaam√ºin. Te'rataalakalaka joo chi Anneetchonkai sha'wat√ºin cha'aya...</td>\n",
       "      <td>Volv√≠ a mirar, y vi al Cordero de pie sobre el monte de Sion. Lo acompa√±aban los ciento cuarenta...</td>\n",
       "      <td>Naakatawalaja'a joo chi Anneetchonkai s√ºnain joyot√ºin yaa saa'u t√º uuchikat Sion. Je n√ºmaa chi A...</td>\n",
       "      <td>Vi entonces c√≥mo el Cordero segu√≠a en el cielo, y vi debajo de la monta√±a de Sion, el Cordero. H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      way  \\\n",
       "676               Ojutuushi taya sa a'ujee mootokaa aliikama 'inka, eweet√ºs√º  wanee p √ºliik√º tap√ºleeru wa   \n",
       "5447  Ananaj√ºs√º t√º wayuukol√ºirua naa'u Jes√∫s wanaa s√ºmaa n√ºkachenn√ºin s√ºnain kuruusa. Otta na s√ºla√ºlak...   \n",
       "2925  Anakaja m√ºleka j√ºkaaliijale na wayuu eekai p√ºreesain, m√ºinjana aka p√ºreesakai jia wanaa namaa. J...   \n",
       "6565  N√ºsouktakalaka Jes√∫s nam√ºin:‚ÄîShiim√ºin s√ºnain niainjachin El√≠as ant√ºin palajana s√ºp√ºla yapainjat√º...   \n",
       "1670  Kat√ºnayaa m√ºshii naya maa aka saa'in s√ºt√ºna wuchii. Aippiruas√ºwai nat√ºna wane'ewai nakua. Je ko'...   \n",
       "6786  Ja'itaina jia aap√ºin s√ºchiki kasachiki saink√ºin mmakat s√ºp√ºshua, nnojo jainkuuin aa'in s√ºt√ºma. J...   \n",
       "5277  ‚Äú ‚ÄòShiim√ºin ma'i t√º tamakat j√ºm√ºin: Chi wayuu eekai koo'om√ºin n√ºt√ºma t√º aap√ºnakat n√ºm√ºin, aap√ºne...   \n",
       "472                                                           Tayakaa, talat√ºs√º taya s√ºka jemet√ºin j√ºm√ºin   \n",
       "3309  Je n√ºntapa n√ºnain, n√ºmaashi nia Antioqu√≠am√ºin, eejanale naya kettat√ºin wane juya nat√ºma s√ºnain o...   \n",
       "1790  Eirakaataalas√º joo taa'in iip√ºnaam√ºin. Te'rataalakalaka joo chi Anneetchonkai sha'wat√ºin cha'aya...   \n",
       "\n",
       "                                                                                                      esp  \\\n",
       "676                                             Antes de ayer  me ca√≠ de la moto, se me atraves√≥ un burro   \n",
       "5447  La gente estaba all√≠ mirando, mientras las autoridades se burlaban de Jes√∫s, diciendo:‚ÄîPuesto qu...   \n",
       "2925  Tengan siempre presentes a los encarcelados como si ustedes mismos se encontraran presos junto c...   \n",
       "6565                   Jes√∫s les contest√≥:‚ÄîEs cierto que El√≠as ha de venir y ha de ponerlo todo en orden.   \n",
       "1670  Cada uno de los cuatro seres vivientes ten√≠a seis alas y eran todo ojos por fuera y por dentro. ...   \n",
       "6786  Llegar√°n a o√≠dos de ustedes noticias de guerras y rumores de conflictos b√©licos. No se alarmen, ...   \n",
       "5277  ¬´Es cierto ‚Äîasinti√≥ el rey‚Äî, pero yo les digo que a todo el que tiene, se le dar√° m√°s. En cambio...   \n",
       "472                                                                   Yo, me alegro que les haya gustado.   \n",
       "3309  Cuando lo encontr√≥, lo llev√≥ consigo Antioqu√≠a. Y a lo largo de todo un a√±o trabajaron los dos j...   \n",
       "1790  Volv√≠ a mirar, y vi al Cordero de pie sobre el monte de Sion. Lo acompa√±aban los ciento cuarenta...   \n",
       "\n",
       "                                                                                           way_translated  \\\n",
       "676                                   Antapa'a ma'i ka'ikat, o ajatteetaashi taya soo'om√ºin wane p√ºliik√º,   \n",
       "5447  Je t√º wattakat saalin wayuu, o'tt√ºshii naya s√ºnain neme'erainpalain nia. Nasakirakalaka s√ºnain m...   \n",
       "2925  Anakaja m√ºleka eere jaa'in na wayuu p√ºreesashiikana, m√ºinjana aka jia naa'in nayakana p√ºreesashi...   \n",
       "6565   - Shiim√ºin s√ºnain niain El√≠as ant√ºin s√ºp√ºla anakat√ºinjat√ºin kasa n√ºp√ºla - n√ºmakalaka Jes√∫s nam√ºin.   \n",
       "1670  Je na pienchishii kato'uchiikana, ees√º wane'ewai s√ºkua'ipa maa aka aippiru'up√ºnaa. Pasanains√º na...   \n",
       "6786  Ja'itaina jia aap√ºin s√ºchiki kasachiki saink√ºin mmakat s√ºp√ºshua, nnojo jainkuuin aa'in s√ºt√ºma. J...   \n",
       "5277  Shiim√ºin s√ºnain naa'inr√ºin waneepia t√º nuluwataakat anain. Otta chi wayuu eekai kama'an√ºin n√ºt√ºm...   \n",
       "472                                                            Talatashaatas√º ma'in taa'in anap√º'√ºin jia.   \n",
       "3309  Je n√ºntapa n√ºnain, naapaain nia nipialu'um√ºin. Eeshi nia s√ºnain wane juya'a ma'i s√ºnain ekirajaa...   \n",
       "1790  Naakatawalaja'a joo chi Anneetchonkai s√ºnain joyot√ºin yaa saa'u t√º uuchikat Sion. Je n√ºmaa chi A...   \n",
       "\n",
       "                                                                                           esp_translated  \n",
       "676                       Yo me escond√≠ en un chinchorro con una mochila, hay un poco de lavar mi ropaje.  \n",
       "5447  All√≠ tomaron la palabra Jes√∫s y le dijeron: - ¬°Adivina qui√©n te ha pegado! Porque algunos de los...  \n",
       "2925      Traten a los que est√°n en la c√°rcel como a prisioneros, y a los que lloran, como a complicados.  \n",
       "6565                                         Jes√∫s contest√≥: - Vino a ser el heredero de la casa de Dios.  \n",
       "1670  Fueron vestidos de p√∫rpura y ce√±idas sus cabezas, ce√±idas sus cabezas y ce√±idas sus dientes. Dan...  \n",
       "6786  Cuando oigan noticias de guerras y rumores de conflictos b√©licos, no se alarmen. Aunque todo eso...  \n",
       "5277  Porque a todo el que tiene, a√∫n se le dar√° m√°s, y tendr√° de sobra; pero al que no tiene, hasta l...  \n",
       "472                                                                Yo estoy contenta de estar con ustedes  \n",
       "3309  A su llegada, se encontraron en Antioqu√≠a donde condujeron a la iglesia y ense√±aron con gran ayu...  \n",
       "1790  Vi entonces c√≥mo el Cordero segu√≠a en el cielo, y vi debajo de la monta√±a de Sion, el Cordero. H...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776cf77-7387-40e4-8941-ab345fb844ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
