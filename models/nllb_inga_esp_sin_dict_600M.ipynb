{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=2\n",
    "MODEL_USED=\"models/nllb_quechua_esp_v4_600M\"\n",
    "# MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_inga_esp_sin_dict_600M\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"ing_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"quechua_Latn\" # Quechua Transferr Learning\n",
    "LANGUAGE_FILE=\"data/constitucion_ing_completo.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"ing\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 3)\n",
      "Index(['esp', 'ing', 'parte'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 169 entries, 127 to 102\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   esp     169 non-null    object\n",
      " 1   ing     169 non-null    object\n",
      " 2   parte   169 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>ing</th>\n",
       "      <th>parte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>el estado garantiza las libertades de ense√±anz...</td>\n",
       "      <td>nukanchipa atun llagta tukuikunatami iuka kuan...</td>\n",
       "      <td>articulos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>el pueblo la ejerce en forma directa o por med...</td>\n",
       "      <td>chi suma iuaikuna nukanchikikin u atun taitaku...</td>\n",
       "      <td>articulos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>en m√°s de una ocasi√≥n tuvieron que volver a em...</td>\n",
       "      <td>kai achka lachag pangata nukanchipa simima ial...</td>\n",
       "      <td>coordinador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>estas lenguas est√°n entre las m√°s habladas de ...</td>\n",
       "      <td>sugkunaka √±i nukanchi kikimpa rimaillatapas ma...</td>\n",
       "      <td>coordinador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>art√≠culos relativos a los derechos de las pers...</td>\n",
       "      <td>nukanchi ima ma√±angapa ministiska</td>\n",
       "      <td>titulos_constitucion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   esp  \\\n",
       "127  el estado garantiza las libertades de ense√±anz...   \n",
       "108  el pueblo la ejerce en forma directa o por med...   \n",
       "69   en m√°s de una ocasi√≥n tuvieron que volver a em...   \n",
       "84   estas lenguas est√°n entre las m√°s habladas de ...   \n",
       "97   art√≠culos relativos a los derechos de las pers...   \n",
       "\n",
       "                                                   ing                 parte  \n",
       "127  nukanchipa atun llagta tukuikunatami iuka kuan...             articulos  \n",
       "108  chi suma iuaikuna nukanchikikin u atun taitaku...             articulos  \n",
       "69   kai achka lachag pangata nukanchipa simima ial...           coordinador  \n",
       "84   sugkunaka √±i nukanchi kikimpa rimaillatapas ma...           coordinador  \n",
       "97                   nukanchi ima ma√±angapa ministiska  titulos_constitucion  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21 entries, 30 to 190\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   esp     21 non-null     object\n",
      " 1   ing     21 non-null     object\n",
      " 2   parte   21 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 672.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>ing</th>\n",
       "      <th>parte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>alfonso palma y al sr</td>\n",
       "      <td>achka iachag pangata nukanchipa simipi ialichi...</td>\n",
       "      <td>carta_traductor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tomar parte en elecciones, plebiscitos, refere...</td>\n",
       "      <td>kline  xan  kimsa</td>\n",
       "      <td>articulos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>las lenguas y dialectos de los grupos √©tnicos ...</td>\n",
       "      <td>nukanchipa sug rigcha kaugsai runakunapa rimai...</td>\n",
       "      <td>articulos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>los distritos y los municipios percibir√°n como...</td>\n",
       "      <td>wawa llagtata katiraiagkuna mas achka kulkinmi...</td>\n",
       "      <td>articulos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>la ley establecer√° las formas de coordinaci√≥n ...</td>\n",
       "      <td>maikan nukanchi pandarispa kaugsanakugpika, nu...</td>\n",
       "      <td>articulos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   esp  \\\n",
       "30                               alfonso palma y al sr   \n",
       "177  tomar parte en elecciones, plebiscitos, refere...   \n",
       "163  las lenguas y dialectos de los grupos √©tnicos ...   \n",
       "209  los distritos y los municipios percibir√°n como...   \n",
       "189  la ley establecer√° las formas de coordinaci√≥n ...   \n",
       "\n",
       "                                                   ing            parte  \n",
       "30   achka iachag pangata nukanchipa simipi ialichi...  carta_traductor  \n",
       "177                                  kline  xan  kimsa        articulos  \n",
       "163  nukanchipa sug rigcha kaugsai runakunapa rimai...        articulos  \n",
       "209  wawa llagtata katiraiagkuna mas achka kulkinmi...        articulos  \n",
       "189  maikan nukanchi pandarispa kaugsanakugpika, nu...        articulos  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22 entries, 96 to 25\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   esp     22 non-null     object\n",
      " 1   ing     22 non-null     object\n",
      " 2   parte   22 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 704.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>ing</th>\n",
       "      <th>parte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>art√≠culos relativos a los principios fundament...</td>\n",
       "      <td>kulumbiamanda achka iachag pangakuna iapa mini...</td>\n",
       "      <td>titulos_constitucion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>algunos de los derechos son considerados funda...</td>\n",
       "      <td>pusag chunga sugta, pusag chunga kanchis, pusa...</td>\n",
       "      <td>articulos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>en los establecimientos del estado ninguna per...</td>\n",
       "      <td>achka iachag pangapa wawami maki kuangapa kank...</td>\n",
       "      <td>articulos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>los ciudadanos colombianos que se encuentren o...</td>\n",
       "      <td>iurakuna i nukanchipa runakunapas, sug llagtap...</td>\n",
       "      <td>articulos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>este trabajo y una constante discusi√≥n sobre l...</td>\n",
       "      <td>chikunata rigsigkuna sutikankunami: mamos, pay...</td>\n",
       "      <td>coordinador</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   esp  \\\n",
       "96   art√≠culos relativos a los principios fundament...   \n",
       "150  algunos de los derechos son considerados funda...   \n",
       "143  en los establecimientos del estado ninguna per...   \n",
       "181  los ciudadanos colombianos que se encuentren o...   \n",
       "73   este trabajo y una constante discusi√≥n sobre l...   \n",
       "\n",
       "                                                   ing                 parte  \n",
       "96   kulumbiamanda achka iachag pangakuna iapa mini...  titulos_constitucion  \n",
       "150  pusag chunga sugta, pusag chunga kanchis, pusa...             articulos  \n",
       "143  achka iachag pangapa wawami maki kuangapa kank...             articulos  \n",
       "181  iurakuna i nukanchipa runakunapas, sug llagtap...             articulos  \n",
       "73   chikunata rigsigkuna sutikankunami: mamos, pay...           coordinador  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "499822a8-f5de-4475-bd7b-aae3668f5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f9ad22-d9c3-4b3e-9bc5-e67b263c36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "379b1605-5ead-443a-9b43-2b7f5a54cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', '<mask>', 'quechua_Latn']\n",
      "[262576, 262578, 262577]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([262576, 262577, 262578])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', 'quechua_Latn', '<mask>'])) # [256202, 256203, 256204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2270130-3f49-4ae1-a27f-f947af629f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer, new_lang=\"quechua_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e522da1-81a8-45d5-93c7-cfadc901b780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'quechua_Latn', '<mask>']\n",
      "[262576, 262577, 262578]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([262576, 262577, 262578])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', 'quechua_Latn', '<mask>'])) # [256202, 256203, 256204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>ing</th>\n",
       "      <th>ing_words</th>\n",
       "      <th>ing_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>la ley podr√° darle el car√°cter de entidades te...</td>\n",
       "      <td>[la, ley, podr√°, darle, el, car√°cter, de, enti...</td>\n",
       "      <td>[‚ñÅla, ‚ñÅley, ‚ñÅpodr√°, ‚ñÅdarle, ‚ñÅel, ‚ñÅcar√°cter, ‚ñÅd...</td>\n",
       "      <td>atun llagtapa katilla alpakuna i puntu wawa ll...</td>\n",
       "      <td>[atun, llagtapa, katilla, alpakuna, i, puntu, ...</td>\n",
       "      <td>[‚ñÅatun, ‚ñÅl, lag, tapa, ‚ñÅkat, illa, ‚ñÅal, pak, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>en todo caso de incompatibilidad entre la cons...</td>\n",
       "      <td>[en, todo, caso, de, incompatibilidad, entre, ...</td>\n",
       "      <td>[‚ñÅen, ‚ñÅtodo, ‚ñÅcaso, ‚ñÅde, ‚ñÅincompati, bilidad, ...</td>\n",
       "      <td>mana achka iachag pangakuna suma tukuskata u m...</td>\n",
       "      <td>[mana, achka, iachag, pangakuna, suma, tukuska...</td>\n",
       "      <td>[‚ñÅmana, ‚ñÅachka, ‚ñÅiach, ag, ‚ñÅpang, akuna, ‚ñÅsuma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>estas lenguas est√°n entre las m√°s habladas de ...</td>\n",
       "      <td>[estas, lenguas, est√°n, entre, las, m√°s, habla...</td>\n",
       "      <td>[‚ñÅestas, ‚ñÅlengu, as, ‚ñÅest√°n, ‚ñÅentre, ‚ñÅlas, ‚ñÅm√°...</td>\n",
       "      <td>sugkunaka √±i nukanchi kikimpa rimaillatapas ma...</td>\n",
       "      <td>[sugkunaka, √±i, nukanchi, kikimpa, rimaillatap...</td>\n",
       "      <td>[‚ñÅsug, kun, aka, ‚ñÅ√±i, ‚ñÅn, ukan, chi, ‚ñÅkik, imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>sin embargo quedaron todas las otras por fuera...</td>\n",
       "      <td>[sin, embargo, quedaron, todas, las, otras, po...</td>\n",
       "      <td>[‚ñÅsin, ‚ñÅembargo, ‚ñÅqued, aron, ‚ñÅtodas, ‚ñÅlas, ‚ñÅo...</td>\n",
       "      <td>chasa rurangapaka, iacha panganigtami maskaspa...</td>\n",
       "      <td>[chasa, rurangapaka, ,, iacha, panganigtami, m...</td>\n",
       "      <td>[‚ñÅch, asa, ‚ñÅr, urang, ap, aka, ,, ‚ñÅi, acha, ‚ñÅp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>son nacionales colombianos:  c</td>\n",
       "      <td>[son, nacionales, colombianos, :, c]</td>\n",
       "      <td>[‚ñÅson, ‚ñÅnacionales, ‚ñÅcol, ombi, anos, :, ‚ñÅc]</td>\n",
       "      <td>kawasunchi ari pikunami kulumbianu niraianchi:  a</td>\n",
       "      <td>[kawasunchi, ari, pikunami, kulumbianu, niraia...</td>\n",
       "      <td>[‚ñÅkawas, un, chi, ‚ñÅari, ‚ñÅpik, unami, ‚ñÅkul, umb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   esp  \\\n",
       "191  la ley podr√° darle el car√°cter de entidades te...   \n",
       "110  en todo caso de incompatibilidad entre la cons...   \n",
       "84   estas lenguas est√°n entre las m√°s habladas de ...   \n",
       "85   sin embargo quedaron todas las otras por fuera...   \n",
       "146                     son nacionales colombianos:  c   \n",
       "\n",
       "                                             esp_words  \\\n",
       "191  [la, ley, podr√°, darle, el, car√°cter, de, enti...   \n",
       "110  [en, todo, caso, de, incompatibilidad, entre, ...   \n",
       "84   [estas, lenguas, est√°n, entre, las, m√°s, habla...   \n",
       "85   [sin, embargo, quedaron, todas, las, otras, po...   \n",
       "146               [son, nacionales, colombianos, :, c]   \n",
       "\n",
       "                                              esp_toks  \\\n",
       "191  [‚ñÅla, ‚ñÅley, ‚ñÅpodr√°, ‚ñÅdarle, ‚ñÅel, ‚ñÅcar√°cter, ‚ñÅd...   \n",
       "110  [‚ñÅen, ‚ñÅtodo, ‚ñÅcaso, ‚ñÅde, ‚ñÅincompati, bilidad, ...   \n",
       "84   [‚ñÅestas, ‚ñÅlengu, as, ‚ñÅest√°n, ‚ñÅentre, ‚ñÅlas, ‚ñÅm√°...   \n",
       "85   [‚ñÅsin, ‚ñÅembargo, ‚ñÅqued, aron, ‚ñÅtodas, ‚ñÅlas, ‚ñÅo...   \n",
       "146       [‚ñÅson, ‚ñÅnacionales, ‚ñÅcol, ombi, anos, :, ‚ñÅc]   \n",
       "\n",
       "                                                   ing  \\\n",
       "191  atun llagtapa katilla alpakuna i puntu wawa ll...   \n",
       "110  mana achka iachag pangakuna suma tukuskata u m...   \n",
       "84   sugkunaka √±i nukanchi kikimpa rimaillatapas ma...   \n",
       "85   chasa rurangapaka, iacha panganigtami maskaspa...   \n",
       "146  kawasunchi ari pikunami kulumbianu niraianchi:  a   \n",
       "\n",
       "                                             ing_words  \\\n",
       "191  [atun, llagtapa, katilla, alpakuna, i, puntu, ...   \n",
       "110  [mana, achka, iachag, pangakuna, suma, tukuska...   \n",
       "84   [sugkunaka, √±i, nukanchi, kikimpa, rimaillatap...   \n",
       "85   [chasa, rurangapaka, ,, iacha, panganigtami, m...   \n",
       "146  [kawasunchi, ari, pikunami, kulumbianu, niraia...   \n",
       "\n",
       "                                              ing_toks  \n",
       "191  [‚ñÅatun, ‚ñÅl, lag, tapa, ‚ñÅkat, illa, ‚ñÅal, pak, u...  \n",
       "110  [‚ñÅmana, ‚ñÅachka, ‚ñÅiach, ag, ‚ñÅpang, akuna, ‚ñÅsuma...  \n",
       "84   [‚ñÅsug, kun, aka, ‚ñÅ√±i, ‚ñÅn, ukan, chi, ‚ñÅkik, imp...  \n",
       "85   [‚ñÅch, asa, ‚ñÅr, urang, ap, aka, ,, ‚ñÅi, acha, ‚ñÅp...  \n",
       "146  [‚ñÅkawas, un, chi, ‚ñÅari, ‚ñÅpik, unami, ‚ñÅkul, umb...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_281259/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>ing_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>ing_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.531900</td>\n",
       "      <td>37.988200</td>\n",
       "      <td>25.641300</td>\n",
       "      <td>17.472700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.285429</td>\n",
       "      <td>27.055075</td>\n",
       "      <td>18.853885</td>\n",
       "      <td>12.662041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>131.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks      ing_toks     esp_words     ing_words\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean      33.531900     37.988200     25.641300     17.472700\n",
       "std       25.285429     27.055075     18.853885     12.662041\n",
       "min        1.000000      2.000000      1.000000      1.000000\n",
       "25%       14.000000     18.000000     11.000000      8.000000\n",
       "50%       25.000000     31.000000     20.000000     14.000000\n",
       "75%       44.000000     52.000000     36.000000     24.000000\n",
       "max      131.000000    163.000000    100.000000     74.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.307730107287852\n",
      "2.174145953401592\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423e3dec632e4ed5a27f24277a39d187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# s = random.sample(texts_with_unk, 5)\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace ùìïùîØùîûùî´ùî†ùî¢ùî∞ùî†ùîû by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb84536de4e4b808e7898d58764f7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515f8c448bbc4533a9d04935eab63ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_inga_esp_sin_dict_600M/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_inga_esp_sin_dict_600M/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1024\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: aiunkspgcmhtlr,wd√±oeb√°jyx19:()v;z8f032q6-5\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_inga_esp_sin_dict_600M/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 212 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=27450\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=49\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 212 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=15894\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 3630 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 212\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 1444\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 1444 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1190 obj=12.0794 num_tokens=2948 num_tokens/piece=2.47731\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1022 obj=9.85703 num_tokens=2967 num_tokens/piece=2.90313\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_inga_esp_sin_dict_600M/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_inga_esp_sin_dict_600M/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**10,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-10 11:04:37--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-10 11:04:37 (12.6 MB/s) - ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "fix_tokenizer(tokenizer, new_lang=\"quechua_Latn\")\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262579 263140\n",
      "561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 11:04:40.641043: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-10 11:04:40.801480: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-10 11:04:41.434467: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-10 11:04:41.434526: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-10 11:04:41.434531: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 263140. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e79af2d235f44d29cdfdc0c2017f733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "fix_tokenizer(tokenizer_old, new_lang=\"quechua_Latn\")\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f20fc584-27fa-4d8f-b0ec-57936d69c98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'quechua_Latn', '<mask>']\n",
      "[262576, 262577, 262578]\n",
      "['zul_Latn', 'quechua_Latn', '<mask>']\n",
      "[263137, 3, 263139]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_old.convert_ids_to_tokens([262576, 262577, 262578])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "print(tokenizer_old.convert_tokens_to_ids(['zul_Latn', 'quechua_Latn', '<mask>'])) # [256202, 256203, 256204]\n",
    "\n",
    "fix_tokenizer(tokenizer, new_lang=\"quechua_Latn\")\n",
    "print(tokenizer.convert_ids_to_tokens([263137, 263138, 263139])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', 'quechua_Cyrl', '<mask>'])) # [256202, 256203, 256204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263140\n",
      "561\n",
      "['quechua_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(len(added_vocab))\n",
    "print(tokenizer.convert_ids_to_tokens([263138, 263139]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quechua_Latn', 'ing_Latn', '<mask>']\n",
      "[263138, 263139, 263140]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([262576 + len(added_vocab) + 1, 262576 + len(added_vocab) + 2, 262576 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['quechua_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263139 263138\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 263141. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(263141, 1024)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['nukanchipa achka iachag pangakunata waranga iskun patsa iskun chunga wata kaurami surkurkakuna, kanchis chunga runakuna intiru atun llagtamanda samuspa, sugkunaka sugrigcha iuiaiug, sugkunaka chillatata iuiaiwa tuparinakuspa, askurinti unai tiarispa chi achka iachag pangakunatami surkurkakuna'], ['los ind√≠genas que participaron en la constituyente nos representaron exponiendo nuestro pensamiento, el cual qued√≥ parcialmente escrito en la constituci√≥n'], 'ing_Latn', 'spa_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabe61752a024076af4117a122fbe547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.884777069091797\n",
      "1000 3.3778814415484666\n",
      "2000 0.26206783271254974\n",
      "3000 0.044807057205820455\n",
      "4000 0.013726625888899434\n",
      "5000 0.008686140736099333\n",
      "6000 0.005863375636428828\n",
      "7000 0.004719531923357863\n",
      "8000 0.0032343571928067833\n",
      "9000 0.00362241078641091\n",
      "10000 0.0032828529957914724\n",
      "11000 0.0027557711060617295\n",
      "12000 0.002624264501675498\n",
      "13000 0.002511388319970138\n",
      "14000 0.0020761756875053833\n",
      "15000 0.0019162798250563354\n",
      "16000 0.0016382560423062386\n",
      "17000 0.001651207297683868\n",
      "18000 0.0017460337119673567\n",
      "19000 0.0016877662960596354\n",
      "20000 0.0021264849395483906\n",
      "21000 0.0016977910371042525\n",
      "22000 0.0015742447582797468\n",
      "23000 0.0017817173039011323\n",
      "24000 0.0015847786091107991\n",
      "25000 0.0020043361349707995\n",
      "26000 0.0019656291964001865\n",
      "27000 0.001965120153584394\n",
      "28000 0.0022340890314708306\n",
      "29000 0.001652091640737126\n",
      "30000 0.0017060262669861004\n",
      "31000 0.0015575996288707756\n",
      "32000 0.0014421942340777606\n",
      "33000 0.001439251428590069\n",
      "34000 0.0014461729117629146\n",
      "35000 0.0014574221216430488\n",
      "36000 0.001298497734515422\n",
      "37000 0.0013226957012821003\n",
      "38000 0.001352452597122692\n",
      "39000 0.0013633820271829792\n",
      "40000 0.0013909585562362282\n",
      "41000 0.0012810198976007997\n",
      "42000 0.001289665884264423\n",
      "43000 0.001215142695874647\n",
      "44000 0.0012453482531910823\n",
      "45000 0.0013440353012304058\n",
      "46000 0.0012795121357823973\n",
      "47000 0.0013947076603473079\n",
      "48000 0.0013520936747971745\n",
      "49000 0.001349056723820695\n",
      "50000 0.0012302541444079225\n",
      "51000 0.0013467987199559275\n",
      "52000 0.001290745230090124\n",
      "53000 0.0014430698103417398\n",
      "54000 0.0014791502007389\n",
      "55000 0.0013094730333608594\n",
      "56000 0.0014095775913634725\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atun llagtapi iachachidiru wasinigtami iachachigkuna iukankuna kangakuna']\n",
      "['la ense√±anza estar√° a cargo de personas de reconocida idoneidad √©tica y pedag√≥gica']\n",
      "['la ley garantiza la profesionalizaci√≥n y dignificaci√≥n de la actividad docente']\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.4G\n",
      "4.0K drwxrwxr-x  2 americasnlp americasnlp 4.0K Mar 10 11:13 .\n",
      "4.0K drwxr-xr-x 12 americasnlp americasnlp 4.0K Mar 10 10:59 ..\n",
      " 28K -rw-rw-r--  1 americasnlp americasnlp  28K Mar 10 11:04 all_texts_file.csv\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  895 Mar 10 19:03 config.json\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  184 Mar 10 19:03 generation_config.json\n",
      "2.4G -rw-rw-r--  1 americasnlp americasnlp 2.4G Mar 10 19:03 pytorch_model.bin\n",
      "4.8M -rw-rw-r--  1 americasnlp americasnlp 4.8M Mar 10 19:03 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp 3.5K Mar 10 19:03 special_tokens_map.json\n",
      "252K -rw-rw-r--  1 americasnlp americasnlp 249K Mar 10 11:04 spm_16k.model\n",
      " 20K -rw-rw-r--  1 americasnlp americasnlp  18K Mar 10 11:04 spm_16k.vocab\n",
      "4.8M -rw-rw-r--  1 americasnlp americasnlp 4.8M Mar 10 11:04 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  570 Mar 10 19:03 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "# fix_tokenizer(tokenizer)\n",
    "# print(tokenizer.convert_ids_to_tokens([262576 + len(added_vocab) + 1, 262576 + len(added_vocab) + 2, 262576 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "# print(tokenizer.convert_tokens_to_ids(['quechua_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8638736c-e6c6-43db-a297-633cdbe77ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer, new_lang=\"quechua_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5a9edd1-ac18-4b94-920b-bdd6dee27d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.convert_ids_to_tokens([263137, 263138, 263139])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "# print(tokenizer.convert_tokens_to_ids(['zul_Latn', 'quechua_Latn', '<mask>'])) # [256202, 256203, 256204]\n",
    "fix_tokenizer(tokenizer)\n",
    "# print(tokenizer.convert_ids_to_tokens([263137, 263138])) # ['zul_Latn', 'quechua_Cyrl', '<mask>']\n",
    "# print(tokenizer.convert_tokens_to_ids(['zul_Latn', 'quechua_Cyrl', '<mask>'])) # [256202, 256203, 256204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb200680-2c26-4a60-a34c-ae5fe7b5c575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ing_Latn', '<mask>']\n",
      "[263139, 263140]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([263139, 263140])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids([LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f83cab4b-fb4e-4c8e-a3aa-47f4fa2e054e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ing_Latn'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGUAGE_TARGET_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['achka iachag pangakunapa wawa nukanchipa simima i sug rigchami iachaikui puchukaskakunami kankuna']\n"
     ]
    }
   ],
   "source": [
    "t = \"Muchas de las centenares de especies se usan ornamentalmente\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['achka iachag pangakunapa wawami tukuikunatami iuka rigsingapa kai alpapi apispa']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['la ley establecer√° las condiciones para su creaci√≥n y gesti√≥n']\n"
     ]
    }
   ],
   "source": [
    "t = \"achka iachag pangakunapa wawami tukuikunatami iuka rigsingapa kai alpapi apispa\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no vacilo en afirmar que este texto encarna el esp√≠ritu que anim√≥ la labor de los constituyentes: tenemos derecho a vivir en un pa√≠s que como √©ste, sea amplio, tolerante y lo suficientemente democr√°tico, para que todos tengamos un lugar bajo el sol de colombia']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b450b66e98474e982e369e6776398e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557faadfd8be48c89ea2f978478334d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 0.74 13.7/1.7/0.2/0.1 (BP = 1.000 ratio = 1.390 hyp_len = 673 ref_len = 484)\n",
      "chrF2++ = 19.21\n",
      "BLEU = 1.86 13.8/3.5/1.0/0.3 (BP = 1.000 ratio = 1.382 hyp_len = 456 ref_len = 330)\n",
      "chrF2++ = 30.00\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ing</th>\n",
       "      <th>esp</th>\n",
       "      <th>ing_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>kulumbiamanda achka iachag pangakuna iapa ministiskata iuiachidiru</td>\n",
       "      <td>art√≠culos relativos a los principios fundamentales del estado</td>\n",
       "      <td>nukanchipa atun llagtapi iuia kagta</td>\n",
       "      <td>el hecho de haberme enfrentado a esta dura tarea, sin una experiencia previa en traducci√≥n, me d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>kaikunata nukanchipa simima ialichingapa sug iacha sug iachatami chaiarka tapuchispa, tapuchispa...</td>\n",
       "      <td>las limitaciones en cuanto al dinero y en cuanto a ling√ºistas ind√≠genas disponibles nos impidier...</td>\n",
       "      <td>achka iachag pangata nukanchipa simima ialichingapa, sugkunaka rimaikunapi churangapa chasalla m...</td>\n",
       "      <td>cada dos meses se reun√≠an con nosotros en bogot√° donde examin√°bamos las dificultades entre todos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nukanchipa simipi ialichigta aidagkunapasmi nukanchipa rimaita askuarinti allilla rimagmi kankuna</td>\n",
       "      <td>antonio cuatindioy gobernador del cabildo inga de san andr√©s</td>\n",
       "      <td>bogot√°manda kaiawai kallariuraka, pirmisukuna ma√±aspami iacharkani ringa</td>\n",
       "      <td>solo se hizo la traducci√≥n en siete lenguas: el way√∫naiki de la guajira, el nasa yuwe o p√°ez del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>pusag chunga sugta, pusag chunga kanchis, pusag chunga pusag hordator (86,87,88) achka iachag ku...</td>\n",
       "      <td>algunos de los derechos son considerados fundamentales como el derecho a la vida, la libertad pe...</td>\n",
       "      <td>kai achka iachag pangakunapa wawapagmami k√°, imasa nukanchipa atunkuna antiwama iachaikungapa, i...</td>\n",
       "      <td>los territorios ind√≠genas estar√°n gobernados por consejos conformados y reglamentados seg√∫n los ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>√±a chasakari sutipami iachi nukanchipa rimaima ialichiskasina</td>\n",
       "      <td>creemos que se allan√≥ el camino para traducir los otros cuando surja la necesidad</td>\n",
       "      <td>nukanchipa simima ialichingapa u suraka nanachigmandami tukungakuna, tukuikunami nukanchipa simi...</td>\n",
       "      <td>anteriormente nunca tuvimos la oportunidad de conocerla ni en castellano y peor en nuestra lengu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>imasa nukanchita iaia sakiskasina</td>\n",
       "      <td>digitalizado por sistema de bibliotecas-universidad de los andes</td>\n",
       "      <td>achka iachag pangata, nukanchipa simipi ialichispa apaskata, mandu kuanakunchimi tukuikuna apisp...</td>\n",
       "      <td>santiago, putumayo, septiembre 26 de 1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>iukanganapasmi chi suma iuiakuna achka iachag pangakuna i achka iachag pangakunapa wawapi imasa ...</td>\n",
       "      <td>cualquier persona puede exigir a la autoridad competente su cumplimiento y la sanci√≥n de los inf...</td>\n",
       "      <td>ni pitapas mana wa√±uchingapa pudirinchu, maikan nukanchipa atunkunasina, tukui nukanchimanda sum...</td>\n",
       "      <td>la pol√≠tica exterior de colombia es una ley mayor que gu√≠a las dem√°s leyes de colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>nukanchipa atun llagta kulumbia tukuikunamanda sumaglla kaugsangapa</td>\n",
       "      <td>colombia es un estado social de derecho, organizado en forma de rep√∫blica unitaria, descentraliz...</td>\n",
       "      <td>kai achka iachag pangakunapa wawapa taitami k√°, nispami tukui kai atun llagtapi kaugsag, autonom...</td>\n",
       "      <td>el estado reconoce y protege la diversidad √©tnica y cultural de la naci√≥n colombiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>iurakuna i nukanchipa runakunapas, sug llagtapi kaugsagriskakunapasmi pudinkuna awanigmanda kawa...</td>\n",
       "      <td>los ciudadanos colombianos que se encuentren o residan en el exterior podr√°n sufragar en las ele...</td>\n",
       "      <td>tukui nukanchipa llagtapi kaugsakuna u sugrigcha iuiaiug kaugsakuna kai alpapi awanigmanda kawad...</td>\n",
       "      <td>los s√≠mbolos de la casa, del cuerpo, de las direcciones del c√≥smos, de la firmeza, de la palabra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>chikunata rigsigkuna sutikankunami: mamos, pay√©s, chamanes, taitakuna i achalakuna u nukanchita ...</td>\n",
       "      <td>este trabajo y una constante discusi√≥n sobre las, muy diversas, tradiciones ind√≠genas de colombi...</td>\n",
       "      <td>√±a kai achka iachag pangata nukanchipa simipi ialichigkuna, sugrigcha rimaikunapa simima ialichi...</td>\n",
       "      <td>mamos, pay√©s, chamanes, i segundo antonio jacanamijoy, adilio ra√∫l chasoy, gobernadores de santi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                     ing  \\\n",
       "96                                    kulumbiamanda achka iachag pangakuna iapa ministiskata iuiachidiru   \n",
       "86   kaikunata nukanchipa simima ialichingapa sug iacha sug iachatami chaiarka tapuchispa, tapuchispa...   \n",
       "9      nukanchipa simipi ialichigta aidagkunapasmi nukanchipa rimaita askuarinti allilla rimagmi kankuna   \n",
       "150  pusag chunga sugta, pusag chunga kanchis, pusag chunga pusag hordator (86,87,88) achka iachag ku...   \n",
       "82                                         √±a chasakari sutipami iachi nukanchipa rimaima ialichiskasina   \n",
       "93                                                                     imasa nukanchita iaia sakiskasina   \n",
       "135  iukanganapasmi chi suma iuiakuna achka iachag pangakuna i achka iachag pangakunapa wawapi imasa ...   \n",
       "104                                  nukanchipa atun llagta kulumbia tukuikunamanda sumaglla kaugsangapa   \n",
       "181  iurakuna i nukanchipa runakunapas, sug llagtapi kaugsagriskakunapasmi pudinkuna awanigmanda kawa...   \n",
       "73   chikunata rigsigkuna sutikankunami: mamos, pay√©s, chamanes, taitakuna i achalakuna u nukanchita ...   \n",
       "\n",
       "                                                                                                     esp  \\\n",
       "96                                         art√≠culos relativos a los principios fundamentales del estado   \n",
       "86   las limitaciones en cuanto al dinero y en cuanto a ling√ºistas ind√≠genas disponibles nos impidier...   \n",
       "9                                           antonio cuatindioy gobernador del cabildo inga de san andr√©s   \n",
       "150  algunos de los derechos son considerados fundamentales como el derecho a la vida, la libertad pe...   \n",
       "82                     creemos que se allan√≥ el camino para traducir los otros cuando surja la necesidad   \n",
       "93                                      digitalizado por sistema de bibliotecas-universidad de los andes   \n",
       "135  cualquier persona puede exigir a la autoridad competente su cumplimiento y la sanci√≥n de los inf...   \n",
       "104  colombia es un estado social de derecho, organizado en forma de rep√∫blica unitaria, descentraliz...   \n",
       "181  los ciudadanos colombianos que se encuentren o residan en el exterior podr√°n sufragar en las ele...   \n",
       "73   este trabajo y una constante discusi√≥n sobre las, muy diversas, tradiciones ind√≠genas de colombi...   \n",
       "\n",
       "                                                                                          ing_translated  \\\n",
       "96                                                                   nukanchipa atun llagtapi iuia kagta   \n",
       "86   achka iachag pangata nukanchipa simima ialichingapa, sugkunaka rimaikunapi churangapa chasalla m...   \n",
       "9                               bogot√°manda kaiawai kallariuraka, pirmisukuna ma√±aspami iacharkani ringa   \n",
       "150  kai achka iachag pangakunapa wawapagmami k√°, imasa nukanchipa atunkuna antiwama iachaikungapa, i...   \n",
       "82   nukanchipa simima ialichingapa u suraka nanachigmandami tukungakuna, tukuikunami nukanchipa simi...   \n",
       "93   achka iachag pangata, nukanchipa simipi ialichispa apaskata, mandu kuanakunchimi tukuikuna apisp...   \n",
       "135  ni pitapas mana wa√±uchingapa pudirinchu, maikan nukanchipa atunkunasina, tukui nukanchimanda sum...   \n",
       "104  kai achka iachag pangakunapa wawapa taitami k√°, nispami tukui kai atun llagtapi kaugsag, autonom...   \n",
       "181  tukui nukanchipa llagtapi kaugsakuna u sugrigcha iuiaiug kaugsakuna kai alpapi awanigmanda kawad...   \n",
       "73   √±a kai achka iachag pangata nukanchipa simipi ialichigkuna, sugrigcha rimaikunapa simima ialichi...   \n",
       "\n",
       "                                                                                          esp_translated  \n",
       "96   el hecho de haberme enfrentado a esta dura tarea, sin una experiencia previa en traducci√≥n, me d...  \n",
       "86   cada dos meses se reun√≠an con nosotros en bogot√° donde examin√°bamos las dificultades entre todos...  \n",
       "9    solo se hizo la traducci√≥n en siete lenguas: el way√∫naiki de la guajira, el nasa yuwe o p√°ez del...  \n",
       "150  los territorios ind√≠genas estar√°n gobernados por consejos conformados y reglamentados seg√∫n los ...  \n",
       "82   anteriormente nunca tuvimos la oportunidad de conocerla ni en castellano y peor en nuestra lengu...  \n",
       "93                                                             santiago, putumayo, septiembre 26 de 1993  \n",
       "135               la pol√≠tica exterior de colombia es una ley mayor que gu√≠a las dem√°s leyes de colombia  \n",
       "104                 el estado reconoce y protege la diversidad √©tnica y cultural de la naci√≥n colombiana  \n",
       "181  los s√≠mbolos de la casa, del cuerpo, de las direcciones del c√≥smos, de la firmeza, de la palabra...  \n",
       "73   mamos, pay√©s, chamanes, i segundo antonio jacanamijoy, adilio ra√∫l chasoy, gobernadores de santi...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776cf77-7387-40e4-8941-ab345fb844ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
