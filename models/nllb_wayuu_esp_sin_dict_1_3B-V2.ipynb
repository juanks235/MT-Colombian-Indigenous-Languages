{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=2\n",
    "# MODEL_USED=\"facebook/nllb-200-distilled-600M\"\n",
    "MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_wayuu_esp_sin_dict_1_3B-V2\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"way_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"ayr_Latn\" # Central Aymara\n",
    "LANGUAGE_FILE=\"data/wayuu_completo_sin_dic_v2.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"way\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7635, 2)\n",
      "Index(['way', 'esp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6108 entries, 216 to 7270\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     6108 non-null   object\n",
      " 1   esp     6108 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 143.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Antüsü wanee palajana, antüsü wanee mapan.</td>\n",
       "      <td>Llegó primero una, llegó otra después.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>Nüsouktakalaka Jesús nümüin:—Tamüsü paala pümü...</td>\n",
       "      <td>Jesús le contestó:—El que me ama de verdad se ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>Anainja tojuittüle yaajee tale'ejaiwa nünainmü...</td>\n",
       "      <td>Volveré a mi padre y le diré: Padre, he pecado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>¿Eesü asalaa cha ꞌaya suluꞌu  aikaaleekalü?</td>\n",
       "      <td>¿Hay carne allá en la tienda?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Aa, antajachi taya si'iralüin müshia ekirajaai...</td>\n",
       "      <td>Si, el profesor me dijo que viniera en guayuco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "216          Antüsü wanee palajana, antüsü wanee mapan.   \n",
       "4383  Nüsouktakalaka Jesús nümüin:—Tamüsü paala pümü...   \n",
       "5163  Anainja tojuittüle yaajee tale'ejaiwa nünainmü...   \n",
       "421         ¿Eesü asalaa cha ꞌaya suluꞌu  aikaaleekalü?   \n",
       "505   Aa, antajachi taya si'iralüin müshia ekirajaai...   \n",
       "\n",
       "                                                    esp  \n",
       "216              Llegó primero una, llegó otra después.  \n",
       "4383  Jesús le contestó:—El que me ama de verdad se ...  \n",
       "5163  Volveré a mi padre y le diré: Padre, he pecado...  \n",
       "421                       ¿Hay carne allá en la tienda?  \n",
       "505   Si, el profesor me dijo que viniera en guayuco...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 763 entries, 5981 to 5799\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     763 non-null    object\n",
      " 1   esp     763 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>Sükajee tüü, shii'iyatüin tamüin tojut süpülap...</td>\n",
       "      <td>Ha hecho lo que estaba en su mano preparando p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>Nükumajüin shia Maleiwakai süpüla süchajaainja...</td>\n",
       "      <td>Y esto para ver si, aunque fuese a tientas, pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>Ni'rapa Jesús tü wayuu wattakat saalin nü'ütpa...</td>\n",
       "      <td>Viendo Jesús que lo rodeaba una gran multitud,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>¿Kasa paa Ꞌinraka?</td>\n",
       "      <td>¿Qué haces?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>Je ni'rataalain naa'in wane wayuu kanüliashi A...</td>\n",
       "      <td>y acaba de tener una visión en la que un hombr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "5981  Sükajee tüü, shii'iyatüin tamüin tojut süpülap...   \n",
       "3491  Nükumajüin shia Maleiwakai süpüla süchajaainja...   \n",
       "6276  Ni'rapa Jesús tü wayuu wattakat saalin nü'ütpa...   \n",
       "265                                  ¿Kasa paa Ꞌinraka?   \n",
       "3210  Je ni'rataalain naa'in wane wayuu kanüliashi A...   \n",
       "\n",
       "                                                    esp  \n",
       "5981  Ha hecho lo que estaba en su mano preparando p...  \n",
       "3491  Y esto para ver si, aunque fuese a tientas, pu...  \n",
       "6276  Viendo Jesús que lo rodeaba una gran multitud,...  \n",
       "265                                         ¿Qué haces?  \n",
       "3210  y acaba de tener una visión en la que un hombr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 764 entries, 4233 to 682\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     764 non-null    object\n",
      " 1   esp     764 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>Wanaa sümaa naapinnüin nüchiki Lázaro sünain a...</td>\n",
       "      <td>Jesús tenía una gran amistad con Marta, con su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>“Je jalia pia suulia kaainjalaa sükajee tü kas...</td>\n",
       "      <td>Y si tu pie va a ser causa de que caigas en pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>eeinjanale kepiain naya wane'ere'eya ouktapa H...</td>\n",
       "      <td>donde permaneció hasta la muerte de Herodes. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>Joutaa mama anterru joluu</td>\n",
       "      <td>Y también viene tu mamá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>Süka jamüin, tü taküjakat, nnojotsü tale'eru'u...</td>\n",
       "      <td>Porque yo no hablo por mi cuenta; el Padre, qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "4233  Wanaa sümaa naapinnüin nüchiki Lázaro sünain a...   \n",
       "5827  “Je jalia pia suulia kaainjalaa sükajee tü kas...   \n",
       "6131  eeinjanale kepiain naya wane'ere'eya ouktapa H...   \n",
       "7628                          Joutaa mama anterru joluu   \n",
       "4325  Süka jamüin, tü taküjakat, nnojotsü tale'eru'u...   \n",
       "\n",
       "                                                    esp  \n",
       "4233  Jesús tenía una gran amistad con Marta, con su...  \n",
       "5827  Y si tu pie va a ser causa de que caigas en pe...  \n",
       "6131  donde permaneció hasta la muerte de Herodes. A...  \n",
       "7628                            Y también viene tu mamá  \n",
       "4325  Porque yo no hablo por mi cuenta; el Padre, qu...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>way</th>\n",
       "      <th>way_words</th>\n",
       "      <th>way_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>dijeron Aarón: Haznos dioses que nos guíen en ...</td>\n",
       "      <td>[dijeron, Aarón, :, Haznos, dioses, que, nos, ...</td>\n",
       "      <td>[▁di, jeron, ▁Aar, ón, :, ▁Haz, nos, ▁di, oses...</td>\n",
       "      <td>Süka kama'ain Moisés saa'u tü uuchikat, müshii...</td>\n",
       "      <td>[Süka, kama, ', ain, Moisés, saa, ', u, tü, uu...</td>\n",
       "      <td>[▁Sü, ka, ▁kama, ', ain, ▁Moisés, ▁saa, ', u, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>Entonces volvieron a preguntar al que había si...</td>\n",
       "      <td>[Entonces, volvieron, a, preguntar, al, que, h...</td>\n",
       "      <td>[▁Entonces, ▁vol, vieron, ▁a, ▁preguntar, ▁al,...</td>\n",
       "      <td>nasakirakalaka chi mo'upü'ükai nüchikua'aya:—P...</td>\n",
       "      <td>[nasakirakalaka, chi, mo, ', upü, ', ükai, nüc...</td>\n",
       "      <td>[▁nas, akir, aka, laka, ▁chi, ▁mo, ', up, ü, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>No se vayan por allá y no vayan ustedes a esta...</td>\n",
       "      <td>[No, se, vayan, por, allá, y, no, vayan, usted...</td>\n",
       "      <td>[▁No, ▁se, ▁v, ayan, ▁por, ▁allá, ▁y, ▁no, ▁v,...</td>\n",
       "      <td>Nnojolü maata jo'unuin chapünaa chaa'a ya, ee ...</td>\n",
       "      <td>[Nnojolü, maata, jo, ', unuin, chapünaa, chaa,...</td>\n",
       "      <td>[▁N, noj, ol, ü, ▁maata, ▁jo, ', unu, in, ▁cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>Le preguntaron:—¿Dónde quieres que la preparemos?</td>\n",
       "      <td>[Le, preguntaron, :, —, ¿, Dónde, quieres, que...</td>\n",
       "      <td>[▁Le, ▁pregunt, aron, :, —, ¿, Dónde, ▁quieres...</td>\n",
       "      <td>—¿Jalasü pücheküin süpüleerua wekeraajüin shia...</td>\n",
       "      <td>[—, ¿, Jalasü, pücheküin, süpüleerua, wekeraaj...</td>\n",
       "      <td>[▁, —, ¿, J, alas, ü, ▁pü, ch, ek, ü, in, ▁sü,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158</th>\n",
       "      <td>Fue el pecado el que, aprovechando la ocasión ...</td>\n",
       "      <td>[Fue, el, pecado, el, que, ,, aprovechando, la...</td>\n",
       "      <td>[▁Fue, ▁el, ▁pe, cado, ▁el, ▁que, ,, ▁aprove, ...</td>\n",
       "      <td>Je tatüjaapa saa'u sütüma tü nüshajakat Moisés...</td>\n",
       "      <td>[Je, tatüjaapa, saa, ', u, sütüma, tü, nüshaja...</td>\n",
       "      <td>[▁Je, ▁tat, ü, ja, apa, ▁saa, ', u, ▁süt, ü, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    esp  \\\n",
       "3147  dijeron Aarón: Haznos dioses que nos guíen en ...   \n",
       "4171  Entonces volvieron a preguntar al que había si...   \n",
       "1227  No se vayan por allá y no vayan ustedes a esta...   \n",
       "5369  Le preguntaron:—¿Dónde quieres que la preparemos?   \n",
       "7158  Fue el pecado el que, aprovechando la ocasión ...   \n",
       "\n",
       "                                              esp_words  \\\n",
       "3147  [dijeron, Aarón, :, Haznos, dioses, que, nos, ...   \n",
       "4171  [Entonces, volvieron, a, preguntar, al, que, h...   \n",
       "1227  [No, se, vayan, por, allá, y, no, vayan, usted...   \n",
       "5369  [Le, preguntaron, :, —, ¿, Dónde, quieres, que...   \n",
       "7158  [Fue, el, pecado, el, que, ,, aprovechando, la...   \n",
       "\n",
       "                                               esp_toks  \\\n",
       "3147  [▁di, jeron, ▁Aar, ón, :, ▁Haz, nos, ▁di, oses...   \n",
       "4171  [▁Entonces, ▁vol, vieron, ▁a, ▁preguntar, ▁al,...   \n",
       "1227  [▁No, ▁se, ▁v, ayan, ▁por, ▁allá, ▁y, ▁no, ▁v,...   \n",
       "5369  [▁Le, ▁pregunt, aron, :, —, ¿, Dónde, ▁quieres...   \n",
       "7158  [▁Fue, ▁el, ▁pe, cado, ▁el, ▁que, ,, ▁aprove, ...   \n",
       "\n",
       "                                                    way  \\\n",
       "3147  Süka kama'ain Moisés saa'u tü uuchikat, müshii...   \n",
       "4171  nasakirakalaka chi mo'upü'ükai nüchikua'aya:—P...   \n",
       "1227  Nnojolü maata jo'unuin chapünaa chaa'a ya, ee ...   \n",
       "5369  —¿Jalasü pücheküin süpüleerua wekeraajüin shia...   \n",
       "7158  Je tatüjaapa saa'u sütüma tü nüshajakat Moisés...   \n",
       "\n",
       "                                              way_words  \\\n",
       "3147  [Süka, kama, ', ain, Moisés, saa, ', u, tü, uu...   \n",
       "4171  [nasakirakalaka, chi, mo, ', upü, ', ükai, nüc...   \n",
       "1227  [Nnojolü, maata, jo, ', unuin, chapünaa, chaa,...   \n",
       "5369  [—, ¿, Jalasü, pücheküin, süpüleerua, wekeraaj...   \n",
       "7158  [Je, tatüjaapa, saa, ', u, sütüma, tü, nüshaja...   \n",
       "\n",
       "                                               way_toks  \n",
       "3147  [▁Sü, ka, ▁kama, ', ain, ▁Moisés, ▁saa, ', u, ...  \n",
       "4171  [▁nas, akir, aka, laka, ▁chi, ▁mo, ', up, ü, '...  \n",
       "1227  [▁N, noj, ol, ü, ▁maata, ▁jo, ', unu, in, ▁cha...  \n",
       "5369  [▁, —, ¿, J, alas, ü, ▁pü, ch, ek, ü, in, ▁sü,...  \n",
       "7158  [▁Je, ▁tat, ü, ja, apa, ▁saa, ', u, ▁süt, ü, m...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_320182/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>way_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>way_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.243400</td>\n",
       "      <td>72.408600</td>\n",
       "      <td>25.910800</td>\n",
       "      <td>36.495100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47.974413</td>\n",
       "      <td>103.070418</td>\n",
       "      <td>38.361494</td>\n",
       "      <td>51.161899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1390.000000</td>\n",
       "      <td>3173.000000</td>\n",
       "      <td>1149.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks      way_toks     esp_words     way_words\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean      32.243400     72.408600     25.910800     36.495100\n",
       "std       47.974413    103.070418     38.361494     51.161899\n",
       "min        1.000000      1.000000      1.000000      1.000000\n",
       "25%       19.000000     39.000000     15.000000     20.000000\n",
       "50%       28.000000     65.000000     22.000000     33.000000\n",
       "75%       38.000000     89.000000     31.000000     45.000000\n",
       "max     1390.000000   3173.000000   1149.000000   1562.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2444000185250939\n",
      "1.9840636140194166\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fa57c45c104b889ef7c06c1235c104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2806\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Nasakirakalaka nia:—¿Jamüshii naküjaka'a na karalouktamaajanakana nüchiki Elías sünain niainjachin antüin palajana nüpüleerua chi Cristo Nüneekajalakai Maleiwa? —namakalaka nümüin.\",\n",
       " \"Je sünüiki wayuu süpüshua so'uweena tia: “Anasüje sujuttüle tü uuchikalüirua waa'u”, meerü süka mülo'ujeerüin ma'i tü müliaakat namüin.\",\n",
       " 'Tajütüinjachi pia puumainpa ’amüin - müshi  laülaakai.',\n",
       " \"Je tü wayuukolüirua, meerü shia jümüin: ‘Jiirakaa, ichaa chi Shipayakai Wayuu cha'aya’ oo'ulaka ‘Jiirakaa, anii nia yaaya’. Nnojo ju'unüin shi'ipajee tia sünain jüchajaain tachiki.\",\n",
       " \"Je jikerolapa sulu'u tü miichikat, ‘Eeshi Maleiwa jümaa’, meena jia namüin na kepiakana sulu'u.\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "s = random.sample(texts_with_unk, 5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace 𝓕𝔯𝔞𝔫𝔠𝔢𝔰𝔠𝔞 by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451051cb486f477187b3cf94d4bd11e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2806 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4c5558f5254bdd8fbc487a5052090a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_wayuu_esp_sin_dict_1_3B-V2/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_wayuu_esp_sin_dict_1_3B-V2/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2048\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: ainüestkulj'mohpwryc.,JMNASú-\":OdTPC¿?EíWbéKgáIf23ó14LBGD5vYzFꞋꞌH70Rq6[]89Z¡!;)ñÉ(UxØVÜ/_\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_wayuu_esp_sin_dict_1_3B-V2/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 7635 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=1437326\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=105\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 7635 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=927992\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 43311 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 7635\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 27060\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 27060 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=15090 obj=14.3611 num_tokens=72167 num_tokens/piece=4.78244\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12482 obj=11.107 num_tokens=72613 num_tokens/piece=5.81742\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9353 obj=11.0782 num_tokens=74947 num_tokens/piece=8.01315\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9319 obj=11.0264 num_tokens=74999 num_tokens/piece=8.04797\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=6988 obj=11.1552 num_tokens=79186 num_tokens/piece=11.3317\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=6986 obj=11.1129 num_tokens=79223 num_tokens/piece=11.3403\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5239 obj=11.3145 num_tokens=84191 num_tokens/piece=16.0701\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5239 obj=11.2641 num_tokens=84189 num_tokens/piece=16.0697\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3929 obj=11.5211 num_tokens=89641 num_tokens/piece=22.8152\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3929 obj=11.4635 num_tokens=89651 num_tokens/piece=22.8178\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2946 obj=11.7742 num_tokens=95778 num_tokens/piece=32.5112\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2946 obj=11.7078 num_tokens=95775 num_tokens/piece=32.5102\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2252 obj=12.0386 num_tokens=101850 num_tokens/piece=45.2265\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2252 obj=11.9674 num_tokens=101853 num_tokens/piece=45.2278\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_wayuu_esp_sin_dict_1_3B-V2/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_wayuu_esp_sin_dict_1_3B-V2/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**11,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-16 10:22:48--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‘/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py’\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-16 10:22:48 (52.8 MB/s) - ‘/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py’ saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256204 257724\n",
      "1519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 10:22:52.129199: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-16 10:22:52.270295: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-16 10:22:53.012294: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-16 10:22:53.012362: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-16 10:22:53.012367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 257724. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0059f7e878548fba830e7b8412d098a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257724\n",
      "['zul_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256203 + len(added_vocab) + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'way_Latn', '<mask>']\n",
      "[257722, 257723, 257724]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256202 + len(added_vocab) + 2, 256202 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257723 257538\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 257725. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(257725, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([\"Sünainjee ayaakuwaakairua piyu'la süchiki süka pünüiki.\"], ['Con estas imágenes van a armar una historia con sus propias palabras.'], 'way_Latn', 'spa_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627324fdd2d8463890e1d7744735830b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.902059555053711\n",
      "1000 3.9136983239650727\n",
      "2000 2.2290843242406844\n",
      "3000 1.5212472704648972\n",
      "4000 1.0565567362904549\n",
      "5000 0.7444994303584099\n",
      "6000 0.5271086331233382\n",
      "7000 0.3788785894960165\n",
      "8000 0.2750394050255418\n",
      "9000 0.20599242202192544\n",
      "10000 0.16559879416786133\n",
      "11000 0.1396648780591786\n",
      "12000 0.11479668705537915\n",
      "13000 0.09658769210614264\n",
      "14000 0.08218583373818547\n",
      "15000 0.07329277908522636\n",
      "16000 0.06855591662786902\n",
      "17000 0.06077122840750963\n",
      "18000 0.05393795684445649\n",
      "19000 0.0505776533014141\n",
      "20000 0.04683107604738325\n",
      "21000 0.04548560573533177\n",
      "22000 0.04088370854500681\n",
      "23000 0.037132929598912595\n",
      "24000 0.03766237500682473\n",
      "25000 0.03603599041001871\n",
      "26000 0.032469453578814866\n",
      "27000 0.032187555831391365\n",
      "28000 0.03184228764148429\n",
      "29000 0.029299610102549195\n",
      "30000 0.029127615751698612\n",
      "31000 0.027360065940301867\n",
      "32000 0.02605831712973304\n",
      "33000 0.024985419590258972\n",
      "34000 0.024116715609794483\n",
      "35000 0.023490903279045596\n",
      "36000 0.02327422091853805\n",
      "37000 0.023443988183978946\n",
      "38000 0.022352272200863808\n",
      "39000 0.021492355541326107\n",
      "40000 0.020471871632849796\n",
      "41000 0.021330000623129307\n",
      "42000 0.02004223025497049\n",
      "43000 0.020026061073760502\n",
      "44000 0.019300211197696628\n",
      "45000 0.019444772640010342\n",
      "46000 0.018589185778284445\n",
      "47000 0.018307851323392244\n",
      "48000 0.017841348039510194\n",
      "49000 0.01729171284486074\n",
      "50000 0.017195274468627758\n",
      "51000 0.015978755253134296\n",
      "52000 0.01644976315810345\n",
      "53000 0.015906016521388663\n",
      "54000 0.015789681950118394\n",
      "55000 0.015725120076793248\n",
      "56000 0.015026523580658249\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jesús hizo en presencia de sus discípulos otros muchos milagros que no han sido recogidos en este libro.']\n",
      "[\"Wainma kasa anasü naa'inrapü'ükat Jesús no'upala na nikirajüinkana, tü kasa nütüjakat apüleerua Maleiwa nümüiwa. Otta nnojotsü tashajüin süpüshua sulu'u tü karalouktakat.\"]\n",
      "[\"Naa'inrüin Jesús wainma kasa nütüjakat apüleerua Maleiwa nümüiwa su'upala tü wayuukolüirua. Nnojotsü pii'iyatüin achiki sulu'u tü karalouktakat.\"]\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.2G\n",
      "4.0K drwxrwxr-x  2 americasnlp americasnlp 4.0K Mar 16 10:41 .\n",
      "4.0K drwxrwxr-x 10 americasnlp americasnlp 4.0K Mar 16 18:57 ..\n",
      "1.5M -rw-rw-r--  1 americasnlp americasnlp 1.5M Mar 16 10:22 all_texts_file.csv\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  848 Mar 17 02:38 config.json\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  184 Mar 17 02:38 generation_config.json\n",
      "5.2G -rw-rw-r--  1 americasnlp americasnlp 5.2G Mar 17 02:38 pytorch_model.bin\n",
      "4.7M -rw-rw-r--  1 americasnlp americasnlp 4.7M Mar 17 02:38 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp 3.5K Mar 17 02:38 special_tokens_map.json\n",
      "268K -rw-rw-r--  1 americasnlp americasnlp 267K Mar 16 10:22 spm_16k.model\n",
      " 40K -rw-rw-r--  1 americasnlp americasnlp  37K Mar 16 10:22 spm_16k.vocab\n",
      "4.7M -rw-rw-r--  1 americasnlp americasnlp 4.7M Mar 16 10:22 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  570 Mar 17 02:38 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tüü jayeechi aisü tapüla']\n"
     ]
    }
   ],
   "source": [
    "t = \"las canciones de amor me gustan mucho\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chaanüii cintashaatasü tanüiki']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Miguel está contento con el criollo [que se quedó mi pajarito]']\n"
     ]
    }
   ],
   "source": [
    "t = \"kuyakuyllawan takitam anchata kuyani\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Todavía cocina pajarito rojo']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f417b55202147e2a13b50aae7a9d0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ec63108a434d499c4f0304ab568969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 15.37 41.3/17.9/12.0/9.1 (BP = 0.911 ratio = 0.915 hyp_len = 17832 ref_len = 19488)\n",
      "chrF2++ = 32.06\n",
      "BLEU = 18.93 46.7/23.6/15.8/11.9 (BP = 0.886 ratio = 0.892 hyp_len = 18662 ref_len = 20913)\n",
      "chrF2++ = 42.79\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "      <th>way_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Ojutuushi taya sa a'ujee mootokaa aliikama 'inka, eweetüsü  wanee p üliikü tapüleeru wa</td>\n",
       "      <td>Antes de ayer  me caí de la moto, se me atravesó un burro</td>\n",
       "      <td>Antalaa kaꞋikaa, ojunuuüshi taya moto'opünaa, nülatiraakalaka taya wanee püliikü</td>\n",
       "      <td>Yo me lanzo al medio de un motín, hay un motín cerca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>Ananajüsü tü wayuukolüirua naa'u Jesús wanaa sümaa nükachennüin sünain kuruusa. Otta na sülaülak...</td>\n",
       "      <td>La gente estaba allí mirando, mientras las autoridades se burlaban de Jesús, diciendo:—Puesto qu...</td>\n",
       "      <td>Je tü wayuukolüirua, shi'rüinjase'e tü naa'inrakat Jesús. Otta na laülaayuukana, na'ülüjünaakala...</td>\n",
       "      <td>Los judíos alabaron Jesús y lo golpeaban con insultos. - ¿No eres tú el Mesías? ¡Pues sálvate a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>Anakaja müleka jükaaliijale na wayuu eekai püreesain, müinjana aka püreesakai jia wanaa namaa. J...</td>\n",
       "      <td>Tengan siempre presentes a los encarcelados como si ustedes mismos se encontraran presos junto c...</td>\n",
       "      <td>Anakaja müleka jümüliarüle naa'in na juwalayuukana eekai püreesain, maa aka jümülialain jia wana...</td>\n",
       "      <td>Tengan compasión de los que están en la cárcel como compañeros de prisión; tengan compasión de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>Nüsouktakalaka Jesús namüin:—Shiimüin sünain niainjachin Elías antüin palajana süpüla yapainjatü...</td>\n",
       "      <td>Jesús les contestó:—Es cierto que Elías ha de venir y ha de ponerlo todo en orden.</td>\n",
       "      <td>Nüsouktakalaka Jesús namüin: - Shiimüin sünain antüin Elías sünain anouktaa sukuaippa wayuu süpü...</td>\n",
       "      <td>Jesús le contestó: - Es cierto que Elías ha de venir primero para traer de la paz a toda la huma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>Katünayaa müshii naya maa aka saa'in sütüna wuchii. Aippiruasüwai natüna wane'ewai nakua. Je ko'...</td>\n",
       "      <td>Cada uno de los cuatro seres vivientes tenía seis alas y eran todo ojos por fuera y por dentro. ...</td>\n",
       "      <td>Je wane'ewai nakua na pienchishii kato'uchiikana, kasüpüshua'a ma'i no'u. Otta nayakana, ayatshi...</td>\n",
       "      <td>Sus mentes serán como de osota, armadas de poderosos aguijones que pertenecen al Reino.Ministros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>Ja'itaina jia aapüin süchiki kasachiki sainküin mmakat süpüshua, nnojo jainkuuin aa'in sütüma. J...</td>\n",
       "      <td>Llegarán a oídos de ustedes noticias de guerras y rumores de conflictos bélicos. No se alarmen, ...</td>\n",
       "      <td>Ja'itaina jia aapüin süchiki kasachiki sainküin mmakat süpüshua, nnojo jainkuuin aa'in sütüma. J...</td>\n",
       "      <td>Cuando oigan noticias de guerras y rumores de conflictos bélicos, no se alarmen. Aunque todo eso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>“ ‘Shiimüin ma'i tü tamakat jümüin: Chi wayuu eekai koo'omüin nütüma tü aapünakat nümüin, aapüne...</td>\n",
       "      <td>«Es cierto —asintió el rey—, pero yo les digo que a todo el que tiene, se le dará más. En cambio...</td>\n",
       "      <td>Shiimüin sünain niain aluwataainjachin chi aluwataashikai. Otta tayakai chi eekai nütüjain tü aa...</td>\n",
       "      <td>Porque a todo el que tiene, aún se le dará más, y tendrá de sobra; pero al que no tiene, hasta l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Tayakaa, talatüsü taya süka jemetüin jümüin</td>\n",
       "      <td>Yo, me alegro que les haya gustado.</td>\n",
       "      <td>Talatashaanashi taya süka talatüin ma'in taa'in jümüin.</td>\n",
       "      <td>Yo sí, estoy contenta de tenerlos a todos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>Je nüntapa nünain, nümaashi nia Antioquíamüin, eejanale naya kettatüin wane juya natüma sünain o...</td>\n",
       "      <td>Cuando lo encontró, lo llevó consigo Antioquía. Y a lo largo de todo un año trabajaron los dos j...</td>\n",
       "      <td>Je nüntapa nia, no'unirüin nia nipialu'umüin tü outkajaaleekat cha'aya. Eeshi Pablo nümaa Bernab...</td>\n",
       "      <td>A su llegada, se puso en camino y pasó dos años con ellos, enseñando con gran exactitud en lo qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>Eirakaataalasü joo taa'in iipünaamüin. Te'rataalakalaka joo chi Anneetchonkai sha'watüin cha'aya...</td>\n",
       "      <td>Volví a mirar, y vi al Cordero de pie sobre el monte de Sion. Lo acompañaban los ciento cuarenta...</td>\n",
       "      <td>Eweeta müshia taya tachikua, te'rakalaka chi Anneetchonkai sha'watüin chaa naa'u chi Maleiwakai ...</td>\n",
       "      <td>Vi al Cordero, que estaba en pie del monte de Sion, mientras mensajeros llevaban el nombre del C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      way  \\\n",
       "676               Ojutuushi taya sa a'ujee mootokaa aliikama 'inka, eweetüsü  wanee p üliikü tapüleeru wa   \n",
       "5447  Ananajüsü tü wayuukolüirua naa'u Jesús wanaa sümaa nükachennüin sünain kuruusa. Otta na sülaülak...   \n",
       "2925  Anakaja müleka jükaaliijale na wayuu eekai püreesain, müinjana aka püreesakai jia wanaa namaa. J...   \n",
       "6565  Nüsouktakalaka Jesús namüin:—Shiimüin sünain niainjachin Elías antüin palajana süpüla yapainjatü...   \n",
       "1670  Katünayaa müshii naya maa aka saa'in sütüna wuchii. Aippiruasüwai natüna wane'ewai nakua. Je ko'...   \n",
       "6786  Ja'itaina jia aapüin süchiki kasachiki sainküin mmakat süpüshua, nnojo jainkuuin aa'in sütüma. J...   \n",
       "5277  “ ‘Shiimüin ma'i tü tamakat jümüin: Chi wayuu eekai koo'omüin nütüma tü aapünakat nümüin, aapüne...   \n",
       "472                                                           Tayakaa, talatüsü taya süka jemetüin jümüin   \n",
       "3309  Je nüntapa nünain, nümaashi nia Antioquíamüin, eejanale naya kettatüin wane juya natüma sünain o...   \n",
       "1790  Eirakaataalasü joo taa'in iipünaamüin. Te'rataalakalaka joo chi Anneetchonkai sha'watüin cha'aya...   \n",
       "\n",
       "                                                                                                      esp  \\\n",
       "676                                             Antes de ayer  me caí de la moto, se me atravesó un burro   \n",
       "5447  La gente estaba allí mirando, mientras las autoridades se burlaban de Jesús, diciendo:—Puesto qu...   \n",
       "2925  Tengan siempre presentes a los encarcelados como si ustedes mismos se encontraran presos junto c...   \n",
       "6565                   Jesús les contestó:—Es cierto que Elías ha de venir y ha de ponerlo todo en orden.   \n",
       "1670  Cada uno de los cuatro seres vivientes tenía seis alas y eran todo ojos por fuera y por dentro. ...   \n",
       "6786  Llegarán a oídos de ustedes noticias de guerras y rumores de conflictos bélicos. No se alarmen, ...   \n",
       "5277  «Es cierto —asintió el rey—, pero yo les digo que a todo el que tiene, se le dará más. En cambio...   \n",
       "472                                                                   Yo, me alegro que les haya gustado.   \n",
       "3309  Cuando lo encontró, lo llevó consigo Antioquía. Y a lo largo de todo un año trabajaron los dos j...   \n",
       "1790  Volví a mirar, y vi al Cordero de pie sobre el monte de Sion. Lo acompañaban los ciento cuarenta...   \n",
       "\n",
       "                                                                                           way_translated  \\\n",
       "676                      Antalaa kaꞋikaa, ojunuuüshi taya moto'opünaa, nülatiraakalaka taya wanee püliikü   \n",
       "5447  Je tü wayuukolüirua, shi'rüinjase'e tü naa'inrakat Jesús. Otta na laülaayuukana, na'ülüjünaakala...   \n",
       "2925  Anakaja müleka jümüliarüle naa'in na juwalayuukana eekai püreesain, maa aka jümülialain jia wana...   \n",
       "6565  Nüsouktakalaka Jesús namüin: - Shiimüin sünain antüin Elías sünain anouktaa sukuaippa wayuu süpü...   \n",
       "1670  Je wane'ewai nakua na pienchishii kato'uchiikana, kasüpüshua'a ma'i no'u. Otta nayakana, ayatshi...   \n",
       "6786  Ja'itaina jia aapüin süchiki kasachiki sainküin mmakat süpüshua, nnojo jainkuuin aa'in sütüma. J...   \n",
       "5277  Shiimüin sünain niain aluwataainjachin chi aluwataashikai. Otta tayakai chi eekai nütüjain tü aa...   \n",
       "472                                               Talatashaanashi taya süka talatüin ma'in taa'in jümüin.   \n",
       "3309  Je nüntapa nia, no'unirüin nia nipialu'umüin tü outkajaaleekat cha'aya. Eeshi Pablo nümaa Bernab...   \n",
       "1790  Eweeta müshia taya tachikua, te'rakalaka chi Anneetchonkai sha'watüin chaa naa'u chi Maleiwakai ...   \n",
       "\n",
       "                                                                                           esp_translated  \n",
       "676                                                  Yo me lanzo al medio de un motín, hay un motín cerca  \n",
       "5447  Los judíos alabaron Jesús y lo golpeaban con insultos. - ¿No eres tú el Mesías? ¡Pues sálvate a ...  \n",
       "2925  Tengan compasión de los que están en la cárcel como compañeros de prisión; tengan compasión de l...  \n",
       "6565  Jesús le contestó: - Es cierto que Elías ha de venir primero para traer de la paz a toda la huma...  \n",
       "1670  Sus mentes serán como de osota, armadas de poderosos aguijones que pertenecen al Reino.Ministros...  \n",
       "6786  Cuando oigan noticias de guerras y rumores de conflictos bélicos, no se alarmen. Aunque todo eso...  \n",
       "5277  Porque a todo el que tiene, aún se le dará más, y tendrá de sobra; pero al que no tiene, hasta l...  \n",
       "472                                                            Yo sí, estoy contenta de tenerlos a todos.  \n",
       "3309  A su llegada, se puso en camino y pasó dos años con ellos, enseñando con gran exactitud en lo qu...  \n",
       "1790  Vi al Cordero, que estaba en pie del monte de Sion, mientras mensajeros llevaban el nombre del C...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776cf77-7387-40e4-8941-ab345fb844ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
