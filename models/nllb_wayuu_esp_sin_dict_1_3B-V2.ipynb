{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=2\n",
    "# MODEL_USED=\"facebook/nllb-200-distilled-600M\"\n",
    "MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_wayuu_esp_sin_dict_1_3B-V2\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"way_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"ayr_Latn\" # Central Aymara\n",
    "LANGUAGE_FILE=\"data/wayuu_completo_sin_dic_v2.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"way\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7635, 2)\n",
      "Index(['way', 'esp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6108 entries, 216 to 7270\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     6108 non-null   object\n",
      " 1   esp     6108 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 143.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Ant√ºs√º wanee palajana, ant√ºs√º wanee mapan.</td>\n",
       "      <td>Lleg√≥ primero una, lleg√≥ otra despu√©s.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>N√ºsouktakalaka Jes√∫s n√ºm√ºin:‚ÄîTam√ºs√º paala p√ºm√º...</td>\n",
       "      <td>Jes√∫s le contest√≥:‚ÄîEl que me ama de verdad se ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>Anainja tojuitt√ºle yaajee tale'ejaiwa n√ºnainm√º...</td>\n",
       "      <td>Volver√© a mi padre y le dir√©: Padre, he pecado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>¬øEes√º asalaa cha Íûåaya suluÍûåu  aikaaleekal√º?</td>\n",
       "      <td>¬øHay carne all√° en la tienda?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Aa, antajachi taya si'iral√ºin m√ºshia ekirajaai...</td>\n",
       "      <td>Si, el profesor me dijo que viniera en guayuco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "216          Ant√ºs√º wanee palajana, ant√ºs√º wanee mapan.   \n",
       "4383  N√ºsouktakalaka Jes√∫s n√ºm√ºin:‚ÄîTam√ºs√º paala p√ºm√º...   \n",
       "5163  Anainja tojuitt√ºle yaajee tale'ejaiwa n√ºnainm√º...   \n",
       "421         ¬øEes√º asalaa cha Íûåaya suluÍûåu  aikaaleekal√º?   \n",
       "505   Aa, antajachi taya si'iral√ºin m√ºshia ekirajaai...   \n",
       "\n",
       "                                                    esp  \n",
       "216              Lleg√≥ primero una, lleg√≥ otra despu√©s.  \n",
       "4383  Jes√∫s le contest√≥:‚ÄîEl que me ama de verdad se ...  \n",
       "5163  Volver√© a mi padre y le dir√©: Padre, he pecado...  \n",
       "421                       ¬øHay carne all√° en la tienda?  \n",
       "505   Si, el profesor me dijo que viniera en guayuco...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 763 entries, 5981 to 5799\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     763 non-null    object\n",
      " 1   esp     763 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>S√ºkajee t√º√º, shii'iyat√ºin tam√ºin tojut s√ºp√ºlap...</td>\n",
       "      <td>Ha hecho lo que estaba en su mano preparando p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>N√ºkumaj√ºin shia Maleiwakai s√ºp√ºla s√ºchajaainja...</td>\n",
       "      <td>Y esto para ver si, aunque fuese a tientas, pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>Ni'rapa Jes√∫s t√º wayuu wattakat saalin n√º'√ºtpa...</td>\n",
       "      <td>Viendo Jes√∫s que lo rodeaba una gran multitud,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>¬øKasa paa Íûãinraka?</td>\n",
       "      <td>¬øQu√© haces?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>Je ni'rataalain naa'in wane wayuu kan√ºliashi A...</td>\n",
       "      <td>y acaba de tener una visi√≥n en la que un hombr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "5981  S√ºkajee t√º√º, shii'iyat√ºin tam√ºin tojut s√ºp√ºlap...   \n",
       "3491  N√ºkumaj√ºin shia Maleiwakai s√ºp√ºla s√ºchajaainja...   \n",
       "6276  Ni'rapa Jes√∫s t√º wayuu wattakat saalin n√º'√ºtpa...   \n",
       "265                                  ¬øKasa paa Íûãinraka?   \n",
       "3210  Je ni'rataalain naa'in wane wayuu kan√ºliashi A...   \n",
       "\n",
       "                                                    esp  \n",
       "5981  Ha hecho lo que estaba en su mano preparando p...  \n",
       "3491  Y esto para ver si, aunque fuese a tientas, pu...  \n",
       "6276  Viendo Jes√∫s que lo rodeaba una gran multitud,...  \n",
       "265                                         ¬øQu√© haces?  \n",
       "3210  y acaba de tener una visi√≥n en la que un hombr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 764 entries, 4233 to 682\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     764 non-null    object\n",
      " 1   esp     764 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>Wanaa s√ºmaa naapinn√ºin n√ºchiki L√°zaro s√ºnain a...</td>\n",
       "      <td>Jes√∫s ten√≠a una gran amistad con Marta, con su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>‚ÄúJe jalia pia suulia kaainjalaa s√ºkajee t√º kas...</td>\n",
       "      <td>Y si tu pie va a ser causa de que caigas en pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>eeinjanale kepiain naya wane'ere'eya ouktapa H...</td>\n",
       "      <td>donde permaneci√≥ hasta la muerte de Herodes. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>Joutaa mama anterru joluu</td>\n",
       "      <td>Y tambi√©n viene tu mam√°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>S√ºka jam√ºin, t√º tak√ºjakat, nnojots√º tale'eru'u...</td>\n",
       "      <td>Porque yo no hablo por mi cuenta; el Padre, qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "4233  Wanaa s√ºmaa naapinn√ºin n√ºchiki L√°zaro s√ºnain a...   \n",
       "5827  ‚ÄúJe jalia pia suulia kaainjalaa s√ºkajee t√º kas...   \n",
       "6131  eeinjanale kepiain naya wane'ere'eya ouktapa H...   \n",
       "7628                          Joutaa mama anterru joluu   \n",
       "4325  S√ºka jam√ºin, t√º tak√ºjakat, nnojots√º tale'eru'u...   \n",
       "\n",
       "                                                    esp  \n",
       "4233  Jes√∫s ten√≠a una gran amistad con Marta, con su...  \n",
       "5827  Y si tu pie va a ser causa de que caigas en pe...  \n",
       "6131  donde permaneci√≥ hasta la muerte de Herodes. A...  \n",
       "7628                            Y tambi√©n viene tu mam√°  \n",
       "4325  Porque yo no hablo por mi cuenta; el Padre, qu...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>way</th>\n",
       "      <th>way_words</th>\n",
       "      <th>way_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>dijeron Aar√≥n: Haznos dioses que nos gu√≠en en ...</td>\n",
       "      <td>[dijeron, Aar√≥n, :, Haznos, dioses, que, nos, ...</td>\n",
       "      <td>[‚ñÅdi, jeron, ‚ñÅAar, √≥n, :, ‚ñÅHaz, nos, ‚ñÅdi, oses...</td>\n",
       "      <td>S√ºka kama'ain Mois√©s saa'u t√º uuchikat, m√ºshii...</td>\n",
       "      <td>[S√ºka, kama, ', ain, Mois√©s, saa, ', u, t√º, uu...</td>\n",
       "      <td>[‚ñÅS√º, ka, ‚ñÅkama, ', ain, ‚ñÅMois√©s, ‚ñÅsaa, ', u, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>Entonces volvieron a preguntar al que hab√≠a si...</td>\n",
       "      <td>[Entonces, volvieron, a, preguntar, al, que, h...</td>\n",
       "      <td>[‚ñÅEntonces, ‚ñÅvol, vieron, ‚ñÅa, ‚ñÅpreguntar, ‚ñÅal,...</td>\n",
       "      <td>nasakirakalaka chi mo'up√º'√ºkai n√ºchikua'aya:‚ÄîP...</td>\n",
       "      <td>[nasakirakalaka, chi, mo, ', up√º, ', √ºkai, n√ºc...</td>\n",
       "      <td>[‚ñÅnas, akir, aka, laka, ‚ñÅchi, ‚ñÅmo, ', up, √º, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>No se vayan por all√° y no vayan ustedes a esta...</td>\n",
       "      <td>[No, se, vayan, por, all√°, y, no, vayan, usted...</td>\n",
       "      <td>[‚ñÅNo, ‚ñÅse, ‚ñÅv, ayan, ‚ñÅpor, ‚ñÅall√°, ‚ñÅy, ‚ñÅno, ‚ñÅv,...</td>\n",
       "      <td>Nnojol√º maata jo'unuin chap√ºnaa chaa'a ya, ee ...</td>\n",
       "      <td>[Nnojol√º, maata, jo, ', unuin, chap√ºnaa, chaa,...</td>\n",
       "      <td>[‚ñÅN, noj, ol, √º, ‚ñÅmaata, ‚ñÅjo, ', unu, in, ‚ñÅcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>Le preguntaron:‚Äî¬øD√≥nde quieres que la preparemos?</td>\n",
       "      <td>[Le, preguntaron, :, ‚Äî, ¬ø, D√≥nde, quieres, que...</td>\n",
       "      <td>[‚ñÅLe, ‚ñÅpregunt, aron, :, ‚Äî, ¬ø, D√≥nde, ‚ñÅquieres...</td>\n",
       "      <td>‚Äî¬øJalas√º p√ºchek√ºin s√ºp√ºleerua wekeraaj√ºin shia...</td>\n",
       "      <td>[‚Äî, ¬ø, Jalas√º, p√ºchek√ºin, s√ºp√ºleerua, wekeraaj...</td>\n",
       "      <td>[‚ñÅ, ‚Äî, ¬ø, J, alas, √º, ‚ñÅp√º, ch, ek, √º, in, ‚ñÅs√º,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158</th>\n",
       "      <td>Fue el pecado el que, aprovechando la ocasi√≥n ...</td>\n",
       "      <td>[Fue, el, pecado, el, que, ,, aprovechando, la...</td>\n",
       "      <td>[‚ñÅFue, ‚ñÅel, ‚ñÅpe, cado, ‚ñÅel, ‚ñÅque, ,, ‚ñÅaprove, ...</td>\n",
       "      <td>Je tat√ºjaapa saa'u s√ºt√ºma t√º n√ºshajakat Mois√©s...</td>\n",
       "      <td>[Je, tat√ºjaapa, saa, ', u, s√ºt√ºma, t√º, n√ºshaja...</td>\n",
       "      <td>[‚ñÅJe, ‚ñÅtat, √º, ja, apa, ‚ñÅsaa, ', u, ‚ñÅs√ºt, √º, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    esp  \\\n",
       "3147  dijeron Aar√≥n: Haznos dioses que nos gu√≠en en ...   \n",
       "4171  Entonces volvieron a preguntar al que hab√≠a si...   \n",
       "1227  No se vayan por all√° y no vayan ustedes a esta...   \n",
       "5369  Le preguntaron:‚Äî¬øD√≥nde quieres que la preparemos?   \n",
       "7158  Fue el pecado el que, aprovechando la ocasi√≥n ...   \n",
       "\n",
       "                                              esp_words  \\\n",
       "3147  [dijeron, Aar√≥n, :, Haznos, dioses, que, nos, ...   \n",
       "4171  [Entonces, volvieron, a, preguntar, al, que, h...   \n",
       "1227  [No, se, vayan, por, all√°, y, no, vayan, usted...   \n",
       "5369  [Le, preguntaron, :, ‚Äî, ¬ø, D√≥nde, quieres, que...   \n",
       "7158  [Fue, el, pecado, el, que, ,, aprovechando, la...   \n",
       "\n",
       "                                               esp_toks  \\\n",
       "3147  [‚ñÅdi, jeron, ‚ñÅAar, √≥n, :, ‚ñÅHaz, nos, ‚ñÅdi, oses...   \n",
       "4171  [‚ñÅEntonces, ‚ñÅvol, vieron, ‚ñÅa, ‚ñÅpreguntar, ‚ñÅal,...   \n",
       "1227  [‚ñÅNo, ‚ñÅse, ‚ñÅv, ayan, ‚ñÅpor, ‚ñÅall√°, ‚ñÅy, ‚ñÅno, ‚ñÅv,...   \n",
       "5369  [‚ñÅLe, ‚ñÅpregunt, aron, :, ‚Äî, ¬ø, D√≥nde, ‚ñÅquieres...   \n",
       "7158  [‚ñÅFue, ‚ñÅel, ‚ñÅpe, cado, ‚ñÅel, ‚ñÅque, ,, ‚ñÅaprove, ...   \n",
       "\n",
       "                                                    way  \\\n",
       "3147  S√ºka kama'ain Mois√©s saa'u t√º uuchikat, m√ºshii...   \n",
       "4171  nasakirakalaka chi mo'up√º'√ºkai n√ºchikua'aya:‚ÄîP...   \n",
       "1227  Nnojol√º maata jo'unuin chap√ºnaa chaa'a ya, ee ...   \n",
       "5369  ‚Äî¬øJalas√º p√ºchek√ºin s√ºp√ºleerua wekeraaj√ºin shia...   \n",
       "7158  Je tat√ºjaapa saa'u s√ºt√ºma t√º n√ºshajakat Mois√©s...   \n",
       "\n",
       "                                              way_words  \\\n",
       "3147  [S√ºka, kama, ', ain, Mois√©s, saa, ', u, t√º, uu...   \n",
       "4171  [nasakirakalaka, chi, mo, ', up√º, ', √ºkai, n√ºc...   \n",
       "1227  [Nnojol√º, maata, jo, ', unuin, chap√ºnaa, chaa,...   \n",
       "5369  [‚Äî, ¬ø, Jalas√º, p√ºchek√ºin, s√ºp√ºleerua, wekeraaj...   \n",
       "7158  [Je, tat√ºjaapa, saa, ', u, s√ºt√ºma, t√º, n√ºshaja...   \n",
       "\n",
       "                                               way_toks  \n",
       "3147  [‚ñÅS√º, ka, ‚ñÅkama, ', ain, ‚ñÅMois√©s, ‚ñÅsaa, ', u, ...  \n",
       "4171  [‚ñÅnas, akir, aka, laka, ‚ñÅchi, ‚ñÅmo, ', up, √º, '...  \n",
       "1227  [‚ñÅN, noj, ol, √º, ‚ñÅmaata, ‚ñÅjo, ', unu, in, ‚ñÅcha...  \n",
       "5369  [‚ñÅ, ‚Äî, ¬ø, J, alas, √º, ‚ñÅp√º, ch, ek, √º, in, ‚ñÅs√º,...  \n",
       "7158  [‚ñÅJe, ‚ñÅtat, √º, ja, apa, ‚ñÅsaa, ', u, ‚ñÅs√ºt, √º, m...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_320182/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>way_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>way_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.243400</td>\n",
       "      <td>72.408600</td>\n",
       "      <td>25.910800</td>\n",
       "      <td>36.495100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47.974413</td>\n",
       "      <td>103.070418</td>\n",
       "      <td>38.361494</td>\n",
       "      <td>51.161899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1390.000000</td>\n",
       "      <td>3173.000000</td>\n",
       "      <td>1149.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks      way_toks     esp_words     way_words\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean      32.243400     72.408600     25.910800     36.495100\n",
       "std       47.974413    103.070418     38.361494     51.161899\n",
       "min        1.000000      1.000000      1.000000      1.000000\n",
       "25%       19.000000     39.000000     15.000000     20.000000\n",
       "50%       28.000000     65.000000     22.000000     33.000000\n",
       "75%       38.000000     89.000000     31.000000     45.000000\n",
       "max     1390.000000   3173.000000   1149.000000   1562.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2444000185250939\n",
      "1.9840636140194166\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fa57c45c104b889ef7c06c1235c104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2806\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Nasakirakalaka nia:‚Äî¬øJam√ºshii nak√ºjaka'a na karalouktamaajanakana n√ºchiki El√≠as s√ºnain niainjachin ant√ºin palajana n√ºp√ºleerua chi Cristo N√ºneekajalakai Maleiwa? ‚Äînamakalaka n√ºm√ºin.\",\n",
       " \"Je s√ºn√ºiki wayuu s√ºp√ºshua so'uweena tia: ‚ÄúAnas√ºje sujutt√ºle t√º uuchikal√ºirua waa'u‚Äù, meer√º s√ºka m√ºlo'ujeer√ºin ma'i t√º m√ºliaakat nam√ºin.\",\n",
       " 'Taj√ºt√ºinjachi pia puumainpa ‚Äôam√ºin - m√ºshi  la√ºlaakai.',\n",
       " \"Je t√º wayuukol√ºirua, meer√º shia j√ºm√ºin: ‚ÄòJiirakaa, ichaa chi Shipayakai Wayuu cha'aya‚Äô oo'ulaka ‚ÄòJiirakaa, anii nia yaaya‚Äô. Nnojo ju'un√ºin shi'ipajee tia s√ºnain j√ºchajaain tachiki.\",\n",
       " \"Je jikerolapa sulu'u t√º miichikat, ‚ÄòEeshi Maleiwa j√ºmaa‚Äô, meena jia nam√ºin na kepiakana sulu'u.\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "s = random.sample(texts_with_unk, 5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace ùìïùîØùîûùî´ùî†ùî¢ùî∞ùî†ùîû by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451051cb486f477187b3cf94d4bd11e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2806 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4c5558f5254bdd8fbc487a5052090a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_wayuu_esp_sin_dict_1_3B-V2/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_wayuu_esp_sin_dict_1_3B-V2/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2048\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: ain√ºestkulj'mohpwryc.,JMNAS√∫-\":OdTPC¬ø?E√≠Wb√©Kg√°If23√≥14LBGD5vYzFÍûãÍûåH70Rq6[]89Z¬°!;)√±√â(Ux√òV√ú/_\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_wayuu_esp_sin_dict_1_3B-V2/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 7635 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=1437326\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=105\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 7635 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=927992\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 43311 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 7635\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 27060\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 27060 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=15090 obj=14.3611 num_tokens=72167 num_tokens/piece=4.78244\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12482 obj=11.107 num_tokens=72613 num_tokens/piece=5.81742\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9353 obj=11.0782 num_tokens=74947 num_tokens/piece=8.01315\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9319 obj=11.0264 num_tokens=74999 num_tokens/piece=8.04797\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=6988 obj=11.1552 num_tokens=79186 num_tokens/piece=11.3317\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=6986 obj=11.1129 num_tokens=79223 num_tokens/piece=11.3403\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5239 obj=11.3145 num_tokens=84191 num_tokens/piece=16.0701\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5239 obj=11.2641 num_tokens=84189 num_tokens/piece=16.0697\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3929 obj=11.5211 num_tokens=89641 num_tokens/piece=22.8152\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3929 obj=11.4635 num_tokens=89651 num_tokens/piece=22.8178\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2946 obj=11.7742 num_tokens=95778 num_tokens/piece=32.5112\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2946 obj=11.7078 num_tokens=95775 num_tokens/piece=32.5102\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2252 obj=12.0386 num_tokens=101850 num_tokens/piece=45.2265\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2252 obj=11.9674 num_tokens=101853 num_tokens/piece=45.2278\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_wayuu_esp_sin_dict_1_3B-V2/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_wayuu_esp_sin_dict_1_3B-V2/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**11,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-16 10:22:48--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-16 10:22:48 (52.8 MB/s) - ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256204 257724\n",
      "1519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 10:22:52.129199: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-16 10:22:52.270295: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-16 10:22:53.012294: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-16 10:22:53.012362: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-16 10:22:53.012367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 257724. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0059f7e878548fba830e7b8412d098a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257724\n",
      "['zul_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256203 + len(added_vocab) + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'way_Latn', '<mask>']\n",
      "[257722, 257723, 257724]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256202 + len(added_vocab) + 2, 256202 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257723 257538\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 257725. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(257725, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([\"S√ºnainjee ayaakuwaakairua piyu'la s√ºchiki s√ºka p√ºn√ºiki.\"], ['Con estas im√°genes van a armar una historia con sus propias palabras.'], 'way_Latn', 'spa_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627324fdd2d8463890e1d7744735830b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.902059555053711\n",
      "1000 3.9136983239650727\n",
      "2000 2.2290843242406844\n",
      "3000 1.5212472704648972\n",
      "4000 1.0565567362904549\n",
      "5000 0.7444994303584099\n",
      "6000 0.5271086331233382\n",
      "7000 0.3788785894960165\n",
      "8000 0.2750394050255418\n",
      "9000 0.20599242202192544\n",
      "10000 0.16559879416786133\n",
      "11000 0.1396648780591786\n",
      "12000 0.11479668705537915\n",
      "13000 0.09658769210614264\n",
      "14000 0.08218583373818547\n",
      "15000 0.07329277908522636\n",
      "16000 0.06855591662786902\n",
      "17000 0.06077122840750963\n",
      "18000 0.05393795684445649\n",
      "19000 0.0505776533014141\n",
      "20000 0.04683107604738325\n",
      "21000 0.04548560573533177\n",
      "22000 0.04088370854500681\n",
      "23000 0.037132929598912595\n",
      "24000 0.03766237500682473\n",
      "25000 0.03603599041001871\n",
      "26000 0.032469453578814866\n",
      "27000 0.032187555831391365\n",
      "28000 0.03184228764148429\n",
      "29000 0.029299610102549195\n",
      "30000 0.029127615751698612\n",
      "31000 0.027360065940301867\n",
      "32000 0.02605831712973304\n",
      "33000 0.024985419590258972\n",
      "34000 0.024116715609794483\n",
      "35000 0.023490903279045596\n",
      "36000 0.02327422091853805\n",
      "37000 0.023443988183978946\n",
      "38000 0.022352272200863808\n",
      "39000 0.021492355541326107\n",
      "40000 0.020471871632849796\n",
      "41000 0.021330000623129307\n",
      "42000 0.02004223025497049\n",
      "43000 0.020026061073760502\n",
      "44000 0.019300211197696628\n",
      "45000 0.019444772640010342\n",
      "46000 0.018589185778284445\n",
      "47000 0.018307851323392244\n",
      "48000 0.017841348039510194\n",
      "49000 0.01729171284486074\n",
      "50000 0.017195274468627758\n",
      "51000 0.015978755253134296\n",
      "52000 0.01644976315810345\n",
      "53000 0.015906016521388663\n",
      "54000 0.015789681950118394\n",
      "55000 0.015725120076793248\n",
      "56000 0.015026523580658249\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jes√∫s hizo en presencia de sus disc√≠pulos otros muchos milagros que no han sido recogidos en este libro.']\n",
      "[\"Wainma kasa anas√º naa'inrap√º'√ºkat Jes√∫s no'upala na nikiraj√ºinkana, t√º kasa n√ºt√ºjakat ap√ºleerua Maleiwa n√ºm√ºiwa. Otta nnojots√º tashaj√ºin s√ºp√ºshua sulu'u t√º karalouktakat.\"]\n",
      "[\"Naa'inr√ºin Jes√∫s wainma kasa n√ºt√ºjakat ap√ºleerua Maleiwa n√ºm√ºiwa su'upala t√º wayuukol√ºirua. Nnojots√º pii'iyat√ºin achiki sulu'u t√º karalouktakat.\"]\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.2G\n",
      "4.0K drwxrwxr-x  2 americasnlp americasnlp 4.0K Mar 16 10:41 .\n",
      "4.0K drwxrwxr-x 10 americasnlp americasnlp 4.0K Mar 16 18:57 ..\n",
      "1.5M -rw-rw-r--  1 americasnlp americasnlp 1.5M Mar 16 10:22 all_texts_file.csv\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  848 Mar 17 02:38 config.json\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  184 Mar 17 02:38 generation_config.json\n",
      "5.2G -rw-rw-r--  1 americasnlp americasnlp 5.2G Mar 17 02:38 pytorch_model.bin\n",
      "4.7M -rw-rw-r--  1 americasnlp americasnlp 4.7M Mar 17 02:38 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp 3.5K Mar 17 02:38 special_tokens_map.json\n",
      "268K -rw-rw-r--  1 americasnlp americasnlp 267K Mar 16 10:22 spm_16k.model\n",
      " 40K -rw-rw-r--  1 americasnlp americasnlp  37K Mar 16 10:22 spm_16k.vocab\n",
      "4.7M -rw-rw-r--  1 americasnlp americasnlp 4.7M Mar 16 10:22 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  570 Mar 17 02:38 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T√º√º jayeechi ais√º tap√ºla']\n"
     ]
    }
   ],
   "source": [
    "t = \"las canciones de amor me gustan mucho\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chaan√ºii cintashaatas√º tan√ºiki']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Miguel est√° contento con el criollo [que se qued√≥ mi pajarito]']\n"
     ]
    }
   ],
   "source": [
    "t = \"kuyakuyllawan takitam anchata kuyani\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Todav√≠a cocina pajarito rojo']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f417b55202147e2a13b50aae7a9d0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ec63108a434d499c4f0304ab568969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 15.37 41.3/17.9/12.0/9.1 (BP = 0.911 ratio = 0.915 hyp_len = 17832 ref_len = 19488)\n",
      "chrF2++ = 32.06\n",
      "BLEU = 18.93 46.7/23.6/15.8/11.9 (BP = 0.886 ratio = 0.892 hyp_len = 18662 ref_len = 20913)\n",
      "chrF2++ = 42.79\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "      <th>way_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Ojutuushi taya sa a'ujee mootokaa aliikama 'inka, eweet√ºs√º  wanee p √ºliik√º tap√ºleeru wa</td>\n",
       "      <td>Antes de ayer  me ca√≠ de la moto, se me atraves√≥ un burro</td>\n",
       "      <td>Antalaa kaÍûãikaa, ojunuu√ºshi taya moto'op√ºnaa, n√ºlatiraakalaka taya wanee p√ºliik√º</td>\n",
       "      <td>Yo me lanzo al medio de un mot√≠n, hay un mot√≠n cerca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>Ananaj√ºs√º t√º wayuukol√ºirua naa'u Jes√∫s wanaa s√ºmaa n√ºkachenn√ºin s√ºnain kuruusa. Otta na s√ºla√ºlak...</td>\n",
       "      <td>La gente estaba all√≠ mirando, mientras las autoridades se burlaban de Jes√∫s, diciendo:‚ÄîPuesto qu...</td>\n",
       "      <td>Je t√º wayuukol√ºirua, shi'r√ºinjase'e t√º naa'inrakat Jes√∫s. Otta na la√ºlaayuukana, na'√ºl√ºj√ºnaakala...</td>\n",
       "      <td>Los jud√≠os alabaron Jes√∫s y lo golpeaban con insultos. - ¬øNo eres t√∫ el Mes√≠as? ¬°Pues s√°lvate a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>Anakaja m√ºleka j√ºkaaliijale na wayuu eekai p√ºreesain, m√ºinjana aka p√ºreesakai jia wanaa namaa. J...</td>\n",
       "      <td>Tengan siempre presentes a los encarcelados como si ustedes mismos se encontraran presos junto c...</td>\n",
       "      <td>Anakaja m√ºleka j√ºm√ºliar√ºle naa'in na juwalayuukana eekai p√ºreesain, maa aka j√ºm√ºlialain jia wana...</td>\n",
       "      <td>Tengan compasi√≥n de los que est√°n en la c√°rcel como compa√±eros de prisi√≥n; tengan compasi√≥n de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>N√ºsouktakalaka Jes√∫s nam√ºin:‚ÄîShiim√ºin s√ºnain niainjachin El√≠as ant√ºin palajana s√ºp√ºla yapainjat√º...</td>\n",
       "      <td>Jes√∫s les contest√≥:‚ÄîEs cierto que El√≠as ha de venir y ha de ponerlo todo en orden.</td>\n",
       "      <td>N√ºsouktakalaka Jes√∫s nam√ºin: - Shiim√ºin s√ºnain ant√ºin El√≠as s√ºnain anouktaa sukuaippa wayuu s√ºp√º...</td>\n",
       "      <td>Jes√∫s le contest√≥: - Es cierto que El√≠as ha de venir primero para traer de la paz a toda la huma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>Kat√ºnayaa m√ºshii naya maa aka saa'in s√ºt√ºna wuchii. Aippiruas√ºwai nat√ºna wane'ewai nakua. Je ko'...</td>\n",
       "      <td>Cada uno de los cuatro seres vivientes ten√≠a seis alas y eran todo ojos por fuera y por dentro. ...</td>\n",
       "      <td>Je wane'ewai nakua na pienchishii kato'uchiikana, kas√ºp√ºshua'a ma'i no'u. Otta nayakana, ayatshi...</td>\n",
       "      <td>Sus mentes ser√°n como de osota, armadas de poderosos aguijones que pertenecen al Reino.Ministros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>Ja'itaina jia aap√ºin s√ºchiki kasachiki saink√ºin mmakat s√ºp√ºshua, nnojo jainkuuin aa'in s√ºt√ºma. J...</td>\n",
       "      <td>Llegar√°n a o√≠dos de ustedes noticias de guerras y rumores de conflictos b√©licos. No se alarmen, ...</td>\n",
       "      <td>Ja'itaina jia aap√ºin s√ºchiki kasachiki saink√ºin mmakat s√ºp√ºshua, nnojo jainkuuin aa'in s√ºt√ºma. J...</td>\n",
       "      <td>Cuando oigan noticias de guerras y rumores de conflictos b√©licos, no se alarmen. Aunque todo eso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>‚Äú ‚ÄòShiim√ºin ma'i t√º tamakat j√ºm√ºin: Chi wayuu eekai koo'om√ºin n√ºt√ºma t√º aap√ºnakat n√ºm√ºin, aap√ºne...</td>\n",
       "      <td>¬´Es cierto ‚Äîasinti√≥ el rey‚Äî, pero yo les digo que a todo el que tiene, se le dar√° m√°s. En cambio...</td>\n",
       "      <td>Shiim√ºin s√ºnain niain aluwataainjachin chi aluwataashikai. Otta tayakai chi eekai n√ºt√ºjain t√º aa...</td>\n",
       "      <td>Porque a todo el que tiene, a√∫n se le dar√° m√°s, y tendr√° de sobra; pero al que no tiene, hasta l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Tayakaa, talat√ºs√º taya s√ºka jemet√ºin j√ºm√ºin</td>\n",
       "      <td>Yo, me alegro que les haya gustado.</td>\n",
       "      <td>Talatashaanashi taya s√ºka talat√ºin ma'in taa'in j√ºm√ºin.</td>\n",
       "      <td>Yo s√≠, estoy contenta de tenerlos a todos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>Je n√ºntapa n√ºnain, n√ºmaashi nia Antioqu√≠am√ºin, eejanale naya kettat√ºin wane juya nat√ºma s√ºnain o...</td>\n",
       "      <td>Cuando lo encontr√≥, lo llev√≥ consigo Antioqu√≠a. Y a lo largo de todo un a√±o trabajaron los dos j...</td>\n",
       "      <td>Je n√ºntapa nia, no'unir√ºin nia nipialu'um√ºin t√º outkajaaleekat cha'aya. Eeshi Pablo n√ºmaa Bernab...</td>\n",
       "      <td>A su llegada, se puso en camino y pas√≥ dos a√±os con ellos, ense√±ando con gran exactitud en lo qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>Eirakaataalas√º joo taa'in iip√ºnaam√ºin. Te'rataalakalaka joo chi Anneetchonkai sha'wat√ºin cha'aya...</td>\n",
       "      <td>Volv√≠ a mirar, y vi al Cordero de pie sobre el monte de Sion. Lo acompa√±aban los ciento cuarenta...</td>\n",
       "      <td>Eweeta m√ºshia taya tachikua, te'rakalaka chi Anneetchonkai sha'wat√ºin chaa naa'u chi Maleiwakai ...</td>\n",
       "      <td>Vi al Cordero, que estaba en pie del monte de Sion, mientras mensajeros llevaban el nombre del C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      way  \\\n",
       "676               Ojutuushi taya sa a'ujee mootokaa aliikama 'inka, eweet√ºs√º  wanee p √ºliik√º tap√ºleeru wa   \n",
       "5447  Ananaj√ºs√º t√º wayuukol√ºirua naa'u Jes√∫s wanaa s√ºmaa n√ºkachenn√ºin s√ºnain kuruusa. Otta na s√ºla√ºlak...   \n",
       "2925  Anakaja m√ºleka j√ºkaaliijale na wayuu eekai p√ºreesain, m√ºinjana aka p√ºreesakai jia wanaa namaa. J...   \n",
       "6565  N√ºsouktakalaka Jes√∫s nam√ºin:‚ÄîShiim√ºin s√ºnain niainjachin El√≠as ant√ºin palajana s√ºp√ºla yapainjat√º...   \n",
       "1670  Kat√ºnayaa m√ºshii naya maa aka saa'in s√ºt√ºna wuchii. Aippiruas√ºwai nat√ºna wane'ewai nakua. Je ko'...   \n",
       "6786  Ja'itaina jia aap√ºin s√ºchiki kasachiki saink√ºin mmakat s√ºp√ºshua, nnojo jainkuuin aa'in s√ºt√ºma. J...   \n",
       "5277  ‚Äú ‚ÄòShiim√ºin ma'i t√º tamakat j√ºm√ºin: Chi wayuu eekai koo'om√ºin n√ºt√ºma t√º aap√ºnakat n√ºm√ºin, aap√ºne...   \n",
       "472                                                           Tayakaa, talat√ºs√º taya s√ºka jemet√ºin j√ºm√ºin   \n",
       "3309  Je n√ºntapa n√ºnain, n√ºmaashi nia Antioqu√≠am√ºin, eejanale naya kettat√ºin wane juya nat√ºma s√ºnain o...   \n",
       "1790  Eirakaataalas√º joo taa'in iip√ºnaam√ºin. Te'rataalakalaka joo chi Anneetchonkai sha'wat√ºin cha'aya...   \n",
       "\n",
       "                                                                                                      esp  \\\n",
       "676                                             Antes de ayer  me ca√≠ de la moto, se me atraves√≥ un burro   \n",
       "5447  La gente estaba all√≠ mirando, mientras las autoridades se burlaban de Jes√∫s, diciendo:‚ÄîPuesto qu...   \n",
       "2925  Tengan siempre presentes a los encarcelados como si ustedes mismos se encontraran presos junto c...   \n",
       "6565                   Jes√∫s les contest√≥:‚ÄîEs cierto que El√≠as ha de venir y ha de ponerlo todo en orden.   \n",
       "1670  Cada uno de los cuatro seres vivientes ten√≠a seis alas y eran todo ojos por fuera y por dentro. ...   \n",
       "6786  Llegar√°n a o√≠dos de ustedes noticias de guerras y rumores de conflictos b√©licos. No se alarmen, ...   \n",
       "5277  ¬´Es cierto ‚Äîasinti√≥ el rey‚Äî, pero yo les digo que a todo el que tiene, se le dar√° m√°s. En cambio...   \n",
       "472                                                                   Yo, me alegro que les haya gustado.   \n",
       "3309  Cuando lo encontr√≥, lo llev√≥ consigo Antioqu√≠a. Y a lo largo de todo un a√±o trabajaron los dos j...   \n",
       "1790  Volv√≠ a mirar, y vi al Cordero de pie sobre el monte de Sion. Lo acompa√±aban los ciento cuarenta...   \n",
       "\n",
       "                                                                                           way_translated  \\\n",
       "676                      Antalaa kaÍûãikaa, ojunuu√ºshi taya moto'op√ºnaa, n√ºlatiraakalaka taya wanee p√ºliik√º   \n",
       "5447  Je t√º wayuukol√ºirua, shi'r√ºinjase'e t√º naa'inrakat Jes√∫s. Otta na la√ºlaayuukana, na'√ºl√ºj√ºnaakala...   \n",
       "2925  Anakaja m√ºleka j√ºm√ºliar√ºle naa'in na juwalayuukana eekai p√ºreesain, maa aka j√ºm√ºlialain jia wana...   \n",
       "6565  N√ºsouktakalaka Jes√∫s nam√ºin: - Shiim√ºin s√ºnain ant√ºin El√≠as s√ºnain anouktaa sukuaippa wayuu s√ºp√º...   \n",
       "1670  Je wane'ewai nakua na pienchishii kato'uchiikana, kas√ºp√ºshua'a ma'i no'u. Otta nayakana, ayatshi...   \n",
       "6786  Ja'itaina jia aap√ºin s√ºchiki kasachiki saink√ºin mmakat s√ºp√ºshua, nnojo jainkuuin aa'in s√ºt√ºma. J...   \n",
       "5277  Shiim√ºin s√ºnain niain aluwataainjachin chi aluwataashikai. Otta tayakai chi eekai n√ºt√ºjain t√º aa...   \n",
       "472                                               Talatashaanashi taya s√ºka talat√ºin ma'in taa'in j√ºm√ºin.   \n",
       "3309  Je n√ºntapa nia, no'unir√ºin nia nipialu'um√ºin t√º outkajaaleekat cha'aya. Eeshi Pablo n√ºmaa Bernab...   \n",
       "1790  Eweeta m√ºshia taya tachikua, te'rakalaka chi Anneetchonkai sha'wat√ºin chaa naa'u chi Maleiwakai ...   \n",
       "\n",
       "                                                                                           esp_translated  \n",
       "676                                                  Yo me lanzo al medio de un mot√≠n, hay un mot√≠n cerca  \n",
       "5447  Los jud√≠os alabaron Jes√∫s y lo golpeaban con insultos. - ¬øNo eres t√∫ el Mes√≠as? ¬°Pues s√°lvate a ...  \n",
       "2925  Tengan compasi√≥n de los que est√°n en la c√°rcel como compa√±eros de prisi√≥n; tengan compasi√≥n de l...  \n",
       "6565  Jes√∫s le contest√≥: - Es cierto que El√≠as ha de venir primero para traer de la paz a toda la huma...  \n",
       "1670  Sus mentes ser√°n como de osota, armadas de poderosos aguijones que pertenecen al Reino.Ministros...  \n",
       "6786  Cuando oigan noticias de guerras y rumores de conflictos b√©licos, no se alarmen. Aunque todo eso...  \n",
       "5277  Porque a todo el que tiene, a√∫n se le dar√° m√°s, y tendr√° de sobra; pero al que no tiene, hasta l...  \n",
       "472                                                            Yo s√≠, estoy contenta de tenerlos a todos.  \n",
       "3309  A su llegada, se puso en camino y pas√≥ dos a√±os con ellos, ense√±ando con gran exactitud en lo qu...  \n",
       "1790  Vi al Cordero, que estaba en pie del monte de Sion, mientras mensajeros llevaban el nombre del C...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776cf77-7387-40e4-8941-ab345fb844ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
