{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=0\n",
    "MODEL_USED=\"facebook/nllb-200-distilled-600M\"\n",
    "# MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_nasa_esp_completo_600M\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"nas_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"quy_Latn\" # Ayacucho Quechua\n",
    "LANGUAGE_FILE=\"data/nasa_full_dataset.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"nas\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3862, 2)\n",
      "Index(['esp', 'nas'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3089 entries, 1839 to 3174\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   esp     3089 non-null   object\n",
      " 1   nas     3089 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 72.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>nas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>contagiar</td>\n",
       "      <td>neesu-niipeetje-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>nada</td>\n",
       "      <td>qu√≠j yujva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>herido</td>\n",
       "      <td>cp√°y√∫uni, cp√°vitni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>tejer</td>\n",
       "      <td>um-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>herir</td>\n",
       "      <td>cp√°vit-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            esp                 nas\n",
       "1839  contagiar    neesu-niipeetje-\n",
       "2500       nada          qu√≠j yujva\n",
       "805      herido  cp√°y√∫uni, cp√°vitni\n",
       "3185      tejer                 um-\n",
       "803       herir             cp√°vit-"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 386 entries, 3726 to 429\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   esp     386 non-null    object\n",
      " 1   nas     386 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>nas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>intercambiar</td>\n",
       "      <td>yu'ptjej-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>chicha dulce</td>\n",
       "      <td>beca √±usha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>desatar nudo</td>\n",
       "      <td>jy√∫cjwende-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>hacer brujer√≠as</td>\n",
       "      <td>mestl√°a-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3351</th>\n",
       "      <td>dedo</td>\n",
       "      <td>vyllill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  esp          nas\n",
       "3726     intercambiar    yu'ptjej-\n",
       "274      chicha dulce   beca √±usha\n",
       "1616     desatar nudo  jy√∫cjwende-\n",
       "1738  hacer brujer√≠as     mestl√°a-\n",
       "3351             dedo      vyllill"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 387 entries, 3105 to 2536\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   esp     387 non-null    object\n",
      " 1   nas     387 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>nas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>nuca</td>\n",
       "      <td>tyjicj dyi'tj, tyjicj shbimby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>temblar</td>\n",
       "      <td>quiwe √©se-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>entender</td>\n",
       "      <td>jiyu-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>cansar</td>\n",
       "      <td>cwaaty i'j-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>chlguaco</td>\n",
       "      <td>slluj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp                            nas\n",
       "3105      nuca  tyjicj dyi'tj, tyjicj shbimby\n",
       "2554   temblar                     quiwe √©se-\n",
       "1510  entender                          jiyu-\n",
       "1006    cansar                    cwaaty i'j-\n",
       "2736  chlguaco                          slluj"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>nas</th>\n",
       "      <th>nas_words</th>\n",
       "      <th>nas_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>urraca</td>\n",
       "      <td>[urraca]</td>\n",
       "      <td>[‚ñÅurra, ca]</td>\n",
       "      <td>ulchic</td>\n",
       "      <td>[ulchic]</td>\n",
       "      <td>[‚ñÅul, chic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>ponerse liso</td>\n",
       "      <td>[ponerse, liso]</td>\n",
       "      <td>[‚ñÅponer, se, ‚ñÅliso]</td>\n",
       "      <td>lavy-</td>\n",
       "      <td>[lavy, -]</td>\n",
       "      <td>[‚ñÅla, vy, -]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666</th>\n",
       "      <td>reto√±o</td>\n",
       "      <td>[reto√±o]</td>\n",
       "      <td>[‚ñÅreto, √±o]</td>\n",
       "      <td>ye'ch</td>\n",
       "      <td>[ye, ', ch]</td>\n",
       "      <td>[‚ñÅye, ', ch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>guala</td>\n",
       "      <td>[guala]</td>\n",
       "      <td>[‚ñÅg, uala]</td>\n",
       "      <td>sapete</td>\n",
       "      <td>[sapete]</td>\n",
       "      <td>[‚ñÅsap, ete]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>sangre</td>\n",
       "      <td>[sangre]</td>\n",
       "      <td>[‚ñÅsangre]</td>\n",
       "      <td>ee</td>\n",
       "      <td>[ee]</td>\n",
       "      <td>[‚ñÅee]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               esp        esp_words             esp_toks     nas    nas_words  \\\n",
       "3181        urraca         [urraca]          [‚ñÅurra, ca]  ulchic     [ulchic]   \n",
       "1644  ponerse liso  [ponerse, liso]  [‚ñÅponer, se, ‚ñÅliso]   lavy-    [lavy, -]   \n",
       "3666        reto√±o         [reto√±o]          [‚ñÅreto, √±o]   ye'ch  [ye, ', ch]   \n",
       "2582         guala          [guala]           [‚ñÅg, uala]  sapete     [sapete]   \n",
       "1155        sangre         [sangre]            [‚ñÅsangre]      ee         [ee]   \n",
       "\n",
       "          nas_toks  \n",
       "3181   [‚ñÅul, chic]  \n",
       "1644  [‚ñÅla, vy, -]  \n",
       "3666  [‚ñÅye, ', ch]  \n",
       "2582   [‚ñÅsap, ete]  \n",
       "1155         [‚ñÅee]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280184/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>nas_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>nas_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.0000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.0198</td>\n",
       "      <td>8.076200</td>\n",
       "      <td>2.623100</td>\n",
       "      <td>5.869600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.8495</td>\n",
       "      <td>32.136392</td>\n",
       "      <td>11.761797</td>\n",
       "      <td>26.039259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>329.0000</td>\n",
       "      <td>657.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>542.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         esp_toks      nas_toks     esp_words     nas_words\n",
       "count  10000.0000  10000.000000  10000.000000  10000.000000\n",
       "mean       4.0198      8.076200      2.623100      5.869600\n",
       "std       14.8495     32.136392     11.761797     26.039259\n",
       "min        1.0000      1.000000      1.000000      1.000000\n",
       "25%        2.0000      3.000000      1.000000      2.000000\n",
       "50%        2.0000      4.000000      1.000000      3.000000\n",
       "75%        3.0000      6.000000      2.000000      4.000000\n",
       "max      329.0000    657.000000    258.000000    542.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5324615912469979\n",
      "1.3759370314842578\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aab39bf256c4eedb9ae1d3b195fe432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caap√©jyucue‚Äôj-',\n",
       " \"wa'ta'j-, wa‚Äôta atyaj-\",\n",
       " 'etste caashi‚Äôj-',\n",
       " 'yu‚Äò',\n",
       " 'jypa‚Äôyacynim√©e']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "s = random.sample(texts_with_unk, 5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace ùìïùîØùîûùî´ùî†ùî¢ùî∞ùî†ùîû by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3533d7337314682aabd0ddb05b01373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3d674e37f34ca9a96914fe9b23a2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_nasa_esp_completo_600M/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_nasa_esp_completo_600M/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2048\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: a'eusictyjhnw-pk,mld√∫√©√°bfv√≠z.gqNrK√±Eo;MACSIFWY:1TLR9\"3DUH20()B7P4√ÅO√ö65V8J√≥\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_nasa_esp_completo_600M/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 3862 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=63268\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=83\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 3862 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=34691\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 5442 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 3862\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 5873\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 5873 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3159 obj=19.1527 num_tokens=19943 num_tokens/piece=6.31307\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2720 obj=16.7808 num_tokens=20230 num_tokens/piece=7.4375\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2249 obj=16.7946 num_tokens=20706 num_tokens/piece=9.20676\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2242 obj=16.7093 num_tokens=20769 num_tokens/piece=9.2636\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_nasa_esp_completo_600M/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_nasa_esp_completo_600M/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**11,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-10 10:59:20--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-10 10:59:20 (101 MB/s) - ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256204 257430\n",
      "1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 10:59:23.628395: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-10 10:59:23.762212: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-10 10:59:24.384676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-10 10:59:24.384740: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-10 10:59:24.384745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 257430. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910f3be04895416ab8af81e82ed9fb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257430\n",
      "['zul_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256203 + len(added_vocab) + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'nas_Latn', '<mask>']\n",
      "[257428, 257429, 257430]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256202 + len(added_vocab) + 2, 256202 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257429 257370\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 257431. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(257431, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([\"caaf√≠cje'j-\"], ['hacer poner sombrero'], 'nas_Latn', 'spa_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3470b2c771343f782d043fbf87bfd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.093742370605469\n",
      "1000 4.791785227537155\n",
      "2000 2.2759260957241056\n",
      "3000 1.3913363950550557\n",
      "4000 0.8467903584092855\n",
      "5000 0.5222313566282392\n",
      "6000 0.3626545791327953\n",
      "7000 0.2684491973575205\n",
      "8000 0.22765560531802476\n",
      "9000 0.18945902156922967\n",
      "10000 0.15623587110172957\n",
      "11000 0.13543669661320745\n",
      "12000 0.11733638629503548\n",
      "13000 0.10546312924241646\n",
      "14000 0.09262669888394885\n",
      "15000 0.0851774139313493\n",
      "16000 0.07800476412649732\n",
      "17000 0.07062030060042161\n",
      "18000 0.06726877798256464\n",
      "19000 0.06228006180585362\n",
      "20000 0.05704705267387908\n",
      "21000 0.05498337139512296\n",
      "22000 0.056793901053140874\n",
      "23000 0.05307805293181445\n",
      "24000 0.051565082653891293\n",
      "25000 0.04719096691947198\n",
      "26000 0.04734170994278975\n",
      "27000 0.04554547716971138\n",
      "28000 0.04519970875530271\n",
      "29000 0.04488368772523245\n",
      "30000 0.04330233709877939\n",
      "31000 0.04077165628293005\n",
      "32000 0.041087437634821984\n",
      "33000 0.03909426186713972\n",
      "34000 0.039372746629902394\n",
      "35000 0.03813494568108581\n",
      "36000 0.03923728992874385\n",
      "37000 0.03863783879444964\n",
      "38000 0.038514857665424646\n",
      "39000 0.035420908594547655\n",
      "40000 0.03679165173962247\n",
      "41000 0.03664843764784746\n",
      "42000 0.0365949124441031\n",
      "43000 0.036074803580428125\n",
      "44000 0.034945558149949645\n",
      "45000 0.034810993422695904\n",
      "46000 0.03529881954708253\n",
      "47000 0.034247204389343096\n",
      "48000 0.03270156792946364\n",
      "49000 0.033981958245021815\n",
      "50000 0.03367617516127211\n",
      "51000 0.032487567420554114\n",
      "52000 0.03246956373465582\n",
      "53000 0.030818795606341154\n",
      "54000 0.0308047602584993\n",
      "55000 0.031666291239635026\n",
      "56000 0.031463001088341117\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jytj√°asni']\n",
      "['voluntad']\n",
      "['cintura']\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.4G\n",
      "4.0K drwxrwxr-x 2 americasnlp americasnlp 4.0K Mar 10 11:04 .\n",
      "4.0K drwxrwxr-x 6 americasnlp americasnlp 4.0K Mar 10 10:59 ..\n",
      " 68K -rw-rw-r-- 1 americasnlp americasnlp  68K Mar 10 10:59 all_texts_file.csv\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  896 Mar 10 15:26 config.json\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  184 Mar 10 15:26 generation_config.json\n",
      "2.3G -rw-rw-r-- 1 americasnlp americasnlp 2.3G Mar 10 15:26 pytorch_model.bin\n",
      "4.7M -rw-rw-r-- 1 americasnlp americasnlp 4.7M Mar 10 15:26 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp 3.5K Mar 10 15:26 special_tokens_map.json\n",
      "260K -rw-rw-r-- 1 americasnlp americasnlp 260K Mar 10 10:59 spm_16k.model\n",
      " 32K -rw-rw-r-- 1 americasnlp americasnlp  30K Mar 10 10:59 spm_16k.vocab\n",
      "4.7M -rw-rw-r-- 1 americasnlp americasnlp 4.7M Mar 10 10:59 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  570 Mar 10 15:26 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"peeyg√°mni, peeyg√°aweete, peeyg√°awa'j\"]\n"
     ]
    }
   ],
   "source": [
    "t = \"las canciones de amor me gustan mucho\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peeycandeey']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atasco']\n"
     ]
    }
   ],
   "source": [
    "t = \"kuyakuyllawan takitam anchata kuyani\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uncorpo']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e07149ea59402fb52764400264a73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283e7fa9f63e4680bbac3471267e4191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 2.65 19.2/3.9/1.3/0.8 (BP = 0.893 ratio = 0.899 hyp_len = 1055 ref_len = 1174)\n",
      "chrF2++ = 18.18\n",
      "BLEU = 4.02 17.5/6.3/3.8/2.4 (BP = 0.713 ratio = 0.747 hyp_len = 865 ref_len = 1158)\n",
      "chrF2++ = 18.70\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nas</th>\n",
       "      <th>esp</th>\n",
       "      <th>nas_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>quita</td>\n",
       "      <td>macana</td>\n",
       "      <td>acy, a'cjy</td>\n",
       "      <td>quebrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>puts-</td>\n",
       "      <td>al borde de</td>\n",
       "      <td>putste</td>\n",
       "      <td>orinar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>atall we'we-</td>\n",
       "      <td>cantar</td>\n",
       "      <td>mem-, mem-</td>\n",
       "      <td>hablar gallina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>ucje</td>\n",
       "      <td>malla</td>\n",
       "      <td>tsam ucje</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>finze quiwe</td>\n",
       "      <td>tierra fr√≠a</td>\n",
       "      <td>etse</td>\n",
       "      <td>fr√≠o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>u'j-</td>\n",
       "      <td>seguir, continuar</td>\n",
       "      <td>jya'j-</td>\n",
       "      <td>ir, irse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>pshi'nd-</td>\n",
       "      <td>burlar</td>\n",
       "      <td>weech-, weech we'we-, npeevyshijca-</td>\n",
       "      <td>llorar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>F'i'n'ipe'la</td>\n",
       "      <td>un pedazo escrito de</td>\n",
       "      <td>pe'la ets</td>\n",
       "      <td>manejo de las cosas ahorrables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>cshiica'j-</td>\n",
       "      <td>hacer re√≠r</td>\n",
       "      <td>cpeembe'j-, cweeyi'j-</td>\n",
       "      <td>hacer risue√±o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>cpa'ja'j</td>\n",
       "      <td>hacer llegar</td>\n",
       "      <td>caapa'ja'j-</td>\n",
       "      <td>hacer montar a caballo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nas                   esp                       nas_translated  \\\n",
       "2529         quita                macana                           acy, a'cjy   \n",
       "2429         puts-           al borde de                               putste   \n",
       "205   atall we'we-                cantar                           mem-, mem-   \n",
       "3144          ucje                 malla                            tsam ucje   \n",
       "1281   finze quiwe           tierra fr√≠a                                 etse   \n",
       "3156          u'j-     seguir, continuar                               jya'j-   \n",
       "2348      pshi'nd-                burlar  weech-, weech we'we-, npeevyshijca-   \n",
       "3811  F'i'n'ipe'la  un pedazo escrito de                            pe'la ets   \n",
       "842     cshiica'j-            hacer re√≠r                cpeembe'j-, cweeyi'j-   \n",
       "798       cpa'ja'j          hacer llegar                          caapa'ja'j-   \n",
       "\n",
       "                      esp_translated  \n",
       "2529                        quebrada  \n",
       "2429                          orinar  \n",
       "205                   hablar gallina  \n",
       "3144                             red  \n",
       "1281                            fr√≠o  \n",
       "3156                        ir, irse  \n",
       "2348                          llorar  \n",
       "3811  manejo de las cosas ahorrables  \n",
       "842                    hacer risue√±o  \n",
       "798           hacer montar a caballo  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776cf77-7387-40e4-8941-ab345fb844ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
