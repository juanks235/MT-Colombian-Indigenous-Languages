{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=0\n",
    "# MODEL_USED=\"facebook/nllb-200-distilled-600M\"\n",
    "MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_arhuaco_esp_sin_dic_1_3B\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"arh_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"ayr_Latn\" # Central Aymara\n",
    "LANGUAGE_FILE=\"data/arh_sin_dic.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"arh\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5672, 2)\n",
      "Index(['arh', 'esp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4537 entries, 4966 to 860\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     4537 non-null   object\n",
      " 1   esp     4537 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 106.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>Niwisakuku Jesú zaka'nugasin ɉwa winʉnkʉsana n...</td>\n",
       "      <td>Cuando los apóstoles que estaban en Jerusalén ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>a'ga uweri nʉkeyri, kʉmeyuzey ayeygwi ɉe a'gi'...</td>\n",
       "      <td>Si ella me responde: “Bebe, y también sacaré a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>Josesin winʉnkuya ɉinari, sakuse' trigu ʉnwinʉ...</td>\n",
       "      <td>Entonces ellos cargaron el grano sobre sus asn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>Ey uye'ri Jesuse' keywʉ key ie'ri: —“Tá kinki...</td>\n",
       "      <td>Y añadió:—Jesús, acuérdate de mí cuando vengas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Ey uye'ki Lori ɉwʉn zʉn riware'ri, Niwipaw zʉ ...</td>\n",
       "      <td>Pero como Lot titubeaba, los mensajeros los ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "4966  Niwisakuku Jesú zaka'nugasin ɉwa winʉnkʉsana n...   \n",
       "1071  a'ga uweri nʉkeyri, kʉmeyuzey ayeygwi ɉe a'gi'...   \n",
       "718   Josesin winʉnkuya ɉinari, sakuse' trigu ʉnwinʉ...   \n",
       "4114  Ey uye'ri Jesuse' keywʉ key ie'ri: —“Tá kinki...   \n",
       "670   Ey uye'ki Lori ɉwʉn zʉn riware'ri, Niwipaw zʉ ...   \n",
       "\n",
       "                                                    esp  \n",
       "4966  Cuando los apóstoles que estaban en Jerusalén ...  \n",
       "1071  Si ella me responde: “Bebe, y también sacaré a...  \n",
       "718   Entonces ellos cargaron el grano sobre sus asn...  \n",
       "4114  Y añadió:—Jesús, acuérdate de mí cuando vengas...  \n",
       "670   Pero como Lot titubeaba, los mensajeros los ag...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 567 entries, 4453 to 219\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     567 non-null    object\n",
      " 1   esp     567 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>ikʉnha'se'ri: —“Sakuku emiri mowga masite gekw...</td>\n",
       "      <td>Ellos dijeron:—¡Señor, aquí tenemos dos espada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Oh! Pinna juna chuka a’ zuna kwuyun Chuka me’z...</td>\n",
       "      <td>¡Oh, naturaleza!, lugar de vida y alegría, te ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>ey awiki eyma cheyrwari tʉnhana gun nʉnnige'ri...</td>\n",
       "      <td>Y añadió:—Que los dirigentes de ustedes me aco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>Sinkʉ ʉnzanisi twí ʉnzanikʉn pare'ri, Lori pow...</td>\n",
       "      <td>Al caer la tarde los dos mensajeros llegaron a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>posuri ɉomʉ zariri aroma zʉnekʉ winʉkʉwitesi n...</td>\n",
       "      <td>y, agarrándolo, lo arrojaron a un aljibe que e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "4453  ikʉnha'se'ri: —“Sakuku emiri mowga masite gekw...   \n",
       "101   Oh! Pinna juna chuka a’ zuna kwuyun Chuka me’z...   \n",
       "5333  ey awiki eyma cheyrwari tʉnhana gun nʉnnige'ri...   \n",
       "655   Sinkʉ ʉnzanisi twí ʉnzanikʉn pare'ri, Lori pow...   \n",
       "1620  posuri ɉomʉ zariri aroma zʉnekʉ winʉkʉwitesi n...   \n",
       "\n",
       "                                                    esp  \n",
       "4453  Ellos dijeron:—¡Señor, aquí tenemos dos espada...  \n",
       "101   ¡Oh, naturaleza!, lugar de vida y alegría, te ...  \n",
       "5333  Y añadió:—Que los dirigentes de ustedes me aco...  \n",
       "655   Al caer la tarde los dos mensajeros llegaron a...  \n",
       "1620  y, agarrándolo, lo arrojaron a un aljibe que e...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 568 entries, 2515 to 4410\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     568 non-null    object\n",
      " 1   esp     568 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>Uye' María Magdalena awiri i'ngweygwi Mariari,...</td>\n",
       "      <td>Entre tanto, María Magdalena y la otra María e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2c. iku kagumu rekumanaba kwuya-jinari, gwamu ...</td>\n",
       "      <td>estos puntos suspensivos están para representa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>ey awi ingʉ ɉiwʉ bʉkʉna ka' a'nikwʉya Kawda za...</td>\n",
       "      <td>Pasamos a sotavento de Cauda, una pequeña isla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Ey anunaɉu nʉngwa ga'kumana ɉinari i'mʉnʉ eygw...</td>\n",
       "      <td>Los apóstoles volvieron a reunirse con Jesús y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>Inʉ awʉtari a'zʉnari, ku'nawakʉ zʉndi ʉnkʉnnis...</td>\n",
       "      <td>Acumulen, más bien, riquezas en el cielo, dond...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "2515  Uye' María Magdalena awiri i'ngweygwi Mariari,...   \n",
       "44    2c. iku kagumu rekumanaba kwuya-jinari, gwamu ...   \n",
       "4922  ey awi ingʉ ɉiwʉ bʉkʉna ka' a'nikwʉya Kawda za...   \n",
       "3250  Ey anunaɉu nʉngwa ga'kumana ɉinari i'mʉnʉ eygw...   \n",
       "2656  Inʉ awʉtari a'zʉnari, ku'nawakʉ zʉndi ʉnkʉnnis...   \n",
       "\n",
       "                                                    esp  \n",
       "2515  Entre tanto, María Magdalena y la otra María e...  \n",
       "44    estos puntos suspensivos están para representa...  \n",
       "4922  Pasamos a sotavento de Cauda, una pequeña isla...  \n",
       "3250  Los apóstoles volvieron a reunirse con Jesús y...  \n",
       "2656  Acumulen, más bien, riquezas en el cielo, dond...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>arh</th>\n",
       "      <th>arh_words</th>\n",
       "      <th>arh_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>Esto originó graves conflictos y discusiones a...</td>\n",
       "      <td>[Esto, originó, graves, conflictos, y, discusi...</td>\n",
       "      <td>[▁Esto, ▁origin, ó, ▁graves, ▁confli, ctos, ▁y...</td>\n",
       "      <td>Pabluri awiri Bernaweri ikʉnha'sin winʉnka'nug...</td>\n",
       "      <td>[Pabluri, awiri, Bernaweri, ikʉnha, ', sin, wi...</td>\n",
       "      <td>[▁Pab, l, uri, ▁awiri, ▁Ber, naw, eri, ▁ik, ʉ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>Se reunió tanta gente en torno a él que decidi...</td>\n",
       "      <td>[Se, reunió, tanta, gente, en, torno, a, él, q...</td>\n",
       "      <td>[▁Se, ▁reuni, ó, ▁tanta, ▁gente, ▁en, ▁torno, ...</td>\n",
       "      <td>ikʉ sʉmʉ kʉnhani'kuma awʉnpare'ri, Jesuri bark...</td>\n",
       "      <td>[ikʉ, sʉmʉ, kʉnhani, ', kuma, awʉnpare, ', ri,...</td>\n",
       "      <td>[▁ik, ʉ, ▁s, ʉ, m, ʉ, ▁k, ʉ, nh, ani, ', kuma,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>Pero Jesús, advirtiendo lo que pasaba, les dij...</td>\n",
       "      <td>[Pero, Jesús, ,, advirtiendo, lo, que, pasaba,...</td>\n",
       "      <td>[▁Pero, ▁Jesús, ,, ▁ad, virti, endo, ▁lo, ▁que...</td>\n",
       "      <td>Winyeyka Jesuse'ri winino'se'ri: —“¿Yari a'mia...</td>\n",
       "      <td>[Winyeyka, Jesuse, ', ri, winino, ', se, ', ri...</td>\n",
       "      <td>[▁W, inye, yka, ▁Jes, use, ', ri, ▁win, ino, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>Al anochecer, Jesús se sentó a la mesa con los...</td>\n",
       "      <td>[Al, anochecer, ,, Jesús, se, sentó, a, la, me...</td>\n",
       "      <td>[▁Al, ▁ano, che, cer, ,, ▁Jesús, ▁se, ▁sent, ó...</td>\n",
       "      <td>Ey anawi twí ʉnzanise'ri, Jesuri i'ngwi uga mo...</td>\n",
       "      <td>[Ey, anawi, twí, ʉnzanise, ', ri, ,, Jesuri, i...</td>\n",
       "      <td>[▁Ey, ▁ana, wi, ▁tw, í, ▁, ʉ, n, zan, ise, ', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>Oyeron estas palabras los jefes de los sacerdo...</td>\n",
       "      <td>[Oyeron, estas, palabras, los, jefes, de, los,...</td>\n",
       "      <td>[▁O, yeron, ▁estas, ▁palabras, ▁los, ▁je, fes,...</td>\n",
       "      <td>Awi nʉngwari ikʉ winʉwiya'bari: —“Aga'kʉnamʉ d...</td>\n",
       "      <td>[Awi, nʉngwari, ikʉ, winʉwiya, ', bari, :, —, ...</td>\n",
       "      <td>[▁Awi, ▁n, ʉ, ng, wari, ▁ik, ʉ, ▁win, ʉ, wiya,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    esp  \\\n",
       "4817  Esto originó graves conflictos y discusiones a...   \n",
       "2262  Se reunió tanta gente en torno a él que decidi...   \n",
       "2170  Pero Jesús, advirtiendo lo que pasaba, les dij...   \n",
       "2180  Al anochecer, Jesús se sentó a la mesa con los...   \n",
       "3294  Oyeron estas palabras los jefes de los sacerdo...   \n",
       "\n",
       "                                              esp_words  \\\n",
       "4817  [Esto, originó, graves, conflictos, y, discusi...   \n",
       "2262  [Se, reunió, tanta, gente, en, torno, a, él, q...   \n",
       "2170  [Pero, Jesús, ,, advirtiendo, lo, que, pasaba,...   \n",
       "2180  [Al, anochecer, ,, Jesús, se, sentó, a, la, me...   \n",
       "3294  [Oyeron, estas, palabras, los, jefes, de, los,...   \n",
       "\n",
       "                                               esp_toks  \\\n",
       "4817  [▁Esto, ▁origin, ó, ▁graves, ▁confli, ctos, ▁y...   \n",
       "2262  [▁Se, ▁reuni, ó, ▁tanta, ▁gente, ▁en, ▁torno, ...   \n",
       "2170  [▁Pero, ▁Jesús, ,, ▁ad, virti, endo, ▁lo, ▁que...   \n",
       "2180  [▁Al, ▁ano, che, cer, ,, ▁Jesús, ▁se, ▁sent, ó...   \n",
       "3294  [▁O, yeron, ▁estas, ▁palabras, ▁los, ▁je, fes,...   \n",
       "\n",
       "                                                    arh  \\\n",
       "4817  Pabluri awiri Bernaweri ikʉnha'sin winʉnka'nug...   \n",
       "2262  ikʉ sʉmʉ kʉnhani'kuma awʉnpare'ri, Jesuri bark...   \n",
       "2170  Winyeyka Jesuse'ri winino'se'ri: —“¿Yari a'mia...   \n",
       "2180  Ey anawi twí ʉnzanise'ri, Jesuri i'ngwi uga mo...   \n",
       "3294  Awi nʉngwari ikʉ winʉwiya'bari: —“Aga'kʉnamʉ d...   \n",
       "\n",
       "                                              arh_words  \\\n",
       "4817  [Pabluri, awiri, Bernaweri, ikʉnha, ', sin, wi...   \n",
       "2262  [ikʉ, sʉmʉ, kʉnhani, ', kuma, awʉnpare, ', ri,...   \n",
       "2170  [Winyeyka, Jesuse, ', ri, winino, ', se, ', ri...   \n",
       "2180  [Ey, anawi, twí, ʉnzanise, ', ri, ,, Jesuri, i...   \n",
       "3294  [Awi, nʉngwari, ikʉ, winʉwiya, ', bari, :, —, ...   \n",
       "\n",
       "                                               arh_toks  \n",
       "4817  [▁Pab, l, uri, ▁awiri, ▁Ber, naw, eri, ▁ik, ʉ,...  \n",
       "2262  [▁ik, ʉ, ▁s, ʉ, m, ʉ, ▁k, ʉ, nh, ani, ', kuma,...  \n",
       "2170  [▁W, inye, yka, ▁Jes, use, ', ri, ▁win, ino, '...  \n",
       "2180  [▁Ey, ▁ana, wi, ▁tw, í, ▁, ʉ, n, zan, ise, ', ...  \n",
       "3294  [▁Awi, ▁n, ʉ, ng, wari, ▁ik, ʉ, ▁win, ʉ, wiya,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258001/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>arh_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>arh_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.345700</td>\n",
       "      <td>72.25660</td>\n",
       "      <td>26.652200</td>\n",
       "      <td>36.86700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.759254</td>\n",
       "      <td>31.14541</td>\n",
       "      <td>11.865088</td>\n",
       "      <td>16.80376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>51.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>26.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>35.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>88.00000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>45.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>438.000000</td>\n",
       "      <td>542.00000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>370.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks     arh_toks     esp_words    arh_words\n",
       "count  10000.000000  10000.00000  10000.000000  10000.00000\n",
       "mean      33.345700     72.25660     26.652200     36.86700\n",
       "std       14.759254     31.14541     11.865088     16.80376\n",
       "min        2.000000      1.00000      1.000000      1.00000\n",
       "25%       24.000000     51.00000     19.000000     26.00000\n",
       "50%       31.000000     68.00000     25.000000     35.00000\n",
       "75%       41.000000     88.00000     32.000000     45.00000\n",
       "max      438.000000    542.00000    323.000000    370.00000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2511424948034309\n",
      "1.9599262212819055\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81721f17410545c98ba123a4568e63b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4369\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Ey uye'ki Pabluri soldadu keywʉ winʉkey ie'ri: —“Niwiri Romanu gwiri ana'nu'kino ey ʉwari chwizari powru bʉkʉnʉnke zʉn asoti niwe'sʉ anawawiri, zachʉn kineki niwinhazataku' gwawa nariri, kʉnse' ʉnniwihʉnkʉgaka anawiri; iwari mʉray ʉnchusʉn duni ki niwinhagwa'hao, ¿Azi gwa'kwa gwasiri? ¡ikʉnha kingwi zʉndi niwinha'chunhʉn rinasizari nanu'kinʉnno!” winʉkʉyana.\",\n",
       " \"Uye' nʉngwari Jesuse'ri: —“Nʉngwari nʉn kingwi Satanari, warin pariri ɉwí tímbiro zana nisi kʉwa'nʉya chwari awnʉnkwe” winʉkʉyana.\",\n",
       " \"Uye' ase'ri: —“Niwipaw zʉ ga'kʉnamʉ a'no'kwa awiri ayey ʉnchunhʉyase'ri awʉnkawari na'nʉnno” yana.Ikʉ du arunhu' neyka inʉ arunhá me'kusʉkweyna sisʉya(Mt. :-; Mar. :)\",\n",
       " \"paka deyru deyru kawari, koga paka, chinchinte kawi, dudute kʉzʉnnari ʉnwinga uwin a'zari faraonse'ri chuwin “a'zari re'kuwikumaye'ri”.\",\n",
       " \"Ey uye'ri sakuku ɉinase'ri eyma ga'kʉnamʉ Jesuse' ʉnkʉwasi asayʉwari niwise' niwinpʉsi a'zari ey yʉwani gun wina'zare'ri winto awiza wina'zare'ki; ikʉ sʉmʉ zʉna chowchu wina'kusʉya'me chusanáɉuri ʉndizoya una.Jesuri azinari wʉsi izari a'zasikumana(Mt. :-; Luk. :-)\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "s = random.sample(texts_with_unk, 5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace 𝓕𝔯𝔞𝔫𝔠𝔢𝔰𝔠𝔞 by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069308b29a9940adbc33b2e379697f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3437\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2479d8caed1f43f6af8d95b2c47dccfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_arhuaco_esp_sin_dic_1_3B/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_arhuaco_esp_sin_dic_1_3B/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8192\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: naiʉwkeru'ygsmzoh,cd.tɉp\"báEíJ:-NlAéúóIMSP¿?U;ɄKfLjBG()D!¡RTYFĆZHñOɈWʻʼÉÁvÍ#1x38\\24657+\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_arhuaco_esp_sin_dic_1_3B/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 5672 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=886957\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=102\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 5672 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=526687\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 31418 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 5672\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 24491\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 24491 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12222 obj=14.9188 num_tokens=67752 num_tokens/piece=5.54345\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9977 obj=11.9106 num_tokens=68365 num_tokens/piece=6.85226\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8822 obj=11.8087 num_tokens=68659 num_tokens/piece=7.7827\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8683 obj=11.7712 num_tokens=68881 num_tokens/piece=7.93286\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_arhuaco_esp_sin_dic_1_3B/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_arhuaco_esp_sin_dic_1_3B/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**13,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-08 03:46:10--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‘/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py’\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-08 03:46:10 (75.4 MB/s) - ‘/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py’ saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256204 262849\n",
      "6644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 03:46:13.673616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-08 03:46:13.815108: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-08 03:46:14.471894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-08 03:46:14.471952: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-08 03:46:14.471958: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 262849. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e14ca457e494ac18d0ad180309a0676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6644 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262849\n",
      "['zul_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256203 + len(added_vocab) + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'arh_Latn', '<mask>']\n",
      "[262847, 262848, 262849]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256202 + len(added_vocab) + 2, 256202 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262848 262663\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 262850. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(262850, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Al anochecer, Jesús se sentó a la mesa con los Doce'], [\"Ey anawi twí ʉnzanise'ri, Jesuri i'ngwi uga mowga kʉtow kʉriwiya ɉinasin mesase' winasi,\"], 'spa_Latn', 'arh_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f24a3bb8d4d42d0ba24b1a876d50646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.879865646362305\n",
      "1000 4.482493012428284\n",
      "2000 2.679631873488426\n",
      "3000 1.9305044021010398\n",
      "4000 1.3628304750919342\n",
      "5000 0.9630590504854918\n",
      "6000 0.7052046181187034\n",
      "7000 0.5646577081680297\n",
      "8000 0.4501689221672714\n",
      "9000 0.34339481907710434\n",
      "10000 0.2848906906377524\n",
      "11000 0.2340163647066802\n",
      "12000 0.1825876977350563\n",
      "13000 0.14366599721834064\n",
      "14000 0.11253687469661236\n",
      "15000 0.09006621156726033\n",
      "16000 0.07723594467807561\n",
      "17000 0.06492905292473733\n",
      "18000 0.056797460774891076\n",
      "19000 0.05153830784931779\n",
      "20000 0.046293974542059003\n",
      "21000 0.04420671386178583\n",
      "22000 0.03927675227401778\n",
      "23000 0.037916588577907535\n",
      "24000 0.035873073193244634\n",
      "25000 0.03383890302316286\n",
      "26000 0.032267229463439434\n",
      "27000 0.0318612582734786\n",
      "28000 0.030622395899379626\n",
      "29000 0.028553091273410245\n",
      "30000 0.028274791226023808\n",
      "31000 0.027149506265064703\n",
      "32000 0.026109493545023725\n",
      "33000 0.02624852309934795\n",
      "34000 0.025275114245712757\n",
      "35000 0.023172197126899847\n",
      "36000 0.022883420597645455\n",
      "37000 0.022402570463251323\n",
      "38000 0.02095070155186113\n",
      "39000 0.020297566870693118\n",
      "40000 0.020685742761124858\n",
      "41000 0.019687496780068613\n",
      "42000 0.018974945836351252\n",
      "43000 0.019438274043495768\n",
      "44000 0.018219428509590217\n",
      "45000 0.018457136874319987\n",
      "46000 0.016566763979382813\n",
      "47000 0.015682686262531206\n",
      "48000 0.016140824200527277\n",
      "49000 0.01698916098335758\n",
      "50000 0.01584198358259164\n",
      "51000 0.015273411898640916\n",
      "52000 0.014430178227019497\n",
      "53000 0.014659509521967266\n",
      "54000 0.015055069169728085\n",
      "55000 0.015342461136518978\n",
      "56000 0.014444809446693399\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A lo que Efrón respondió:']\n",
      "[\"Ey uye' nʉngwa Efrónse' keywʉ key ie'ri:\"]\n",
      "[\"Ey uye' nʉngwa Efrónri:\"]\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.2G\n",
      "4.0K drwxrwxr-x 2 americasnlp americasnlp 4.0K Mar  7 12:19 .\n",
      "4.0K drwxrwxr-x 8 americasnlp americasnlp 4.0K Mar  8 15:54 ..\n",
      "960K -rw-rw-r-- 1 americasnlp americasnlp 960K Mar  8 03:46 all_texts_file.csv\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  848 Mar  8 18:29 config.json\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  184 Mar  8 18:29 generation_config.json\n",
      "5.2G -rw-rw-r-- 1 americasnlp americasnlp 5.2G Mar  8 18:29 pytorch_model.bin\n",
      "4.8M -rw-rw-r-- 1 americasnlp americasnlp 4.8M Mar  8 18:29 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp 3.5K Mar  8 18:29 special_tokens_map.json\n",
      "376K -rw-rw-r-- 1 americasnlp americasnlp 373K Mar  8 03:46 spm_16k.model\n",
      "148K -rw-rw-r-- 1 americasnlp americasnlp 148K Mar  8 03:46 spm_16k.vocab\n",
      "4.8M -rw-rw-r-- 1 americasnlp americasnlp 4.8M Mar  8 03:46 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  570 Mar  8 18:29 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Nʉgunamu wa'ku neyka ɉinaGa'kʉnamʉ unarwási awʉ' niwe'zari michwawin\"]\n"
     ]
    }
   ],
   "source": [
    "t = \"las canciones de amor me gustan mucho\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Jwia'lezanu gun nanun nuzato me'zanéy na'zari\"]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['los padres de familia tendrán derecho de escoger el tipo de educación para sus hijos menores. en los establecimientos del estado ninguna persona podrá ser obligada a recibir educación religiosa.']\n"
     ]
    }
   ],
   "source": [
    "t = \"kuyakuyllawan takitam anchata kuyani\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['los padres de familia tendrán derecho de escoger el tipo de educación para sus hijos menores. en los establecimientos del estado ninguna persona podrá ser obligada a recibir educación religiosa.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366cd31bfa114b7aa9715d83362dcb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be64c98dbe1a4c84a745253c2f1d2975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 8.19 28.7/8.3/5.0/3.7 (BP = 1.000 ratio = 1.000 hyp_len = 15033 ref_len = 15030)\n",
      "chrF2++ = 23.80\n",
      "BLEU = 8.75 30.3/11.0/5.7/3.4 (BP = 0.981 ratio = 0.981 hyp_len = 14103 ref_len = 14379)\n",
      "chrF2++ = 33.38\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "      <th>arh_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>Uye'ri Judase'ri: —“¿Inʉ nʉkʉchusanʉndi me'zano?” key ie'ri: —“Seyu awiri ʉya sí mikʉbenuga mika...</td>\n",
       "      <td>Judá preguntó:—¿Qué quieres que te deje?Ella respondió:—Tu sello con su cordón y el bastón que l...</td>\n",
       "      <td>Uye' nʉngwari Judári: - \"¿Azi minhawkwa me'ɉuno?\" key ie'ri, Lease'ri: - \"Nʉɉurí ʉwa'ba, kʉmeyu ...</td>\n",
       "      <td>Judá respondió: - Deja que el muchacho venga bajo mi cuidado y pongámonos inmediatamente en marc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>Ey anunaɉu nʉngwa Israerise' keywʉ key ie'ri: —“Tá kinki, iwa nʉngwa eyki nʉkuyʉn ʉnna'zʉn gun a...</td>\n",
       "      <td>Entonces Israel dijo a José:—Ahora ya puedo morir. Te he visto y sé que estás vivo.</td>\n",
       "      <td>Ey uye' nʉngwa Israeri José keywʉ key ie'ri: - \"Iwa ɉwía ʉnnʉwicha gun anawaki ʉnnukʉndi, mákich...</td>\n",
       "      <td>Y Jacob se enteró de que su padre había muerto. Entonces su padre le dijo: - Tal vez me matarás.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>Ey anunaɉu nʉngwari asige' ɉirʉgakakʉ pari ʉndiyunʉn nuse'ri, ikʉ zʉgurókʉchʉ Jesusin winʉnka'r...</td>\n",
       "      <td>Al día siguiente, cuando bajaron del monte, mucha gente salió al encuentro de Jesús.</td>\n",
       "      <td>Ey anawi asige' bunsi ʉnchare'ri, kwimʉkʉnʉ pari ʉndiyunʉn rinuse'ri, ikʉ sʉmʉ kʉnhani'kuma una.</td>\n",
       "      <td>Al día siguiente, cuando Jesús salía de la montaña, la gente se apiñaba a su alrededor deseosa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Ey awi ɉwiku' pari ratrekindi ka'gʉmʉse'ri aɉu yow twí zanika una.</td>\n",
       "      <td>Desde el mediodía, toda la tierra quedó sumida en oscuridad hasta las tres de la tarde.</td>\n",
       "      <td>Uye'ri ayʉnke rinukʉn nugase' winino'kuye'ri: - \"Profeta Elíae kʉkanʉn nusi zʉn eiya niná wingwa...</td>\n",
       "      <td>Jesús le contestó: - Te aseguro que hoy estarás conmigo en el paraíso.Muerte de Jesús</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>emi akwey zoyeyka, yow, paperi asamu yamu awiukwa, ingwiri gugín (guchu) unnuku name, kwa gugín ...</td>\n",
       "      <td>para hacer efectiva la protección de estos derechos existen unos mecanismos que podemos utilizar...</td>\n",
       "      <td>1. michwi enanuyáy winíkwuya. eymari: 1. sakuku ingwi umún azuna neykase (acta de tutela), 2. sa...</td>\n",
       "      <td>los padres de familia tendrán derecho de escoger el tipo de educación para sus hijos menores. en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Ey uye' nʉngwa Jakobuse' key ie'ri: —“Sanusi má gʉmʉsinʉ umʉn na'zʉnazey inʉ duna nipanʉngwa mik...</td>\n",
       "      <td>Jacob insistió:—Júramelo antes.Esaú se lo juró, y de ese modo le vendió a Jacob sus derechos de ...</td>\n",
       "      <td>Ey uye'ki Jakobuse'ri, kʉriwiya ɉina umʉn a'zʉna umʉnb na'ba umʉngwi una, sakuku umʉnte wina'zʉn...</td>\n",
       "      <td>Jacob respondió: - Soy Esaú, tu primogénito, y debes venir.Él respondió: - Vengo huyendo de mi p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>Ey awi Perge ga'kʉnamʉ winbasanaɉuri eygwi Atalía rizoyana.</td>\n",
       "      <td>Anunciaron el mensaje en Perge y bajaron a Atalía.</td>\n",
       "      <td>Awi nʉngwa Berge ayekʉ ga'kʉnamʉ duna zakʉ winʉka'cho'si nʉngwari Atalía ʉndizoya una.</td>\n",
       "      <td>Se embarcaron allí para Antioquía de Siria, donde los habían confiado a la protección de Dios.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>Uye'ki nowmisinʉri eygwi ie'ri: —“Kakʉ Abraan eymí nʉngwa riniku' rinariza'chʉ, ʉwe'ki i'ngwi ʉ...</td>\n",
       "      <td>El rico replicó: «No, padre Abrahán, solo si alguno de los que han muerto va a hablarles, se con...</td>\n",
       "      <td>Uye'ki nowmisinʉse' eygwi key ie'ri: - \"Ʉnne'ki, kakʉ Abraandi, tá winʉnha'chu' ne awʉnki someth...</td>\n",
       "      <td>Los ricos dijeron: \"Señor, ¡pero si ya tiene diez veces más!\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>Ey ʉweri du winʉ kʉno'kwa ú, emey gwi nari ingʉ kindi ey kʉnʉnase'ri eygwi kawʉ ka'sari ukumu'n...</td>\n",
       "      <td>Presten mucha atención, porque al que tenga algo, aún se le dará más; pero al que no tenga nada,...</td>\n",
       "      <td>¡Azi kindi ey kʉnʉn nuga neki miwe'zanu' kinó! Ka'gʉmʉse'ri eygwi kawʉ ka'sari ukumu'nʉnno, ʉwe'...</td>\n",
       "      <td>¡Ay de ustedes, maestros de la ley y fariseos hipócritas, que ofrecen a Dios el diezmo de la men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Ingʉ birin ʉnzanika uye'ri, Judá zʉ kʉsaw Súa zʉ bu'gʉmʉri, ʉnwicha una, ey awi Judári iawichana...</td>\n",
       "      <td>Después de mucho tiempo, murió la mujer de Judá, la hija de Súa. Pasado el duelo por ella, subió...</td>\n",
       "      <td>Ey awi ingʉ birin ʉnzanikʉn nuse'ri, Judá zʉ kʉsaw, Disón zʉ bu'gʉmʉ ʉnwicha anuye'ri, Judári aɉ...</td>\n",
       "      <td>Un día, la hija de Judá murió y se acostó con la viuda, y así lo pasó con acostarse con ella. En...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      arh  \\\n",
       "748   Uye'ri Judase'ri: —“¿Inʉ nʉkʉchusanʉndi me'zano?” key ie'ri: —“Seyu awiri ʉya sí mikʉbenuga mika...   \n",
       "1350  Ey anunaɉu nʉngwa Israerise' keywʉ key ie'ri: —“Tá kinki, iwa nʉngwa eyki nʉkuyʉn ʉnna'zʉn gun a...   \n",
       "4309  Ey anunaɉu nʉngwari asige' ɉirʉgakakʉ pari ʉndiyunʉn nuse'ri, ikʉ zʉgurókʉchʉ Jesusin winʉnka'r...   \n",
       "2499                                   Ey awi ɉwiku' pari ratrekindi ka'gʉmʉse'ri aɉu yow twí zanika una.   \n",
       "33    emi akwey zoyeyka, yow, paperi asamu yamu awiukwa, ingwiri gugín (guchu) unnuku name, kwa gugín ...   \n",
       "1419  Ey uye' nʉngwa Jakobuse' key ie'ri: —“Sanusi má gʉmʉsinʉ umʉn na'zʉnazey inʉ duna nipanʉngwa mik...   \n",
       "5135                                          Ey awi Perge ga'kʉnamʉ winbasanaɉuri eygwi Atalía rizoyana.   \n",
       "4071  Uye'ki nowmisinʉri eygwi ie'ri: —“Kakʉ Abraan eymí nʉngwa riniku' rinariza'chʉ, ʉwe'ki i'ngwi ʉ...   \n",
       "3922  Ey ʉweri du winʉ kʉno'kwa ú, emey gwi nari ingʉ kindi ey kʉnʉnase'ri eygwi kawʉ ka'sari ukumu'n...   \n",
       "742   Ingʉ birin ʉnzanika uye'ri, Judá zʉ kʉsaw Súa zʉ bu'gʉmʉri, ʉnwicha una, ey awi Judári iawichana...   \n",
       "\n",
       "                                                                                                      esp  \\\n",
       "748   Judá preguntó:—¿Qué quieres que te deje?Ella respondió:—Tu sello con su cordón y el bastón que l...   \n",
       "1350                  Entonces Israel dijo a José:—Ahora ya puedo morir. Te he visto y sé que estás vivo.   \n",
       "4309                 Al día siguiente, cuando bajaron del monte, mucha gente salió al encuentro de Jesús.   \n",
       "2499              Desde el mediodía, toda la tierra quedó sumida en oscuridad hasta las tres de la tarde.   \n",
       "33    para hacer efectiva la protección de estos derechos existen unos mecanismos que podemos utilizar...   \n",
       "1419  Jacob insistió:—Júramelo antes.Esaú se lo juró, y de ese modo le vendió a Jacob sus derechos de ...   \n",
       "5135                                                   Anunciaron el mensaje en Perge y bajaron a Atalía.   \n",
       "4071  El rico replicó: «No, padre Abrahán, solo si alguno de los que han muerto va a hablarles, se con...   \n",
       "3922  Presten mucha atención, porque al que tenga algo, aún se le dará más; pero al que no tenga nada,...   \n",
       "742   Después de mucho tiempo, murió la mujer de Judá, la hija de Súa. Pasado el duelo por ella, subió...   \n",
       "\n",
       "                                                                                           arh_translated  \\\n",
       "748   Uye' nʉngwari Judári: - \"¿Azi minhawkwa me'ɉuno?\" key ie'ri, Lease'ri: - \"Nʉɉurí ʉwa'ba, kʉmeyu ...   \n",
       "1350  Ey uye' nʉngwa Israeri José keywʉ key ie'ri: - \"Iwa ɉwía ʉnnʉwicha gun anawaki ʉnnukʉndi, mákich...   \n",
       "4309     Ey anawi asige' bunsi ʉnchare'ri, kwimʉkʉnʉ pari ʉndiyunʉn rinuse'ri, ikʉ sʉmʉ kʉnhani'kuma una.   \n",
       "2499  Uye'ri ayʉnke rinukʉn nugase' winino'kuye'ri: - \"Profeta Elíae kʉkanʉn nusi zʉn eiya niná wingwa...   \n",
       "33    1. michwi enanuyáy winíkwuya. eymari: 1. sakuku ingwi umún azuna neykase (acta de tutela), 2. sa...   \n",
       "1419  Ey uye'ki Jakobuse'ri, kʉriwiya ɉina umʉn a'zʉna umʉnb na'ba umʉngwi una, sakuku umʉnte wina'zʉn...   \n",
       "5135               Awi nʉngwa Berge ayekʉ ga'kʉnamʉ duna zakʉ winʉka'cho'si nʉngwari Atalía ʉndizoya una.   \n",
       "4071  Uye'ki nowmisinʉse' eygwi key ie'ri: - \"Ʉnne'ki, kakʉ Abraandi, tá winʉnha'chu' ne awʉnki someth...   \n",
       "3922  ¡Azi kindi ey kʉnʉn nuga neki miwe'zanu' kinó! Ka'gʉmʉse'ri eygwi kawʉ ka'sari ukumu'nʉnno, ʉwe'...   \n",
       "742   Ey awi ingʉ birin ʉnzanikʉn nuse'ri, Judá zʉ kʉsaw, Disón zʉ bu'gʉmʉ ʉnwicha anuye'ri, Judári aɉ...   \n",
       "\n",
       "                                                                                           esp_translated  \n",
       "748   Judá respondió: - Deja que el muchacho venga bajo mi cuidado y pongámonos inmediatamente en marc...  \n",
       "1350     Y Jacob se enteró de que su padre había muerto. Entonces su padre le dijo: - Tal vez me matarás.  \n",
       "4309      Al día siguiente, cuando Jesús salía de la montaña, la gente se apiñaba a su alrededor deseosa.  \n",
       "2499                Jesús le contestó: - Te aseguro que hoy estarás conmigo en el paraíso.Muerte de Jesús  \n",
       "33    los padres de familia tendrán derecho de escoger el tipo de educación para sus hijos menores. en...  \n",
       "1419  Jacob respondió: - Soy Esaú, tu primogénito, y debes venir.Él respondió: - Vengo huyendo de mi p...  \n",
       "5135       Se embarcaron allí para Antioquía de Siria, donde los habían confiado a la protección de Dios.  \n",
       "4071                                       Los ricos dijeron: \"Señor, ¡pero si ya tiene diez veces más!\".  \n",
       "3922  ¡Ay de ustedes, maestros de la ley y fariseos hipócritas, que ofrecen a Dios el diezmo de la men...  \n",
       "742   Un día, la hija de Judá murió y se acostó con la viuda, y así lo pasó con acostarse con ella. En...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
