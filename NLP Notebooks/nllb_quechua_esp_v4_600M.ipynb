{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=0\n",
    "MODEL_USED=\"facebook/nllb-200-distilled-600M\"\n",
    "# MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_quechua_esp_v4_600M\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"quechua_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"ayr_Latn\" # Central Aymara\n",
    "LANGUAGE_FILE=\"data/ALL.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"quechua\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249755, 2)\n",
      "Index(['esp', 'quechua'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 199804 entries, 46337 to 121958\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   esp      199804 non-null  object\n",
      " 1   quechua  199804 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46337</th>\n",
       "      <td>¬øSigui√≥ Josu√© los consejos que recibi√≥ de Jehov√°?</td>\n",
       "      <td>¬øKasukurqachu Josueyqa Jehov√° Diospa nisqanta?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65250</th>\n",
       "      <td>En particular, los siervos de Dios que entabla...</td>\n",
       "      <td>Astawanraqmi respetanakunanku casarakunankupaq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13897</th>\n",
       "      <td>Empieza por seis meses, por ejemplo.</td>\n",
       "      <td>Ichapas puntataqa kallpanchakuwaq suqta killata.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84690</th>\n",
       "      <td>Primero dedic√≥ tiempo a conocer las necesidade...</td>\n",
       "      <td>Puntataqa, sapakama imayna sasachakuyniyoq kas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100256</th>\n",
       "      <td>Este n√∫mero de La Atalaya muestra c√≥mo cumplir...</td>\n",
       "      <td>Kay Willakuq qillqam yachachichkan imaynata Di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      esp  \\\n",
       "46337   ¬øSigui√≥ Josu√© los consejos que recibi√≥ de Jehov√°?   \n",
       "65250   En particular, los siervos de Dios que entabla...   \n",
       "13897                Empieza por seis meses, por ejemplo.   \n",
       "84690   Primero dedic√≥ tiempo a conocer las necesidade...   \n",
       "100256  Este n√∫mero de La Atalaya muestra c√≥mo cumplir...   \n",
       "\n",
       "                                                  quechua  \n",
       "46337      ¬øKasukurqachu Josueyqa Jehov√° Diospa nisqanta?  \n",
       "65250   Astawanraqmi respetanakunanku casarakunankupaq...  \n",
       "13897    Ichapas puntataqa kallpanchakuwaq suqta killata.  \n",
       "84690   Puntataqa, sapakama imayna sasachakuyniyoq kas...  \n",
       "100256  Kay Willakuq qillqam yachachichkan imaynata Di...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24975 entries, 105644 to 119642\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   esp      24975 non-null  object\n",
      " 1   quechua  24975 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 585.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105644</th>\n",
       "      <td>Por eso entendemos que la historia de las diez...</td>\n",
       "      <td>Chaymi entiendenchik chunka doncellakunamanta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79811</th>\n",
       "      <td>Ustedes, los j√≥venes, deben tener cuidado a la...</td>\n",
       "      <td>Manataqmi allinchu kanman wi√±aymasikikunapa tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174105</th>\n",
       "      <td>Cuando una amiga de la escuela la invit√≥ a su ...</td>\n",
       "      <td>¬øYacharqankichu chhayna fiestapi Bautizaq Juan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113062</th>\n",
       "      <td>Los ancianos trabajan mucho por la congregaci√≥...</td>\n",
       "      <td>Ancianokunaqa i√±iqmasinkunata yanapanankupaqmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132644</th>\n",
       "      <td>El aguante de Abrah√°n tuvo una poderosa influe...</td>\n",
       "      <td>Abrahanpa qaqa sayasqanmi churin Isaacta yanap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      esp  \\\n",
       "105644  Por eso entendemos que la historia de las diez...   \n",
       "79811   Ustedes, los j√≥venes, deben tener cuidado a la...   \n",
       "174105  Cuando una amiga de la escuela la invit√≥ a su ...   \n",
       "113062  Los ancianos trabajan mucho por la congregaci√≥...   \n",
       "132644  El aguante de Abrah√°n tuvo una poderosa influe...   \n",
       "\n",
       "                                                  quechua  \n",
       "105644  Chaymi entiendenchik chunka doncellakunamanta ...  \n",
       "79811   Manataqmi allinchu kanman wi√±aymasikikunapa tu...  \n",
       "174105  ¬øYacharqankichu chhayna fiestapi Bautizaq Juan...  \n",
       "113062  Ancianokunaqa i√±iqmasinkunata yanapanankupaqmi...  \n",
       "132644  Abrahanpa qaqa sayasqanmi churin Isaacta yanap...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24976 entries, 236681 to 108081\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   esp      24976 non-null  object\n",
      " 1   quechua  24976 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 585.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>quechua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236681</th>\n",
       "      <td>Jes√∫s sab√≠a que sus disc√≠pulos ser√≠an felices ...</td>\n",
       "      <td>Jesusqa yacharqanmi qatikuqninkuna tukuy sonqo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63876</th>\n",
       "      <td>‚Äú¬øNos ama Jehov√° aunque seamos ind√≠genas? ‚Äù</td>\n",
       "      <td>‚Äò ¬øKuyawankuchu Jehov√° Diosqa kay llaqtamanta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>Hormiguita.</td>\n",
       "      <td>Sisichamanta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225635</th>\n",
       "      <td>Es una recopilaci√≥n de 66 libros sagrados.</td>\n",
       "      <td>Bibliapiqa 66 librokunan kan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92762</th>\n",
       "      <td>¬øEst√° mal disciplinar a los hijos?</td>\n",
       "      <td>¬øAllinchu kanman warmakunata corregiyqa?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      esp  \\\n",
       "236681  Jes√∫s sab√≠a que sus disc√≠pulos ser√≠an felices ...   \n",
       "63876         ‚Äú¬øNos ama Jehov√° aunque seamos ind√≠genas? ‚Äù   \n",
       "3464                                          Hormiguita.   \n",
       "225635         Es una recopilaci√≥n de 66 libros sagrados.   \n",
       "92762                  ¬øEst√° mal disciplinar a los hijos?   \n",
       "\n",
       "                                                  quechua  \n",
       "236681  Jesusqa yacharqanmi qatikuqninkuna tukuy sonqo...  \n",
       "63876   ‚Äò ¬øKuyawankuchu Jehov√° Diosqa kay llaqtamanta ...  \n",
       "3464                                        Sisichamanta.  \n",
       "225635                      Bibliapiqa 66 librokunan kan.  \n",
       "92762            ¬øAllinchu kanman warmakunata corregiyqa?  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>quechua</th>\n",
       "      <th>quechua_words</th>\n",
       "      <th>quechua_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173585</th>\n",
       "      <td>Para m√°s detalles, comun√≠quese con la Tesorer√≠...</td>\n",
       "      <td>[Para, m√°s, detalles, ,, comun√≠quese, con, la,...</td>\n",
       "      <td>[‚ñÅPara, ‚ñÅm√°s, ‚ñÅdetalles, ,, ‚ñÅcomun, √≠, qu, ese...</td>\n",
       "      <td>Astawan chaymanta yachanaykipaqqa kay telefono...</td>\n",
       "      <td>[Astawan, chaymanta, yachanaykipaqqa, kay, tel...</td>\n",
       "      <td>[‚ñÅAsta, wan, ‚ñÅchay, manta, ‚ñÅyachan, ayki, paq,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61987</th>\n",
       "      <td>Cristianos no casados que ya han pasado la juv...</td>\n",
       "      <td>[Cristianos, no, casados, que, ya, han, pasado...</td>\n",
       "      <td>[‚ñÅCristian, os, ‚ñÅno, ‚ñÅcas, ados, ‚ñÅque, ‚ñÅya, ‚ñÅh...</td>\n",
       "      <td>5: 2 - 5). Soltero qeparuq cristianokuna</td>\n",
       "      <td>[5, :, 2, -, 5, ), ., Soltero, qeparuq, cristi...</td>\n",
       "      <td>[‚ñÅ5:, ‚ñÅ2, ‚ñÅ-, ‚ñÅ5)., ‚ñÅSol, tero, ‚ñÅqe, par, uq, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53370</th>\n",
       "      <td>Y hab√≠a quienes se resist√≠an a abandonar las c...</td>\n",
       "      <td>[Y, hab√≠a, quienes, se, resist√≠an, a, abandona...</td>\n",
       "      <td>[‚ñÅY, ‚ñÅhab√≠a, ‚ñÅquienes, ‚ñÅse, ‚ñÅresist, √≠an, ‚ñÅa, ...</td>\n",
       "      <td>Wakinkum mana saqeyta munarqakuchu samana punc...</td>\n",
       "      <td>[Wakinkum, mana, saqeyta, munarqakuchu, samana...</td>\n",
       "      <td>[‚ñÅWak, ink, um, ‚ñÅmana, ‚ñÅsaq, ey, ta, ‚ñÅmunar, q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189208</th>\n",
       "      <td>Era como si el adorador, su familia, los sacer...</td>\n",
       "      <td>[Era, como, si, el, adorador, ,, su, familia, ...</td>\n",
       "      <td>[‚ñÅEra, ‚ñÅcomo, ‚ñÅsi, ‚ñÅel, ‚ñÅador, ador, ,, ‚ñÅsu, ‚ñÅ...</td>\n",
       "      <td>Chay ruwayqa yupaychaq runapas, familianwan sa...</td>\n",
       "      <td>[Chay, ruwayqa, yupaychaq, runapas, ,, familia...</td>\n",
       "      <td>[‚ñÅChay, ‚ñÅruway, qa, ‚ñÅyupay, chaq, ‚ñÅrun, apas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26549</th>\n",
       "      <td>Su nombre significa ‚Äúderribadores ‚Äù, los que h...</td>\n",
       "      <td>[Su, nombre, significa, ‚Äú, derribadores, ‚Äù, ,,...</td>\n",
       "      <td>[‚ñÅSu, ‚ñÅnombre, ‚ñÅsignifica, ‚ñÅ, ‚Äú, der, rib, ado...</td>\n",
       "      <td>Nefilim sutiqa ‚Äúhukkunata venceq ‚Äù ninanmi.</td>\n",
       "      <td>[Nefilim, sutiqa, ‚Äú, hukkunata, venceq, ‚Äù, nin...</td>\n",
       "      <td>[‚ñÅNe, fi, lim, ‚ñÅsuti, qa, ‚ñÅ, ‚Äú, huk, kunata, ‚ñÅ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      esp  \\\n",
       "173585  Para m√°s detalles, comun√≠quese con la Tesorer√≠...   \n",
       "61987   Cristianos no casados que ya han pasado la juv...   \n",
       "53370   Y hab√≠a quienes se resist√≠an a abandonar las c...   \n",
       "189208  Era como si el adorador, su familia, los sacer...   \n",
       "26549   Su nombre significa ‚Äúderribadores ‚Äù, los que h...   \n",
       "\n",
       "                                                esp_words  \\\n",
       "173585  [Para, m√°s, detalles, ,, comun√≠quese, con, la,...   \n",
       "61987   [Cristianos, no, casados, que, ya, han, pasado...   \n",
       "53370   [Y, hab√≠a, quienes, se, resist√≠an, a, abandona...   \n",
       "189208  [Era, como, si, el, adorador, ,, su, familia, ...   \n",
       "26549   [Su, nombre, significa, ‚Äú, derribadores, ‚Äù, ,,...   \n",
       "\n",
       "                                                 esp_toks  \\\n",
       "173585  [‚ñÅPara, ‚ñÅm√°s, ‚ñÅdetalles, ,, ‚ñÅcomun, √≠, qu, ese...   \n",
       "61987   [‚ñÅCristian, os, ‚ñÅno, ‚ñÅcas, ados, ‚ñÅque, ‚ñÅya, ‚ñÅh...   \n",
       "53370   [‚ñÅY, ‚ñÅhab√≠a, ‚ñÅquienes, ‚ñÅse, ‚ñÅresist, √≠an, ‚ñÅa, ...   \n",
       "189208  [‚ñÅEra, ‚ñÅcomo, ‚ñÅsi, ‚ñÅel, ‚ñÅador, ador, ,, ‚ñÅsu, ‚ñÅ...   \n",
       "26549   [‚ñÅSu, ‚ñÅnombre, ‚ñÅsignifica, ‚ñÅ, ‚Äú, der, rib, ado...   \n",
       "\n",
       "                                                  quechua  \\\n",
       "173585  Astawan chaymanta yachanaykipaqqa kay telefono...   \n",
       "61987            5: 2 - 5). Soltero qeparuq cristianokuna   \n",
       "53370   Wakinkum mana saqeyta munarqakuchu samana punc...   \n",
       "189208  Chay ruwayqa yupaychaq runapas, familianwan sa...   \n",
       "26549         Nefilim sutiqa ‚Äúhukkunata venceq ‚Äù ninanmi.   \n",
       "\n",
       "                                            quechua_words  \\\n",
       "173585  [Astawan, chaymanta, yachanaykipaqqa, kay, tel...   \n",
       "61987   [5, :, 2, -, 5, ), ., Soltero, qeparuq, cristi...   \n",
       "53370   [Wakinkum, mana, saqeyta, munarqakuchu, samana...   \n",
       "189208  [Chay, ruwayqa, yupaychaq, runapas, ,, familia...   \n",
       "26549   [Nefilim, sutiqa, ‚Äú, hukkunata, venceq, ‚Äù, nin...   \n",
       "\n",
       "                                             quechua_toks  \n",
       "173585  [‚ñÅAsta, wan, ‚ñÅchay, manta, ‚ñÅyachan, ayki, paq,...  \n",
       "61987   [‚ñÅ5:, ‚ñÅ2, ‚ñÅ-, ‚ñÅ5)., ‚ñÅSol, tero, ‚ñÅqe, par, uq, ...  \n",
       "53370   [‚ñÅWak, ink, um, ‚ñÅmana, ‚ñÅsaq, ey, ta, ‚ñÅmunar, q...  \n",
       "189208  [‚ñÅChay, ‚ñÅruway, qa, ‚ñÅyupay, chaq, ‚ñÅrun, apas, ...  \n",
       "26549   [‚ñÅNe, fi, lim, ‚ñÅsuti, qa, ‚ñÅ, ‚Äú, huk, kunata, ‚ñÅ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_269610/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>quechua_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>quechua_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.702100</td>\n",
       "      <td>24.46740</td>\n",
       "      <td>18.266300</td>\n",
       "      <td>12.481600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.815638</td>\n",
       "      <td>13.92004</td>\n",
       "      <td>10.228384</td>\n",
       "      <td>7.437513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>140.00000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks  quechua_toks     esp_words  quechua_words\n",
       "count  10000.000000   10000.00000  10000.000000   10000.000000\n",
       "mean      22.702100      24.46740     18.266300      12.481600\n",
       "std       12.815638      13.92004     10.228384       7.437513\n",
       "min        1.000000       1.00000      1.000000       1.000000\n",
       "25%       14.000000      15.00000     11.000000       7.000000\n",
       "50%       21.000000      22.00000     17.000000      11.000000\n",
       "75%       29.000000      31.00000     24.000000      16.000000\n",
       "max      110.000000     140.00000     94.000000      71.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2428406409617712\n",
      "1.9602775285219844\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a15a0ccf7c484990ef13461cdfa1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/249755 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3857 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72814\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marcos 4: 1 - 9 textopi tarikuq rikch‚Äôanachiymanta pisillapi willariy.',\n",
       " 'Pablom nirqa: ‚ÄúRimaspaykichikqa amay√° qacha simichu kaychik, aswanqa allin kaqkunallatay√° rimaychik chaynapi uyariqnikichikkunapas allinninpaq kaptin aswan - aswan wi√±anankupaq ‚Äù, nispa.',\n",
       " 'Imapas ruwasqanchikman hamunankupaq nisqanchikpas anchatam√° kusichinqa ‚Äù, nispa.',\n",
       " '¬øImaynatan Dios kutichin ‚Äúllakisqa sonqoyoqkunaq ‚Äù ‚Äò llakiq √±it‚Äôisqan sonqoyoqkunaq ‚Äô ma√±akusqankuman?',\n",
       " '* Chayta estudiaspan askhata yachasun imayna runa kasqanmanta, √±ak‚Äôarisqanmanta, Rey kasqanmanta, Qespichiqninchis kasqanmantapas.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "s = random.sample(texts_with_unk, 5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace ùìïùîØùîûùî´ùî†ùî¢ùî∞ùî†ùîû by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26790555e3564038ba30a2cc739880f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562f8aef77fd4c52a7981a3e20d57562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/249755 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_quechua_esp_v4_600M/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_quechua_esp_v4_600M/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8192\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: aniuksqhptmycrloew.,√±D'd\"IbJvC:1?¬øAgP√°)2SM(jKB-3fH0T4NE5RQ9LYW678zUG√≠;][√ëx√≥√©!¬°O√∫F‚Ä¢/V*‚ñ™√â√ÅZ‚ñ°Àà|‚óÜ√ç>√ìX º√º√®%‚óè¬∑$√ö√∂‚ñ∏√§¬©√¶‚óá‚óã‚úî≈Ç√£◊î¬∞√Ω‚Üê‚òû√†◊†◊§◊©◊Å‚Üí≈†‚Üì≈º√´√∏√•◊ô‚Üë√ß≈Ø\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_quechua_esp_v4_600M/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 249755 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=21991802\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=161\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 249755 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=12445927\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 570636 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 249755\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 311241\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 311241 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=141325 obj=14.6684 num_tokens=618659 num_tokens/piece=4.37756\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=121508 obj=11.4094 num_tokens=620720 num_tokens/piece=5.10847\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=91097 obj=11.3981 num_tokens=651570 num_tokens/piece=7.15249\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=90947 obj=11.3654 num_tokens=651807 num_tokens/piece=7.16689\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=68207 obj=11.4774 num_tokens=688939 num_tokens/piece=10.1007\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=68193 obj=11.4439 num_tokens=689031 num_tokens/piece=10.1041\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=51143 obj=11.5865 num_tokens=725407 num_tokens/piece=14.1839\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=51141 obj=11.5487 num_tokens=725318 num_tokens/piece=14.1827\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=38354 obj=11.7147 num_tokens=760003 num_tokens/piece=19.8155\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=38354 obj=11.6724 num_tokens=759953 num_tokens/piece=19.8142\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=28764 obj=11.8631 num_tokens=794378 num_tokens/piece=27.6171\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=28764 obj=11.8154 num_tokens=794352 num_tokens/piece=27.6162\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=21573 obj=12.029 num_tokens=828220 num_tokens/piece=38.3915\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=21573 obj=11.9753 num_tokens=828171 num_tokens/piece=38.3892\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=16179 obj=12.2121 num_tokens=863365 num_tokens/piece=53.3633\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=16179 obj=12.1522 num_tokens=863346 num_tokens/piece=53.3621\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12134 obj=12.4168 num_tokens=900875 num_tokens/piece=74.2439\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12134 obj=12.3481 num_tokens=900867 num_tokens/piece=74.2432\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9100 obj=12.6399 num_tokens=939435 num_tokens/piece=103.235\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9100 obj=12.5643 num_tokens=939466 num_tokens/piece=103.238\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9011 obj=12.5723 num_tokens=940720 num_tokens/piece=104.397\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9011 obj=12.5694 num_tokens=940738 num_tokens/piece=104.399\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_quechua_esp_v4_600M/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_quechua_esp_v4_600M/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**13,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-09 15:22:51--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-09 15:22:51 (15.1 MB/s) - ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256204 262578\n",
      "6373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 15:22:55.194520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-09 15:22:55.351456: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-09 15:22:56.007760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-09 15:22:56.007818: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-09 15:22:56.007823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 262578. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdff7b0a42f4baf9e60e7e3aaa2b711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262578\n",
      "['zul_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256203 + len(added_vocab) + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'quechua_Latn', '<mask>']\n",
      "[262576, 262577, 262578]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256202 + len(added_vocab) + 2, 256202 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262577 262392\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 262579. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(262579, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['¬øImatam runakunaqa ruwarqaku?'], ['¬øC√≥mo reaccionaron las personas al ver todo aquello?'], 'quechua_Latn', 'spa_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38693a00c4847a3b194ef6b565cbfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.697717666625977\n",
      "1000 4.60801714682579\n",
      "2000 3.2467598114013674\n",
      "3000 2.997264306783676\n",
      "4000 2.8640812091827392\n",
      "5000 2.7580718643665314\n",
      "6000 2.666862373113632\n",
      "7000 2.5873130880594255\n",
      "8000 2.523510596394539\n",
      "9000 2.456454604625702\n",
      "10000 2.3823741283416746\n",
      "11000 2.33797838139534\n",
      "12000 2.282424886226654\n",
      "13000 2.228626950263977\n",
      "14000 2.1798375527858735\n",
      "15000 2.1633685488700864\n",
      "16000 2.1227959295511245\n",
      "17000 2.081353570699692\n",
      "18000 2.0480959161520005\n",
      "19000 1.9977416628599167\n",
      "20000 2.01556993496418\n",
      "21000 1.9573853551149367\n",
      "22000 1.9406543249487878\n",
      "23000 1.9177169843912125\n",
      "24000 1.8759130741357803\n",
      "25000 1.8374078706502914\n",
      "26000 1.8475868562459945\n",
      "27000 1.8084564536809922\n",
      "28000 1.8042715110778809\n",
      "29000 1.7808924086093902\n",
      "30000 1.7617387379407883\n",
      "31000 1.7567058640122413\n",
      "32000 1.7220084773302078\n",
      "33000 1.7161001838445664\n",
      "34000 1.6987426990270615\n",
      "35000 1.6768532971143721\n",
      "36000 1.6808265246748924\n",
      "37000 1.6580257853865623\n",
      "38000 1.6349995608329773\n",
      "39000 1.6236501521468163\n",
      "40000 1.6103968218564988\n",
      "41000 1.6191330832839013\n",
      "42000 1.5853314052820207\n",
      "43000 1.5765764904022217\n",
      "44000 1.5708166612386703\n",
      "45000 1.5723831111788749\n",
      "46000 1.5501069417595863\n",
      "47000 1.5443805627822875\n",
      "48000 1.5208537455797195\n",
      "49000 1.5291053603887559\n",
      "50000 1.5037411799430846\n",
      "51000 1.4947271345853805\n",
      "52000 1.4966319488883018\n",
      "53000 1.49171739757061\n",
      "54000 1.4776733772158623\n",
      "55000 1.4545700670480728\n",
      "56000 1.4614680179357529\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chayna waqaychawananchikpi i√±iyninchikqa allinpunim kanqa salvakunapaq hinaspa hinalla Diosman sonqo kanapaq (Joel 2: 31, 32).']\n",
      "['La fe en que Jehov√° nos proteger√° durante su d√≠a \"grande e inspirador de temor \" nos permitir√°\" [ver] la salvaci√≥n de Jehov√° \" y as√≠ mantenernos leales.']\n",
      "['La fe en esa protecci√≥n ser√° imprescindible para nuestra salvaci√≥n y nuestra lealtad.']\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.4G\n",
      "4.0K drwxrwxr-x  2 americasnlp americasnlp 4.0K Mar  9 15:29 .\n",
      "4.0K drwxr-xr-x 10 americasnlp americasnlp 4.0K Mar  9 15:35 ..\n",
      " 22M -rw-rw-r--  1 americasnlp americasnlp  22M Mar  9 15:22 all_texts_file.csv\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  896 Mar  9 21:10 config.json\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  184 Mar  9 21:10 generation_config.json\n",
      "2.4G -rw-rw-r--  1 americasnlp americasnlp 2.4G Mar  9 21:10 pytorch_model.bin\n",
      "4.8M -rw-rw-r--  1 americasnlp americasnlp 4.8M Mar  9 21:10 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp 3.5K Mar  9 21:10 special_tokens_map.json\n",
      "384K -rw-rw-r--  1 americasnlp americasnlp 382K Mar  9 15:22 spm_16k.model\n",
      "160K -rw-rw-r--  1 americasnlp americasnlp 157K Mar  9 15:22 spm_16k.vocab\n",
      "4.8M -rw-rw-r--  1 americasnlp americasnlp 4.8M Mar  9 15:22 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  570 Mar  9 21:10 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kuyakuymanta takikunam √±uqapaqqa aswan gustan']\n"
     ]
    }
   ],
   "source": [
    "t = \"las canciones de amor me gustan mucho\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Icha kuyaymanta takikunam kusichiwan']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Me encantan las canciones con melod√≠a.']\n"
     ]
    }
   ],
   "source": [
    "t = \"kuyakuyllawan takitam anchata kuyani\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['La toalla del cine es m√°s que mi sue√±o a diario']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f0e1e525024c80807c98b4b37555f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24976 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac899101db5941f68c89176d8e5eb090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24976 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 19.26 47.7/24.3/16.2/11.3 (BP = 0.898 ratio = 0.903 hyp_len = 403768 ref_len = 447315)\n",
      "chrF2++ = 37.42\n",
      "BLEU = 9.16 33.8/11.8/6.6/4.4 (BP = 0.885 ratio = 0.891 hyp_len = 265408 ref_len = 297933)\n",
      "chrF2++ = 36.65\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quechua</th>\n",
       "      <th>esp</th>\n",
       "      <th>quechua_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12982</th>\n",
       "      <td>Necesitasqallaykichikpi gastaychik.</td>\n",
       "      <td>Hagan cambios.</td>\n",
       "      <td>Imapipas cambiaychik.</td>\n",
       "      <td>Ded√≠quense a cubrir sus necesidades b√°sicas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36270</th>\n",
       "      <td>‚Äò Huk ratollapi ‚Äô nisqanmi qawachin puchukaynin mana unay tiempopi kananmanta.</td>\n",
       "      <td>La expresi√≥n ‚Äúen una sola hora ‚Äù muestra que su destrucci√≥n ser√° relativamente r√°pida.</td>\n",
       "      <td>Huk horallapi kasqankum qawachin satanaspa puchukaynin chaylla kananmanta.</td>\n",
       "      <td>Las palabras de una oraci√≥n en lenguaje sencillo indican que el fin est√° muy cerca.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77931</th>\n",
       "      <td>Bardet runapa nisqanman hinaqa, Cristo sutiqa allintapunim tupan griego rimaypi qellqasqa kasqan...</td>\n",
       "      <td>En su an√°lisis, Bardet declara que ese t√≠tulo concuerda ‚Äúen todo sentido con el idioma griego, q...</td>\n",
       "      <td>Bardet sutiyoq runam qellqasqanpi nin: \"Chay sutiqa tupashanmi griego rimaypi kaq sutikunawan, c...</td>\n",
       "      <td>Bardet explica que el nombre Cristo encaja muy bien con el texto griego original.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156122</th>\n",
       "      <td>Kallpachawananchismi allin kaqta ruwanapaq allin runa kananchispaqpas.</td>\n",
       "      <td>Adem√°s, debe sacar lo mejor de cada uno de nosotros y darnos fuerzas para hacer lo que est√° bien.</td>\n",
       "      <td>Hinaspapas sapankanchistan kallpachashan allin kaqkunata ruwananchispaq.</td>\n",
       "      <td>Tiene que motivarnos a hacer lo correcto y a cultivar cualidades cristianas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119112</th>\n",
       "      <td>Chay mozo√±ataqmi i√±iqmasinchikta nirqa paywan rimayta mana munasqanmanta.</td>\n",
       "      <td>El joven le dijo que no quer√≠a hablar con √©l.</td>\n",
       "      <td>Chay wayna√±ataqmi nirqa paywan mana rimayta munasqanta.</td>\n",
       "      <td>El joven le dijo a la hermana que no quer√≠a hablar con √©l.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140928</th>\n",
       "      <td>‚Ä¢ ¬øImataq ‚Äò llamp‚Äôu sonqo ‚Äô kayri?</td>\n",
       "      <td>‚Ä¢ ¬øQu√© significa ser ‚Äúde genio apacible ‚Äù?</td>\n",
       "      <td>‚Ä¢ ¬øIma ninantaq llampu sonqo kayqa?</td>\n",
       "      <td>‚Ä¢ ¬øQu√© es la apacibilidad y la modestia?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45324</th>\n",
       "      <td>Chayna ma√±akuymi qawachin √±oqanchikmantawan hukkunamanta ima piensasqanchikta.</td>\n",
       "      <td>Ese tipo de oraciones revelan mucho sobre nosotros y sobre la manera en que vemos a los hermanos.</td>\n",
       "      <td>Chayna ma√±akusqanchikmi qawachiwanchik imayna kasqanchikta hinaspa i√±iqmasinchikkunata imayna qa...</td>\n",
       "      <td>Este tipo de oraci√≥n revela lo que pensamos de nosotros y de los dem√°s.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210637</th>\n",
       "      <td>Ar√≠, umallikunaqa ‚Äò michiwashallanchispunin ‚Äô (otaq ‚Äò mana pu√±uspa almanchista qhawashanku ‚Äô, Qh...</td>\n",
       "      <td>Los ancianos est√°n ‚Äúvelando por las almas ‚Äù de sus hermanos.</td>\n",
       "      <td>Congregacionpi ancianokunaqa i√±iqmasinkunapa sonqonmantam cuentallikuchkanku.</td>\n",
       "      <td>En efecto, los superintendentes cristianos siempre est√°n pendientes de nuestro bienestar espirit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193954</th>\n",
       "      <td>Ichaqa iskay semana apachisqanku qhepamanmi llapanta kutichipusqaku.</td>\n",
       "      <td>Sin embargo, dos semanas despu√©s, el env√≠o entero regres√≥ a la Casa B√≠blica.</td>\n",
       "      <td>Ichaqa iskay semana qhepamanmi chay qelqakuna hunt'a karqan Bibliamanta Yachana Wasiman.</td>\n",
       "      <td>Sin embargo, las dos semanas m√°s tardas, el dinero se les devolvi√≥ en su totalidad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131759</th>\n",
       "      <td>nispa pipas tapuykuqtinmi ninku: ‚ÄúTayta - mamaymi chayta yachachiwaranku ‚Äù otaq‚Äú chhaynatan yach...</td>\n",
       "      <td>Pero si se le preguntara por qu√© cree en √©l, tal vez responder√≠a que as√≠ lo criaron o que eso fu...</td>\n",
       "      <td>Sichus tapusunkiman imarayku paypi i√±isqaykimanta chayqa, yaqapasch√° niwaq: \"Chhaynapin uywasqa ...</td>\n",
       "      <td>Cuando alguien les pregunta si es cierto o no, ellos responden que sus padres nos ense√±aron a ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    quechua  \\\n",
       "12982                                                                   Necesitasqallaykichikpi gastaychik.   \n",
       "36270                        ‚Äò Huk ratollapi ‚Äô nisqanmi qawachin puchukaynin mana unay tiempopi kananmanta.   \n",
       "77931   Bardet runapa nisqanman hinaqa, Cristo sutiqa allintapunim tupan griego rimaypi qellqasqa kasqan...   \n",
       "156122                               Kallpachawananchismi allin kaqta ruwanapaq allin runa kananchispaqpas.   \n",
       "119112                            Chay mozo√±ataqmi i√±iqmasinchikta nirqa paywan rimayta mana munasqanmanta.   \n",
       "140928                                                                   ‚Ä¢ ¬øImataq ‚Äò llamp‚Äôu sonqo ‚Äô kayri?   \n",
       "45324                        Chayna ma√±akuymi qawachin √±oqanchikmantawan hukkunamanta ima piensasqanchikta.   \n",
       "210637  Ar√≠, umallikunaqa ‚Äò michiwashallanchispunin ‚Äô (otaq ‚Äò mana pu√±uspa almanchista qhawashanku ‚Äô, Qh...   \n",
       "193954                                 Ichaqa iskay semana apachisqanku qhepamanmi llapanta kutichipusqaku.   \n",
       "131759  nispa pipas tapuykuqtinmi ninku: ‚ÄúTayta - mamaymi chayta yachachiwaranku ‚Äù otaq‚Äú chhaynatan yach...   \n",
       "\n",
       "                                                                                                        esp  \\\n",
       "12982                                                                                        Hagan cambios.   \n",
       "36270                La expresi√≥n ‚Äúen una sola hora ‚Äù muestra que su destrucci√≥n ser√° relativamente r√°pida.   \n",
       "77931   En su an√°lisis, Bardet declara que ese t√≠tulo concuerda ‚Äúen todo sentido con el idioma griego, q...   \n",
       "156122    Adem√°s, debe sacar lo mejor de cada uno de nosotros y darnos fuerzas para hacer lo que est√° bien.   \n",
       "119112                                                        El joven le dijo que no quer√≠a hablar con √©l.   \n",
       "140928                                                           ‚Ä¢ ¬øQu√© significa ser ‚Äúde genio apacible ‚Äù?   \n",
       "45324     Ese tipo de oraciones revelan mucho sobre nosotros y sobre la manera en que vemos a los hermanos.   \n",
       "210637                                         Los ancianos est√°n ‚Äúvelando por las almas ‚Äù de sus hermanos.   \n",
       "193954                         Sin embargo, dos semanas despu√©s, el env√≠o entero regres√≥ a la Casa B√≠blica.   \n",
       "131759  Pero si se le preguntara por qu√© cree en √©l, tal vez responder√≠a que as√≠ lo criaron o que eso fu...   \n",
       "\n",
       "                                                                                         quechua_translated  \\\n",
       "12982                                                                                 Imapipas cambiaychik.   \n",
       "36270                            Huk horallapi kasqankum qawachin satanaspa puchukaynin chaylla kananmanta.   \n",
       "77931   Bardet sutiyoq runam qellqasqanpi nin: \"Chay sutiqa tupashanmi griego rimaypi kaq sutikunawan, c...   \n",
       "156122                             Hinaspapas sapankanchistan kallpachashan allin kaqkunata ruwananchispaq.   \n",
       "119112                                              Chay wayna√±ataqmi nirqa paywan mana rimayta munasqanta.   \n",
       "140928                                                                  ‚Ä¢ ¬øIma ninantaq llampu sonqo kayqa?   \n",
       "45324   Chayna ma√±akusqanchikmi qawachiwanchik imayna kasqanchikta hinaspa i√±iqmasinchikkunata imayna qa...   \n",
       "210637                        Congregacionpi ancianokunaqa i√±iqmasinkunapa sonqonmantam cuentallikuchkanku.   \n",
       "193954             Ichaqa iskay semana qhepamanmi chay qelqakuna hunt'a karqan Bibliamanta Yachana Wasiman.   \n",
       "131759  Sichus tapusunkiman imarayku paypi i√±isqaykimanta chayqa, yaqapasch√° niwaq: \"Chhaynapin uywasqa ...   \n",
       "\n",
       "                                                                                             esp_translated  \n",
       "12982                                                          Ded√≠quense a cubrir sus necesidades b√°sicas.  \n",
       "36270                   Las palabras de una oraci√≥n en lenguaje sencillo indican que el fin est√° muy cerca.  \n",
       "77931                     Bardet explica que el nombre Cristo encaja muy bien con el texto griego original.  \n",
       "156122                         Tiene que motivarnos a hacer lo correcto y a cultivar cualidades cristianas.  \n",
       "119112                                           El joven le dijo a la hermana que no quer√≠a hablar con √©l.  \n",
       "140928                                                             ‚Ä¢ ¬øQu√© es la apacibilidad y la modestia?  \n",
       "45324                               Este tipo de oraci√≥n revela lo que pensamos de nosotros y de los dem√°s.  \n",
       "210637  En efecto, los superintendentes cristianos siempre est√°n pendientes de nuestro bienestar espirit...  \n",
       "193954                  Sin embargo, las dos semanas m√°s tardas, el dinero se les devolvi√≥ en su totalidad.  \n",
       "131759  Cuando alguien les pregunta si es cierto o no, ellos responden que sus padres nos ense√±aron a ha...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
