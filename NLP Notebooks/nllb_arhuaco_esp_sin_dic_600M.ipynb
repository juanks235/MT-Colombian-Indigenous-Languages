{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=3\n",
    "MODEL_USED=\"facebook/nllb-200-distilled-600M\"\n",
    "# MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_arhuaco_esp_sin_dic_600m\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"arh_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"ayr_Latn\" # Central Aymara\n",
    "LANGUAGE_FILE=\"data/arh_sin_dic.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"arh\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5672, 2)\n",
      "Index(['arh', 'esp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4537 entries, 4966 to 860\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     4537 non-null   object\n",
      " 1   esp     4537 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 106.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>Niwisakuku Jes√∫ zaka'nugasin …âwa win ânk âsana n...</td>\n",
       "      <td>Cuando los ap√≥stoles que estaban en Jerusal√©n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>a'ga uweri n âkeyri, k âmeyuzey ayeygwi …âe a'gi'...</td>\n",
       "      <td>Si ella me responde: ‚ÄúBebe, y tambi√©n sacar√© a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>Josesin win ânkuya …âinari, sakuse' trigu  ânwin â...</td>\n",
       "      <td>Entonces ellos cargaron el grano sobre sus asn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>Ey uye'ri Jesuse' keyw â key ie'ri: ‚Äî‚ÄúTaÃÅ kinki...</td>\n",
       "      <td>Y a√±adi√≥:‚ÄîJes√∫s, acu√©rdate de m√≠ cuando vengas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Ey uye'ki Lori …âw ân z ân riware'ri, Niwipaw z â ...</td>\n",
       "      <td>Pero como Lot titubeaba, los mensajeros los ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "4966  Niwisakuku Jes√∫ zaka'nugasin …âwa win ânk âsana n...   \n",
       "1071  a'ga uweri n âkeyri, k âmeyuzey ayeygwi …âe a'gi'...   \n",
       "718   Josesin win ânkuya …âinari, sakuse' trigu  ânwin â...   \n",
       "4114  Ey uye'ri Jesuse' keyw â key ie'ri: ‚Äî‚ÄúTaÃÅ kinki...   \n",
       "670   Ey uye'ki Lori …âw ân z ân riware'ri, Niwipaw z â ...   \n",
       "\n",
       "                                                    esp  \n",
       "4966  Cuando los ap√≥stoles que estaban en Jerusal√©n ...  \n",
       "1071  Si ella me responde: ‚ÄúBebe, y tambi√©n sacar√© a...  \n",
       "718   Entonces ellos cargaron el grano sobre sus asn...  \n",
       "4114  Y a√±adi√≥:‚ÄîJes√∫s, acu√©rdate de m√≠ cuando vengas...  \n",
       "670   Pero como Lot titubeaba, los mensajeros los ag...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 567 entries, 4453 to 219\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     567 non-null    object\n",
      " 1   esp     567 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>ik ânha'se'ri: ‚Äî‚ÄúSakuku emiri mowga masite gekw...</td>\n",
       "      <td>Ellos dijeron:‚Äî¬°Se√±or, aqu√≠ tenemos dos espada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Oh! Pinna juna chuka a‚Äô zuna kwuyun Chuka me‚Äôz...</td>\n",
       "      <td>¬°Oh, naturaleza!, lugar de vida y alegr√≠a, te ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>ey awiki eyma cheyrwari t ânhana gun n ânnige'ri...</td>\n",
       "      <td>Y a√±adi√≥:‚ÄîQue los dirigentes de ustedes me aco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>Sink â  ânzanisi tw√≠  ânzanik ân pare'ri, Lori pow...</td>\n",
       "      <td>Al caer la tarde los dos mensajeros llegaron a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>posuri …âom â zariri aroma z ânek â win âk âwitesi n...</td>\n",
       "      <td>y, agarr√°ndolo, lo arrojaron a un aljibe que e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "4453  ik ânha'se'ri: ‚Äî‚ÄúSakuku emiri mowga masite gekw...   \n",
       "101   Oh! Pinna juna chuka a‚Äô zuna kwuyun Chuka me‚Äôz...   \n",
       "5333  ey awiki eyma cheyrwari t ânhana gun n ânnige'ri...   \n",
       "655   Sink â  ânzanisi tw√≠  ânzanik ân pare'ri, Lori pow...   \n",
       "1620  posuri …âom â zariri aroma z ânek â win âk âwitesi n...   \n",
       "\n",
       "                                                    esp  \n",
       "4453  Ellos dijeron:‚Äî¬°Se√±or, aqu√≠ tenemos dos espada...  \n",
       "101   ¬°Oh, naturaleza!, lugar de vida y alegr√≠a, te ...  \n",
       "5333  Y a√±adi√≥:‚ÄîQue los dirigentes de ustedes me aco...  \n",
       "655   Al caer la tarde los dos mensajeros llegaron a...  \n",
       "1620  y, agarr√°ndolo, lo arrojaron a un aljibe que e...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 568 entries, 2515 to 4410\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   arh     568 non-null    object\n",
      " 1   esp     568 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>Uye' Mar√≠a Magdalena awiri i'ngweygwi Mariari,...</td>\n",
       "      <td>Entre tanto, Mar√≠a Magdalena y la otra Mar√≠a e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2c. iku kagumu rekumanaba kwuya-jinari, gwamu ...</td>\n",
       "      <td>estos puntos suspensivos est√°n para representa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>ey awi ing â …âiw â b âk âna ka' a'nikw âya Kawda za...</td>\n",
       "      <td>Pasamos a sotavento de Cauda, una peque√±a isla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Ey anuna…âu n ângwa ga'kumana …âinari i'm ân â eygw...</td>\n",
       "      <td>Los ap√≥stoles volvieron a reunirse con Jes√∫s y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>In â aw âtari a'z ânari, ku'nawak â z ândi  ânk ânnis...</td>\n",
       "      <td>Acumulen, m√°s bien, riquezas en el cielo, dond...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arh  \\\n",
       "2515  Uye' Mar√≠a Magdalena awiri i'ngweygwi Mariari,...   \n",
       "44    2c. iku kagumu rekumanaba kwuya-jinari, gwamu ...   \n",
       "4922  ey awi ing â …âiw â b âk âna ka' a'nikw âya Kawda za...   \n",
       "3250  Ey anuna…âu n ângwa ga'kumana …âinari i'm ân â eygw...   \n",
       "2656  In â aw âtari a'z ânari, ku'nawak â z ândi  ânk ânnis...   \n",
       "\n",
       "                                                    esp  \n",
       "2515  Entre tanto, Mar√≠a Magdalena y la otra Mar√≠a e...  \n",
       "44    estos puntos suspensivos est√°n para representa...  \n",
       "4922  Pasamos a sotavento de Cauda, una peque√±a isla...  \n",
       "3250  Los ap√≥stoles volvieron a reunirse con Jes√∫s y...  \n",
       "2656  Acumulen, m√°s bien, riquezas en el cielo, dond...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>arh</th>\n",
       "      <th>arh_words</th>\n",
       "      <th>arh_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>Jes√∫s sigui√≥ su camino y entr√≥ en una sinagoga.</td>\n",
       "      <td>[Jes√∫s, sigui√≥, su, camino, y, entr√≥, en, una,...</td>\n",
       "      <td>[‚ñÅJes√∫s, ‚ñÅsigui√≥, ‚ñÅsu, ‚ñÅcamino, ‚ñÅy, ‚ñÅent, r√≥, ...</td>\n",
       "      <td>Jesuri eymi pari w â  ânzori eym ânke kingwi sina...</td>\n",
       "      <td>[Jesuri, eymi, pari, w â,  ânzori, eym ânke, king...</td>\n",
       "      <td>[‚ñÅJes, uri, ‚ñÅey, mi, ‚ñÅpari, ‚ñÅw,  â, ‚ñÅ,  â, nz, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Jura que no nos har√°s ning√∫n da√±o, pues nosotr...</td>\n",
       "      <td>[Jura, que, no, nos, har√°s, ning√∫n, da√±o, ,, p...</td>\n",
       "      <td>[‚ñÅJ, ura, ‚ñÅque, ‚ñÅno, ‚ñÅnos, ‚ñÅhar, √°s, ‚ñÅning√∫n, ...</td>\n",
       "      <td>Niwiri buni'g âm â me'kukumu nari, du z ân minhac...</td>\n",
       "      <td>[Niwiri, buni, ', g âm â, me, ', kukumu, nari, ,...</td>\n",
       "      <td>[‚ñÅNi, wiri, ‚ñÅbuni, ', g,  â, m,  â, ‚ñÅme, ', kuk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>Y en el sue√±o, el √°ngel de Dios me dijo: ¬´Jaco...</td>\n",
       "      <td>[Y, en, el, sue√±o, ,, el, √°ngel, de, Dios, me,...</td>\n",
       "      <td>[‚ñÅY, ‚ñÅen, ‚ñÅel, ‚ñÅsue√±o, ,, ‚ñÅel, ‚ñÅ√°, ngel, ‚ñÅde, ...</td>\n",
       "      <td>Ey awi keyw âri k âm âse' kingwi Niwipaw z â gunam...</td>\n",
       "      <td>[Ey, awi, keyw âri, k âm âse, ', kingwi, Niwipaw,...</td>\n",
       "      <td>[‚ñÅEy, ‚ñÅawi, ‚ñÅkey, w,  â, ri, ‚ñÅk,  â, m,  â, se, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5174</th>\n",
       "      <td>En ese mismo momento llegaron tres hombres a l...</td>\n",
       "      <td>[En, ese, mismo, momento, llegaron, tres, homb...</td>\n",
       "      <td>[‚ñÅEn, ‚ñÅese, ‚ñÅmismo, ‚ñÅmomento, ‚ñÅlleg, aron, ‚ñÅtr...</td>\n",
       "      <td>Ey anaw ân nuse'ri, m√°yk ân â cheyrwa keyw â Sesar...</td>\n",
       "      <td>[Ey, anaw ân, nuse, ', ri, ,, m√°yk ân â, cheyrwa,...</td>\n",
       "      <td>[‚ñÅEy, ‚ñÅana, w,  â, n, ‚ñÅn, use, ', ri, ,, ‚ñÅm√°, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>A partir de aquel momento, Jes√∫s empez√≥ a mani...</td>\n",
       "      <td>[A, partir, de, aquel, momento, ,, Jes√∫s, empe...</td>\n",
       "      <td>[‚ñÅA, ‚ñÅpartir, ‚ñÅde, ‚ñÅaquel, ‚ñÅmomento, ,, ‚ñÅJes√∫s...</td>\n",
       "      <td>Ey awi Jesuri eygwi k âriwiya …âina zach ân kinki...</td>\n",
       "      <td>[Ey, awi, Jesuri, eygwi, k âriwiya, …âina, zach â...</td>\n",
       "      <td>[‚ñÅEy, ‚ñÅawi, ‚ñÅJes, uri, ‚ñÅe, yg, wi, ‚ñÅk,  â, ri, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    esp  \\\n",
       "2529    Jes√∫s sigui√≥ su camino y entr√≥ en una sinagoga.   \n",
       "270   Jura que no nos har√°s ning√∫n da√±o, pues nosotr...   \n",
       "1431  Y en el sue√±o, el √°ngel de Dios me dijo: ¬´Jaco...   \n",
       "5174  En ese mismo momento llegaron tres hombres a l...   \n",
       "2128  A partir de aquel momento, Jes√∫s empez√≥ a mani...   \n",
       "\n",
       "                                              esp_words  \\\n",
       "2529  [Jes√∫s, sigui√≥, su, camino, y, entr√≥, en, una,...   \n",
       "270   [Jura, que, no, nos, har√°s, ning√∫n, da√±o, ,, p...   \n",
       "1431  [Y, en, el, sue√±o, ,, el, √°ngel, de, Dios, me,...   \n",
       "5174  [En, ese, mismo, momento, llegaron, tres, homb...   \n",
       "2128  [A, partir, de, aquel, momento, ,, Jes√∫s, empe...   \n",
       "\n",
       "                                               esp_toks  \\\n",
       "2529  [‚ñÅJes√∫s, ‚ñÅsigui√≥, ‚ñÅsu, ‚ñÅcamino, ‚ñÅy, ‚ñÅent, r√≥, ...   \n",
       "270   [‚ñÅJ, ura, ‚ñÅque, ‚ñÅno, ‚ñÅnos, ‚ñÅhar, √°s, ‚ñÅning√∫n, ...   \n",
       "1431  [‚ñÅY, ‚ñÅen, ‚ñÅel, ‚ñÅsue√±o, ,, ‚ñÅel, ‚ñÅ√°, ngel, ‚ñÅde, ...   \n",
       "5174  [‚ñÅEn, ‚ñÅese, ‚ñÅmismo, ‚ñÅmomento, ‚ñÅlleg, aron, ‚ñÅtr...   \n",
       "2128  [‚ñÅA, ‚ñÅpartir, ‚ñÅde, ‚ñÅaquel, ‚ñÅmomento, ,, ‚ñÅJes√∫s...   \n",
       "\n",
       "                                                    arh  \\\n",
       "2529  Jesuri eymi pari w â  ânzori eym ânke kingwi sina...   \n",
       "270   Niwiri buni'g âm â me'kukumu nari, du z ân minhac...   \n",
       "1431  Ey awi keyw âri k âm âse' kingwi Niwipaw z â gunam...   \n",
       "5174  Ey anaw ân nuse'ri, m√°yk ân â cheyrwa keyw â Sesar...   \n",
       "2128  Ey awi Jesuri eygwi k âriwiya …âina zach ân kinki...   \n",
       "\n",
       "                                              arh_words  \\\n",
       "2529  [Jesuri, eymi, pari, w â,  ânzori, eym ânke, king...   \n",
       "270   [Niwiri, buni, ', g âm â, me, ', kukumu, nari, ,...   \n",
       "1431  [Ey, awi, keyw âri, k âm âse, ', kingwi, Niwipaw,...   \n",
       "5174  [Ey, anaw ân, nuse, ', ri, ,, m√°yk ân â, cheyrwa,...   \n",
       "2128  [Ey, awi, Jesuri, eygwi, k âriwiya, …âina, zach â...   \n",
       "\n",
       "                                               arh_toks  \n",
       "2529  [‚ñÅJes, uri, ‚ñÅey, mi, ‚ñÅpari, ‚ñÅw,  â, ‚ñÅ,  â, nz, o...  \n",
       "270   [‚ñÅNi, wiri, ‚ñÅbuni, ', g,  â, m,  â, ‚ñÅme, ', kuk,...  \n",
       "1431  [‚ñÅEy, ‚ñÅawi, ‚ñÅkey, w,  â, ri, ‚ñÅk,  â, m,  â, se, '...  \n",
       "5174  [‚ñÅEy, ‚ñÅana, w,  â, n, ‚ñÅn, use, ', ri, ,, ‚ñÅm√°, y...  \n",
       "2128  [‚ñÅEy, ‚ñÅawi, ‚ñÅJes, uri, ‚ñÅe, yg, wi, ‚ñÅk,  â, ri, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243907/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>arh_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>arh_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.345700</td>\n",
       "      <td>72.25660</td>\n",
       "      <td>26.652200</td>\n",
       "      <td>36.86700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.759254</td>\n",
       "      <td>31.14541</td>\n",
       "      <td>11.865088</td>\n",
       "      <td>16.80376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>51.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>26.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>35.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>88.00000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>45.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>438.000000</td>\n",
       "      <td>542.00000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>370.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks     arh_toks     esp_words    arh_words\n",
       "count  10000.000000  10000.00000  10000.000000  10000.00000\n",
       "mean      33.345700     72.25660     26.652200     36.86700\n",
       "std       14.759254     31.14541     11.865088     16.80376\n",
       "min        2.000000      1.00000      1.000000      1.00000\n",
       "25%       24.000000     51.00000     19.000000     26.00000\n",
       "50%       31.000000     68.00000     25.000000     35.00000\n",
       "75%       41.000000     88.00000     32.000000     45.00000\n",
       "max      438.000000    542.00000    323.000000    370.00000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2511424948034309\n",
      "1.9599262212819055\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c118ef23614dc1a5586379d823ec9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4369\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"…Ñweri miwisinke' N âsakuku ka'm âkari, dudu anugwe n âk ânari, mawria  ânkidoki, nare' jud√≠w …âinari azekin azekin kizan ângwa, im â winn âwari ku'n ânkwe.\",\n",
       " \"Ey awi eym√≠ nise'ri Abraan z â gunam âse'ri amasay k âch â nariri ey chw ân z ân nu'na: ‚Äî‚ÄúT√° kinki N âpawri Isaazey nari a'mia a'gusi n ângun√°m âsow ki un ânno‚Äù a'zan ân nusi n ângwa.\",\n",
       " \"Ey awi n ângwari Italia keyw â niwiga's ângwa  ânwina'zare'ri, Pablusin wina'gekw ân nu'na …âinari, i'ngwi soldadu z â sakuku emperador ka'm âk âna Juliw za'kinugase' keyw â niwip ânhakumey.\",\n",
       " \"ey awi  ânchus âkwa k âzare'ri fara√≥n z â bu'g âm âse' gu'na…âuri ag âm âsin â n√°n âkin  âwari ineysana gun n ândi.\",\n",
       " \"¬°Farisew …âina azi ch âwi mi me'z ânniko! Sinagogase'ri sanusi akuma…âuriri, o'kak âri aw ânkawa miwiwari miwimasaykwa rigaw ânari nanu'kinoÃÅ.\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "s = random.sample(texts_with_unk, 5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace ùìïùîØùîûùî´ùî†ùî¢ùî∞ùî†ùîû by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f86acce23a14993bfeff2f128397110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3437\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2042654ff7b14fe89fac05bdae3a6878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_arhuaco_esp_sin_dic_600m/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_arhuaco_esp_sin_dic_600m/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8192\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: nai âwkeru'ygsmzoh,cd.t…âp\"b√°E√≠J:-NlA√©√∫√≥IMSP¬ø?U;…ÑKfLjBG()D!¬°RTYFCÃÅZH√±O…àW ª º√â√Åv√ç#1x38\\24657+\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_arhuaco_esp_sin_dic_600m/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 5672 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=886957\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=102\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 5672 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=526687\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 31418 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 5672\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 24491\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 24491 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12222 obj=14.9188 num_tokens=67752 num_tokens/piece=5.54345\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9977 obj=11.9106 num_tokens=68365 num_tokens/piece=6.85226\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8822 obj=11.8087 num_tokens=68659 num_tokens/piece=7.7827\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8683 obj=11.7712 num_tokens=68881 num_tokens/piece=7.93286\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_arhuaco_esp_sin_dic_600m/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_arhuaco_esp_sin_dic_600m/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**13,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-07 00:17:18--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-07 00:17:18 (78.1 MB/s) - ‚Äò/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py‚Äô saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256204 262849\n",
      "6644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 00:17:22.137645: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-07 00:17:22.282632: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-07 00:17:22.990573: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-07 00:17:22.990638: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-07 00:17:22.990644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 262849. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ebe0e153b54c3eb96057f92f6ba477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6644 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262849\n",
      "['zul_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256203 + len(added_vocab) + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'arh_Latn', '<mask>']\n",
      "[262847, 262848, 262849]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256202 + len(added_vocab) + 2, 256202 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262848 262663\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 262850. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(262850, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['n ân kingwi nari, tasa faraonse\\' winu ka\\'dokum âya n âg√≠si, tasase\\' kingwi uwa a\\'pisi a\\'dosiri, faraonse\\' a\\'wesi nik ânu\\'kwin na\\'zarin\" key ie\\' n ângwa.'], ['Con la copa del fara√≥n en la mano, yo tomaba los racimos, los estrujaba en la copa y luego yo mismo la pon√≠a en la mano del fara√≥n.'], 'arh_Latn', 'spa_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd908f06487d4d679d8b57159c9213be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10.351624488830566\n",
      "1000 5.091482271432876\n",
      "2000 3.430109186410904\n",
      "3000 2.814390585064888\n",
      "4000 2.4494245703220368\n",
      "5000 2.079946208357811\n",
      "6000 1.826365584731102\n",
      "7000 1.5457723111510278\n",
      "8000 1.297390819877386\n",
      "9000 1.086095903456211\n",
      "10000 0.9495658976733684\n",
      "11000 0.823296778306365\n",
      "12000 0.7129636156260968\n",
      "13000 0.6080587100163102\n",
      "14000 0.5306741909459233\n",
      "15000 0.4921036439165473\n",
      "16000 0.43846590384468437\n",
      "17000 0.3731550155095756\n",
      "18000 0.33544732188433407\n",
      "19000 0.2969999492838979\n",
      "20000 0.2658815026022494\n",
      "21000 0.2323539179265499\n",
      "22000 0.20697627918422223\n",
      "23000 0.18218976302817463\n",
      "24000 0.16530198775418103\n",
      "25000 0.1477595067843795\n",
      "26000 0.12258790487702936\n",
      "27000 0.10926086606644093\n",
      "28000 0.09436059561837465\n",
      "29000 0.08761291291192173\n",
      "30000 0.07505015329271555\n",
      "31000 0.06951446061208844\n",
      "32000 0.06435905090160668\n",
      "33000 0.05811415484361351\n",
      "34000 0.05570054839830846\n",
      "35000 0.05115646707126871\n",
      "36000 0.047427932837978005\n",
      "37000 0.043614881402812895\n",
      "38000 0.041311712473630906\n",
      "39000 0.03981989130796865\n",
      "40000 0.03907250942965038\n",
      "41000 0.036612741109915074\n",
      "42000 0.03502824559505097\n",
      "43000 0.0350554143874906\n",
      "44000 0.03181265721493401\n",
      "45000 0.0308109094388783\n",
      "46000 0.030462296541780235\n",
      "47000 0.030917348409304397\n",
      "48000 0.028288263702066614\n",
      "49000 0.028015535846352576\n",
      "50000 0.027553652526112273\n",
      "51000 0.026894183141179383\n",
      "52000 0.02610252053523436\n",
      "53000 0.02465636347932741\n",
      "54000 0.02379892169102095\n",
      "55000 0.023496527603594587\n",
      "56000 0.02185442788945511\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diciendo: - Conc√©danme tambi√©n a m√≠ el poder de que, cuando imponga las manos a alguno, reciba el Esp√≠ritu Santo.']\n",
      "[\"Awi m√° kinkiri niwi zana' gwi nari in â nipariza neki nanu' gun n ândi, awi keyw âri anugwese' narunh âyari du neki narunhu' ni Niwipawri miwanu'kin√≥.\"]\n",
      "['- \"N ân ayeygwi bema neki gun â ipani\\'kwe\\'ri Anugwe Duna winipan ângwasi mi…âumam â a\\'nikw âya\\'ba pari,']\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.4G\n",
      "4.0K drwxrwxr-x 2 americasnlp americasnlp 4.0K Mar  7 00:25 .\n",
      "4.0K drwxrwxr-x 5 americasnlp americasnlp 4.0K Mar  7 02:30 ..\n",
      "960K -rw-rw-r-- 1 americasnlp americasnlp 960K Mar  7 00:17 all_texts_file.csv\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  896 Mar  7 07:42 config.json\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  184 Mar  7 07:42 generation_config.json\n",
      "2.4G -rw-rw-r-- 1 americasnlp americasnlp 2.4G Mar  7 07:42 pytorch_model.bin\n",
      "4.8M -rw-rw-r-- 1 americasnlp americasnlp 4.8M Mar  7 07:42 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp 3.5K Mar  7 07:42 special_tokens_map.json\n",
      "376K -rw-rw-r-- 1 americasnlp americasnlp 373K Mar  7 00:17 spm_16k.model\n",
      "148K -rw-rw-r-- 1 americasnlp americasnlp 148K Mar  7 00:17 spm_16k.vocab\n",
      "4.8M -rw-rw-r-- 1 americasnlp americasnlp 4.8M Mar  7 00:17 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r-- 1 americasnlp americasnlp  570 Mar  7 07:42 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"kwey awkwa n âkey ga'k ânam âse' a's âyase'ri, n ândi n âkak â riguz ânhas âkwa na'z ânin\"]\n"
     ]
    }
   ],
   "source": [
    "t = \"las canciones de amor me gustan mucho\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"c âran âgaka miwika'guka uwin n ânk âri ka'  ânkum ây ân im â zorie'ri,\"]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['habr√° un n√∫mero adicional de dos senadores elegidos en circunscripci√≥n nacional especial por comunidades ind√≠genas. el n√∫mero de senadores elegidos en circunscripci√≥n nacional especial por comunidades ind√≠genas se habr√° duplicado en circunscripci√≥n nacional especial por comunidades ind√≠genas.']\n"
     ]
    }
   ],
   "source": [
    "t = \"kuyakuyllawan takitam anchata kuyani\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['habr√° un d√≠a en que habr√° un consejo nacional de planeaci√≥n integrado por representates de las entidades territoriales y de los sectores econ√≥micos, sociales, ecol√≥gicos, comunitarios y culturales. el consejo tendr√° car√°cter consultivo y servir√° de foro para la discusi√≥n del plan nacional de desarrollo.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879e83ad45944bcfb541a4a43cbee732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718b15c204874d26a53a188eeacfcc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 7.28 28.8/7.6/4.4/3.1 (BP = 0.989 ratio = 0.989 hyp_len = 14871 ref_len = 15030)\n",
      "chrF2++ = 23.06\n",
      "BLEU = 8.29 29.7/10.3/5.2/3.2 (BP = 0.981 ratio = 0.982 hyp_len = 14115 ref_len = 14379)\n",
      "chrF2++ = 32.95\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arh</th>\n",
       "      <th>esp</th>\n",
       "      <th>arh_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>Uye'ri Judase'ri: ‚Äî‚Äú¬øIn â n âk âchusan ândi me'zano?‚Äù key ie'ri: ‚Äî‚ÄúSeyu awiri  âya s√≠ mik âbenuga mika...</td>\n",
       "      <td>Jud√° pregunt√≥:‚Äî¬øQu√© quieres que te deje?Ella respondi√≥:‚ÄîTu sello con su cord√≥n y el bast√≥n que l...</td>\n",
       "      <td>Uye' n ângwari Jud√°ri: - \"¬øAzi minhaw ângwasiri n ânno?\" key ie'ri, ase'ri: - \"S âm ângwasiri m âk â z√≠...</td>\n",
       "      <td>Entonces Jud√° le dijo: - Deja que el muchacho venga bajo mi cuidado y pong√°monos inmediatamente ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>Ey anuna…âu n ângwa Israerise' keyw â key ie'ri: ‚Äî‚ÄúT√° kinki, iwa n ângwa eyki n âkuy ân  ânna'z ân gun a...</td>\n",
       "      <td>Entonces Israel dijo a Jos√©:‚ÄîAhora ya puedo morir. Te he visto y s√© que est√°s vivo.</td>\n",
       "      <td>Israeri Jos√© ey keyri: - \"Iwa keyw â z ândi  ânwichana, anugwese' me'z ânnige'ri wicha awn ângwa ni g...</td>\n",
       "      <td>El Se√±or le dijo: - Esc√∫chame, Israel: Yo soy el Se√±or que te sac√≥ de Ur de los caldeos para dar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>Ey anuna…âu n ângwari asige' …âir âgakak â pari  ândiyun ân nuse'ri, ik â z âguroÃÅk âch â Jesusin win ânka'r...</td>\n",
       "      <td>Al d√≠a siguiente, cuando bajaron del monte, mucha gente sali√≥ al encuentro de Jes√∫s.</td>\n",
       "      <td>Ey awi asige' bunsi  ânchare'ri, k ânk ân âse' pari rizwein rinuse'ri, Jesuri s âm â nase'ri winkinkum...</td>\n",
       "      <td>Al d√≠a siguiente, de madrugada, cuando los disc√≠pulos regresaron a la ciudad, encontraron a Jes√∫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Ey awi …âwiku' pari ratrekindi ka'g âm âse'ri a…âu yow tw√≠ zanika una.</td>\n",
       "      <td>Desde el mediod√≠a, toda la tierra qued√≥ sumida en oscuridad hasta las tres de la tarde.</td>\n",
       "      <td>…àw√≠ nen ân yow aniwicha uye' Niwipaw urak ân kortina k âp ânkwanari b âk ân√°ta  ânt âre're'ri,</td>\n",
       "      <td>Jes√∫s le contest√≥: - Te aseguro que hoy estar√°s conmigo en el para√≠so.Muerte de Jes√∫s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>emi akwey zoyeyka, yow, paperi asamu yamu awiukwa, ingwiri gug√≠n (guchu) unnuku name, kwa gug√≠n ...</td>\n",
       "      <td>para hacer efectiva la protecci√≥n de estos derechos existen unos mecanismos que podemos utilizar...</td>\n",
       "      <td>1. michwi enanuy√°y win√≠kwuya (ga'kunamu abunna zukutuse anikw√°y kawi unchunungwasi, gakunamu abu...</td>\n",
       "      <td>estos mecanismos se llaman acciones y se pueden utilizar cuando exista una amenaza de violaci√≥n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Ey uye' n ângwa Jakobuse' key ie'ri: ‚Äî‚ÄúSanusi m√° g âm âsin â um ân na'z ânazey in â duna nipan ângwa mik...</td>\n",
       "      <td>Jacob insisti√≥:‚ÄîJ√∫ramelo antes.Esa√∫ se lo jur√≥, y de ese modo le vendi√≥ a Jacob sus derechos de ...</td>\n",
       "      <td>Ey uye' n ângwari Jakoburi eygwi keyw â key ie'ri: - \"Jakobu za'kinugwe Dunari, m√°, g âm âsin â um ân ...</td>\n",
       "      <td>Entonces su padre le dijo: - ¬°Tengo hambre, hijo m√≠o! Ya hice lo que me pediste.Jacob le replic√≥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>Ey awi Perge ga'k ânam â winbasana…âuri eygwi Atal√≠a rizoyana.</td>\n",
       "      <td>Anunciaron el mensaje en Perge y bajaron a Atal√≠a.</td>\n",
       "      <td>Perge ayek âie'ri ga'k ânam â duna zak âwina'cho'si n ângwari Italia keyw â rizoyana.</td>\n",
       "      <td>donde pasaron a Perge y se embarcaron para Italia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>Uye'ki nowmisin âri eygwi ie'ri: ‚Äî‚ÄúKak â Abraan eymiÃÅ n ângwa riniku' rinariza'ch â,  âwe'ki i'ngwi  â...</td>\n",
       "      <td>El rico replic√≥: ¬´No, padre Abrah√°n, solo si alguno de los que han muerto va a hablarles, se con...</td>\n",
       "      <td>Uye' n ângwari nowmisin âse' eygwi key ie'ri: - \"…Ñnne'ki Abraandi,  âwe'ki  ânwicha aw ândi i'ngwi mi...</td>\n",
       "      <td>En cambio, los ricos dicen: \"Ni siquiera me he servido, pero he ganado mi sustento porque espero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>Ey  âweri du win â k âno'kwa uÃÅ, emey gwi nari ing â kindi ey k ân ânase'ri eygwi kaw â ka'sari ukumu'n...</td>\n",
       "      <td>Presten mucha atenci√≥n, porque al que tenga algo, a√∫n se le dar√° m√°s; pero al que no tenga nada,...</td>\n",
       "      <td>…Ñweri ch√≥w z ân riwan âkwa naki. …Ñweri s âm â k ân ânase'ri eygwi kaw âka'sa ukum ândi ichukumari k âna'n...</td>\n",
       "      <td>Les digo que, en el d√≠a del juicio, todo el que tiene, se salvar√°; pero al que no tiene, hasta l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Ing â birin  ânzanika uye'ri, Jud√° z â k âsaw S√∫a z â bu'g âm âri,  ânwicha una, ey awi Jud√°ri iawichana...</td>\n",
       "      <td>Despu√©s de mucho tiempo, muri√≥ la mujer de Jud√°, la hija de S√∫a. Pasado el duelo por ella, subi√≥...</td>\n",
       "      <td>Awi ing â birin  ânzanik ân nuse'ri, Jud√°ri Esa√∫ z â bu'g âm â Jud√°  ânwicha anuye'ri, ik ânha'ri k ânk ân...</td>\n",
       "      <td>M√°s tarde, Jud√° se enter√≥ de que Siqu√©n hab√≠a violado a Dina, y que luego se quit√≥ el lugar dond...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      arh  \\\n",
       "748   Uye'ri Judase'ri: ‚Äî‚Äú¬øIn â n âk âchusan ândi me'zano?‚Äù key ie'ri: ‚Äî‚ÄúSeyu awiri  âya s√≠ mik âbenuga mika...   \n",
       "1350  Ey anuna…âu n ângwa Israerise' keyw â key ie'ri: ‚Äî‚ÄúT√° kinki, iwa n ângwa eyki n âkuy ân  ânna'z ân gun a...   \n",
       "4309  Ey anuna…âu n ângwari asige' …âir âgakak â pari  ândiyun ân nuse'ri, ik â z âguroÃÅk âch â Jesusin win ânka'r...   \n",
       "2499                                   Ey awi …âwiku' pari ratrekindi ka'g âm âse'ri a…âu yow tw√≠ zanika una.   \n",
       "33    emi akwey zoyeyka, yow, paperi asamu yamu awiukwa, ingwiri gug√≠n (guchu) unnuku name, kwa gug√≠n ...   \n",
       "1419  Ey uye' n ângwa Jakobuse' key ie'ri: ‚Äî‚ÄúSanusi m√° g âm âsin â um ân na'z ânazey in â duna nipan ângwa mik...   \n",
       "5135                                          Ey awi Perge ga'k ânam â winbasana…âuri eygwi Atal√≠a rizoyana.   \n",
       "4071  Uye'ki nowmisin âri eygwi ie'ri: ‚Äî‚ÄúKak â Abraan eymiÃÅ n ângwa riniku' rinariza'ch â,  âwe'ki i'ngwi  â...   \n",
       "3922  Ey  âweri du win â k âno'kwa uÃÅ, emey gwi nari ing â kindi ey k ân ânase'ri eygwi kaw â ka'sari ukumu'n...   \n",
       "742   Ing â birin  ânzanika uye'ri, Jud√° z â k âsaw S√∫a z â bu'g âm âri,  ânwicha una, ey awi Jud√°ri iawichana...   \n",
       "\n",
       "                                                                                                      esp  \\\n",
       "748   Jud√° pregunt√≥:‚Äî¬øQu√© quieres que te deje?Ella respondi√≥:‚ÄîTu sello con su cord√≥n y el bast√≥n que l...   \n",
       "1350                  Entonces Israel dijo a Jos√©:‚ÄîAhora ya puedo morir. Te he visto y s√© que est√°s vivo.   \n",
       "4309                 Al d√≠a siguiente, cuando bajaron del monte, mucha gente sali√≥ al encuentro de Jes√∫s.   \n",
       "2499              Desde el mediod√≠a, toda la tierra qued√≥ sumida en oscuridad hasta las tres de la tarde.   \n",
       "33    para hacer efectiva la protecci√≥n de estos derechos existen unos mecanismos que podemos utilizar...   \n",
       "1419  Jacob insisti√≥:‚ÄîJ√∫ramelo antes.Esa√∫ se lo jur√≥, y de ese modo le vendi√≥ a Jacob sus derechos de ...   \n",
       "5135                                                   Anunciaron el mensaje en Perge y bajaron a Atal√≠a.   \n",
       "4071  El rico replic√≥: ¬´No, padre Abrah√°n, solo si alguno de los que han muerto va a hablarles, se con...   \n",
       "3922  Presten mucha atenci√≥n, porque al que tenga algo, a√∫n se le dar√° m√°s; pero al que no tenga nada,...   \n",
       "742   Despu√©s de mucho tiempo, muri√≥ la mujer de Jud√°, la hija de S√∫a. Pasado el duelo por ella, subi√≥...   \n",
       "\n",
       "                                                                                           arh_translated  \\\n",
       "748   Uye' n ângwari Jud√°ri: - \"¬øAzi minhaw ângwasiri n ânno?\" key ie'ri, ase'ri: - \"S âm ângwasiri m âk â z√≠...   \n",
       "1350  Israeri Jos√© ey keyri: - \"Iwa keyw â z ândi  ânwichana, anugwese' me'z ânnige'ri wicha awn ângwa ni g...   \n",
       "4309  Ey awi asige' bunsi  ânchare'ri, k ânk ân âse' pari rizwein rinuse'ri, Jesuri s âm â nase'ri winkinkum...   \n",
       "2499               …àw√≠ nen ân yow aniwicha uye' Niwipaw urak ân kortina k âp ânkwanari b âk ân√°ta  ânt âre're'ri,   \n",
       "33    1. michwi enanuy√°y win√≠kwuya (ga'kunamu abunna zukutuse anikw√°y kawi unchunungwasi, gakunamu abu...   \n",
       "1419  Ey uye' n ângwari Jakoburi eygwi keyw â key ie'ri: - \"Jakobu za'kinugwe Dunari, m√°, g âm âsin â um ân ...   \n",
       "5135                      Perge ayek âie'ri ga'k ânam â duna zak âwina'cho'si n ângwari Italia keyw â rizoyana.   \n",
       "4071  Uye' n ângwari nowmisin âse' eygwi key ie'ri: - \"…Ñnne'ki Abraandi,  âwe'ki  ânwicha aw ândi i'ngwi mi...   \n",
       "3922  …Ñweri ch√≥w z ân riwan âkwa naki. …Ñweri s âm â k ân ânase'ri eygwi kaw âka'sa ukum ândi ichukumari k âna'n...   \n",
       "742   Awi ing â birin  ânzanik ân nuse'ri, Jud√°ri Esa√∫ z â bu'g âm â Jud√°  ânwicha anuye'ri, ik ânha'ri k ânk ân...   \n",
       "\n",
       "                                                                                           esp_translated  \n",
       "748   Entonces Jud√° le dijo: - Deja que el muchacho venga bajo mi cuidado y pong√°monos inmediatamente ...  \n",
       "1350  El Se√±or le dijo: - Esc√∫chame, Israel: Yo soy el Se√±or que te sac√≥ de Ur de los caldeos para dar...  \n",
       "4309  Al d√≠a siguiente, de madrugada, cuando los disc√≠pulos regresaron a la ciudad, encontraron a Jes√∫...  \n",
       "2499                Jes√∫s le contest√≥: - Te aseguro que hoy estar√°s conmigo en el para√≠so.Muerte de Jes√∫s  \n",
       "33    estos mecanismos se llaman acciones y se pueden utilizar cuando exista una amenaza de violaci√≥n ...  \n",
       "1419  Entonces su padre le dijo: - ¬°Tengo hambre, hijo m√≠o! Ya hice lo que me pediste.Jacob le replic√≥...  \n",
       "5135                                                   donde pasaron a Perge y se embarcaron para Italia.  \n",
       "4071  En cambio, los ricos dicen: \"Ni siquiera me he servido, pero he ganado mi sustento porque espero...  \n",
       "3922  Les digo que, en el d√≠a del juicio, todo el que tiene, se salvar√°; pero al que no tiene, hasta l...  \n",
       "742   M√°s tarde, Jud√° se enter√≥ de que Siqu√©n hab√≠a violado a Dina, y que luego se quit√≥ el lugar dond...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776cf77-7387-40e4-8941-ab345fb844ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
