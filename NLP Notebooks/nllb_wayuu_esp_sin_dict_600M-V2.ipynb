{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a63d5-d164-435d-9190-b145cbe6f391",
   "metadata": {
    "id": "Gq9-Z9DSkT14"
   },
   "source": [
    "<p>In this notebook, we'll see how to fine-tune a NLLB-200 machine translation model for a new language.</p>\n",
    "<p><a href=\"https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865\">https://cointegrated.medium.com/how-to-fine-tune-a-nllb-200-model-for-translating-a-new-language-a37fc706b865</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e270c-dd08-4393-afc4-bf332e2cc906",
   "metadata": {
    "id": "_iBrOtwcjnml"
   },
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d14005-c2e2-42be-9d92-132542be16aa",
   "metadata": {
    "id": "dc8NcXYHj2Zj"
   },
   "source": [
    "Installing dependencies:\n",
    "* `transformers`, as a neural network framework\n",
    "* `sentencepiece`, a backend for my tokenizer (the algorithm for converting a text into symbols from the model's vocabulary)\n",
    "* `sacremoses`, a package required for text preprocessing with which NLLB models were pretrained.\n",
    "* `sacrebleu`, a package for evaluating translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf5dd-3482-4d52-a1ec-5440c6ae444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_CORE=1\n",
    "MODEL_USED=\"facebook/nllb-200-distilled-600M\"\n",
    "# MODEL_USED=\"facebook/nllb-200-1.3B\"\n",
    "# MODEL_USED=\"facebook/nllb-200-3.3B\"\n",
    "MODEL_SAVE_PATH=\"models/nllb_wayuu_esp_sin_dict_600M-V2\"\n",
    "LANGUAGE_ORIGIN_LABEL=\"spa_Latn\"\n",
    "LANGUAGE_TARGET_LABEL=\"way_Latn\"\n",
    "LANGUAGE_SIMILAR_LABEL=\"ayr_Latn\" # Central Aymara\n",
    "LANGUAGE_FILE=\"data/wayuu_completo_sin_dic_v2.csv\"\n",
    "LANGUAGE_FILE_ORIGIN_LABEL=\"esp\"\n",
    "LANGUAGE_FILE_TARGET_LABEL=\"way\"\n",
    "NORMALIZER_LANGUAGE=\"es\"\n",
    "!mkdir -p {MODEL_SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11254f-a905-4a83-98d7-6f8d94748b78",
   "metadata": {
    "id": "qPjx54id5ko8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def gpe(x=None):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deef406-a250-43ff-83db-4697e3f6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu8BrYo292Nx",
    "outputId": "02bb6baa-0519-4560-d32b-e8bcdac6f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers==4.33 datasets sacremoses sacrebleu  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b412eb-8989-4b41-b88c-9ee499dd4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/americasnlp/uniandes/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (8.8.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipywidgets) (5.8.1)\n",
      "Requirement already satisfied: decorator in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: stack-data in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/americasnlp/uniandes/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: six in /home/americasnlp/uniandes/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0474a121-1f7b-425e-947d-35c0ee600921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/americasnlp/uniandes/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/americasnlp/uniandes/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d424-7e0f-4c9b-aa80-253727fe4350",
   "metadata": {
    "id": "OqdSSIVLlCir"
   },
   "source": [
    "<h1 id=\"1.-Exploring-the-data\">1. Exploring the data</h1>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad67ea-a94b-4bf2-bea1-c023ac42965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7635, 2)\n",
      "Index(['way', 'esp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trans_df = pd.read_csv(LANGUAGE_FILE)\n",
    "print(trans_df.shape)\n",
    "print(trans_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9651d838-3458-46b0-9069-6ce1c3928925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_devtest = train_test_split(trans_df, test_size=0.2, random_state=42)\n",
    "df_dev, df_test = train_test_split(df_devtest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c57493-f931-4993-a8a4-07ab2e16ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6108 entries, 216 to 7270\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     6108 non-null   object\n",
      " 1   esp     6108 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 143.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4745ce8-fa3f-452b-8368-ddff64c31644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Antüsü wanee palajana, antüsü wanee mapan.</td>\n",
       "      <td>Llegó primero una, llegó otra después.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>Nüsouktakalaka Jesús nümüin:—Tamüsü paala pümü...</td>\n",
       "      <td>Jesús le contestó:—El que me ama de verdad se ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>Anainja tojuittüle yaajee tale'ejaiwa nünainmü...</td>\n",
       "      <td>Volveré a mi padre y le diré: Padre, he pecado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>¿Eesü asalaa cha ꞌaya suluꞌu  aikaaleekalü?</td>\n",
       "      <td>¿Hay carne allá en la tienda?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Aa, antajachi taya si'iralüin müshia ekirajaai...</td>\n",
       "      <td>Si, el profesor me dijo que viniera en guayuco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "216          Antüsü wanee palajana, antüsü wanee mapan.   \n",
       "4383  Nüsouktakalaka Jesús nümüin:—Tamüsü paala pümü...   \n",
       "5163  Anainja tojuittüle yaajee tale'ejaiwa nünainmü...   \n",
       "421         ¿Eesü asalaa cha ꞌaya suluꞌu  aikaaleekalü?   \n",
       "505   Aa, antajachi taya si'iralüin müshia ekirajaai...   \n",
       "\n",
       "                                                    esp  \n",
       "216              Llegó primero una, llegó otra después.  \n",
       "4383  Jesús le contestó:—El que me ama de verdad se ...  \n",
       "5163  Volveré a mi padre y le diré: Padre, he pecado...  \n",
       "421                       ¿Hay carne allá en la tienda?  \n",
       "505   Si, el profesor me dijo que viniera en guayuco...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eff1d2-b1d7-4239-8dc8-7de8ec53ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 763 entries, 5981 to 5799\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     763 non-null    object\n",
      " 1   esp     763 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97440c68-2cc8-4ed2-8013-b6ab431b7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>Sükajee tüü, shii'iyatüin tamüin tojut süpülap...</td>\n",
       "      <td>Ha hecho lo que estaba en su mano preparando p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>Nükumajüin shia Maleiwakai süpüla süchajaainja...</td>\n",
       "      <td>Y esto para ver si, aunque fuese a tientas, pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>Ni'rapa Jesús tü wayuu wattakat saalin nü'ütpa...</td>\n",
       "      <td>Viendo Jesús que lo rodeaba una gran multitud,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>¿Kasa paa Ꞌinraka?</td>\n",
       "      <td>¿Qué haces?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>Je ni'rataalain naa'in wane wayuu kanüliashi A...</td>\n",
       "      <td>y acaba de tener una visión en la que un hombr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "5981  Sükajee tüü, shii'iyatüin tamüin tojut süpülap...   \n",
       "3491  Nükumajüin shia Maleiwakai süpüla süchajaainja...   \n",
       "6276  Ni'rapa Jesús tü wayuu wattakat saalin nü'ütpa...   \n",
       "265                                  ¿Kasa paa Ꞌinraka?   \n",
       "3210  Je ni'rataalain naa'in wane wayuu kanüliashi A...   \n",
       "\n",
       "                                                    esp  \n",
       "5981  Ha hecho lo que estaba en su mano preparando p...  \n",
       "3491  Y esto para ver si, aunque fuese a tientas, pu...  \n",
       "6276  Viendo Jesús que lo rodeaba una gran multitud,...  \n",
       "265                                         ¿Qué haces?  \n",
       "3210  y acaba de tener una visión en la que un hombr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65795e88-acd2-4322-9bd5-b2fc91c53620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 764 entries, 4233 to 682\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   way     764 non-null    object\n",
      " 1   esp     764 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fde708-161f-4ef5-ad47-afa44ef70dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>Wanaa sümaa naapinnüin nüchiki Lázaro sünain a...</td>\n",
       "      <td>Jesús tenía una gran amistad con Marta, con su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>“Je jalia pia suulia kaainjalaa sükajee tü kas...</td>\n",
       "      <td>Y si tu pie va a ser causa de que caigas en pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>eeinjanale kepiain naya wane'ere'eya ouktapa H...</td>\n",
       "      <td>donde permaneció hasta la muerte de Herodes. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>Joutaa mama anterru joluu</td>\n",
       "      <td>Y también viene tu mamá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>Süka jamüin, tü taküjakat, nnojotsü tale'eru'u...</td>\n",
       "      <td>Porque yo no hablo por mi cuenta; el Padre, qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    way  \\\n",
       "4233  Wanaa sümaa naapinnüin nüchiki Lázaro sünain a...   \n",
       "5827  “Je jalia pia suulia kaainjalaa sükajee tü kas...   \n",
       "6131  eeinjanale kepiain naya wane'ere'eya ouktapa H...   \n",
       "7628                          Joutaa mama anterru joluu   \n",
       "4325  Süka jamüin, tü taküjakat, nnojotsü tale'eru'u...   \n",
       "\n",
       "                                                    esp  \n",
       "4233  Jesús tenía una gran amistad con Marta, con su...  \n",
       "5827  Y si tu pie va a ser causa de que caigas en pe...  \n",
       "6131  donde permaneció hasta la muerte de Herodes. A...  \n",
       "7628                            Y también viene tu mamá  \n",
       "4325  Porque yo no hablo por mi cuenta; el Padre, qu...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270ce-71be-4901-9a95-4406452dba9a",
   "metadata": {
    "id": "K6qHP-DAA4YD"
   },
   "source": [
    "# 2. How well does the data fit into a NLLB tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fdcc16-3398-4927-b4cd-cceec432502c",
   "metadata": {
    "id": "2xL261VQtyLl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import NllbTokenizer\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a96b1c-95f1-4fa5-9960-678d04b2f901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "82f5b5dde8e741968a33318c9fb35aa9",
      "f706db6e100543f09d56943531e9aa0b",
      "62971e310efa4ad780bc7a5a739f5cc0",
      "3da289db147943f690100c529f6b32d5",
      "fea5bb4bddf043f99dbbfbe0796d6430",
      "bfd2e276f5654949982184eb4b61e433",
      "785e2b6a4d9c4d11ab6e1fe6be734b2c",
      "61afbcd7511044a88a4e8e571a86e707",
      "3f598aa696604858a8e3a436aba2988c",
      "f0f7994cbfd940c082ecc0e3f4961f91",
      "fbc82ebca77440f78706eb4cb24df053",
      "4e00115e51e44d6cae397afb3c889993",
      "c9cfe103bd89419cb707e26d3b4dbeb6",
      "edc128d0b6fd477ba3ea070b4b28ab8b",
      "ec9aea35b5684de98e766acdfdff10c2",
      "fdfbbae83fa14f96ab586740a49d0870",
      "bc9d3f4b659d429c985b5d4d9e613a7f",
      "48cb15c9cca74ecea327a5a7e82e76f8",
      "1cf8a2530dc74318b78a417c321d0b5e",
      "fbc4f09f6a8441519ad827e21bdc315d",
      "fd4ebd7447d9407d9cc97bd65bd205a5",
      "37f6e8b92aea431c8fbc0d8faef41739",
      "adcae1e797d242f69664c60b67452828",
      "8b385f2f8f004dda9dfc4cabf7347349",
      "ed2bd8ccf06647a4bec0b1875fda7c77",
      "7f78abdca57f45198d67ece411e347fa",
      "1931cceb216f4aa5bdcde9eb9ea8e8bd",
      "f7cfa0bd58cf4fb08e4ea70f7980512f",
      "08b06e095ec940c9b74ad158e35fab54",
      "f711cdac308d4204b09b30744c664657",
      "a465f8e95487498088dac987b005b0be",
      "c994501b1a2049ec8061703187a7ccc5",
      "6f1dce72a1d9458d911394baac1261d5"
     ]
    },
    "id": "05GfWpzKtvcz",
    "outputId": "f5ee2a8b-200e-4553-8fea-f785674d93a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6054e9d4-92fb-49b8-bd5a-56775fac9a97",
   "metadata": {
    "id": "NQywlyv7t9VH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_tokenize(text):\n",
    "    # a very naive word tokenizer for languages with English-like orthography\n",
    "    return re.findall('(\\w+|[^\\w\\s])', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6489f62a-cd8a-47c4-9c2d-16ffaf2d27b5",
   "metadata": {
    "id": "QzD0htfzuAPu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "smpl = df_train.sample(10000, random_state=42, replace=True)\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_toks'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(tokenizer.tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_toks'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(tokenizer.tokenize)\n",
    "\n",
    "smpl[LANGUAGE_FILE_ORIGIN_LABEL + '_words'] = smpl[LANGUAGE_FILE_ORIGIN_LABEL].apply(word_tokenize)\n",
    "smpl[LANGUAGE_FILE_TARGET_LABEL + '_words'] = smpl[LANGUAGE_FILE_TARGET_LABEL].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8136a1-1518-4c01-beb6-8740f745f3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TrDHIgCwuHeN",
    "outputId": "93d2d173-0ce7-4848-806f-fc4bb02d48d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>way</th>\n",
       "      <th>way_words</th>\n",
       "      <th>way_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>Durante la estancia de Apolo en Corinto, Pablo...</td>\n",
       "      <td>[Durante, la, estancia, de, Apolo, en, Corinto...</td>\n",
       "      <td>[▁Durante, ▁la, ▁estancia, ▁de, ▁Apolo, ▁en, ▁...</td>\n",
       "      <td>Wanaa sümaa chain Apolos sulu'u Corinto, chash...</td>\n",
       "      <td>[Wanaa, sümaa, chain, Apolos, sulu, ', u, Cori...</td>\n",
       "      <td>[▁W, anaa, ▁sü, maa, ▁chain, ▁Apolos, ▁sulu, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Son tres los libros que debemos comprar para e...</td>\n",
       "      <td>[Son, tres, los, libros, que, debemos, comprar...</td>\n",
       "      <td>[▁Son, ▁tres, ▁los, ▁libros, ▁que, ▁debemos, ▁...</td>\n",
       "      <td>Apünüinsü tü karalo ’uta waya’lajüinjatükalü s...</td>\n",
       "      <td>[Apünüinsü, tü, karalo, ’, uta, waya, ’, lajüi...</td>\n",
       "      <td>[▁Ap, ünü, ins, ü, ▁tü, ▁kar, alo, ▁, ’, uta, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>Es esta, además, una dignidad que nadie puede ...</td>\n",
       "      <td>[Es, esta, ,, además, ,, una, dignidad, que, n...</td>\n",
       "      <td>[▁Es, ▁esta, ,, ▁además, ,, ▁una, ▁dign, idad,...</td>\n",
       "      <td>Chi laülaashikai napüleerua na sacerdote judío...</td>\n",
       "      <td>[Chi, laülaashikai, napüleerua, na, sacerdote,...</td>\n",
       "      <td>[▁Chi, ▁la, ü, la, ash, ikai, ▁nap, üle, er, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>Imagínense el caso de un hermano o una hermana...</td>\n",
       "      <td>[Imagínense, el, caso, de, un, hermano, o, una...</td>\n",
       "      <td>[▁Imag, ín, ense, ▁el, ▁caso, ▁de, ▁un, ▁herma...</td>\n",
       "      <td>¿Jameerü eera nukuaippa chira wayuukai nümüin ...</td>\n",
       "      <td>[¿, Jameerü, eera, nukuaippa, chira, wayuukai,...</td>\n",
       "      <td>[▁¿, J, ame, er, ü, ▁e, era, ▁nuk, ua, ip, pa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Está espesa la nube, va a caer un fuerte aguac...</td>\n",
       "      <td>[Está, espesa, la, nube, ,, va, a, caer, un, f...</td>\n",
       "      <td>[▁Está, ▁esp, esa, ▁la, ▁nu, be, ,, ▁va, ▁a, ▁...</td>\n",
       "      <td>Kojosü ma ’in sirumakalü joolu ’u, a’iteerü wa...</td>\n",
       "      <td>[Kojosü, ma, ’, in, sirumakalü, joolu, ’, u, ,...</td>\n",
       "      <td>[▁Ko, jos, ü, ▁ma, ▁, ’, in, ▁sir, um, akal, ü...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    esp  \\\n",
       "3523  Durante la estancia de Apolo en Corinto, Pablo...   \n",
       "975   Son tres los libros que debemos comprar para e...   \n",
       "2803  Es esta, además, una dignidad que nadie puede ...   \n",
       "7362  Imagínense el caso de un hermano o una hermana...   \n",
       "985   Está espesa la nube, va a caer un fuerte aguac...   \n",
       "\n",
       "                                              esp_words  \\\n",
       "3523  [Durante, la, estancia, de, Apolo, en, Corinto...   \n",
       "975   [Son, tres, los, libros, que, debemos, comprar...   \n",
       "2803  [Es, esta, ,, además, ,, una, dignidad, que, n...   \n",
       "7362  [Imagínense, el, caso, de, un, hermano, o, una...   \n",
       "985   [Está, espesa, la, nube, ,, va, a, caer, un, f...   \n",
       "\n",
       "                                               esp_toks  \\\n",
       "3523  [▁Durante, ▁la, ▁estancia, ▁de, ▁Apolo, ▁en, ▁...   \n",
       "975   [▁Son, ▁tres, ▁los, ▁libros, ▁que, ▁debemos, ▁...   \n",
       "2803  [▁Es, ▁esta, ,, ▁además, ,, ▁una, ▁dign, idad,...   \n",
       "7362  [▁Imag, ín, ense, ▁el, ▁caso, ▁de, ▁un, ▁herma...   \n",
       "985   [▁Está, ▁esp, esa, ▁la, ▁nu, be, ,, ▁va, ▁a, ▁...   \n",
       "\n",
       "                                                    way  \\\n",
       "3523  Wanaa sümaa chain Apolos sulu'u Corinto, chash...   \n",
       "975   Apünüinsü tü karalo ’uta waya’lajüinjatükalü s...   \n",
       "2803  Chi laülaashikai napüleerua na sacerdote judío...   \n",
       "7362  ¿Jameerü eera nukuaippa chira wayuukai nümüin ...   \n",
       "985   Kojosü ma ’in sirumakalü joolu ’u, a’iteerü wa...   \n",
       "\n",
       "                                              way_words  \\\n",
       "3523  [Wanaa, sümaa, chain, Apolos, sulu, ', u, Cori...   \n",
       "975   [Apünüinsü, tü, karalo, ’, uta, waya, ’, lajüi...   \n",
       "2803  [Chi, laülaashikai, napüleerua, na, sacerdote,...   \n",
       "7362  [¿, Jameerü, eera, nukuaippa, chira, wayuukai,...   \n",
       "985   [Kojosü, ma, ’, in, sirumakalü, joolu, ’, u, ,...   \n",
       "\n",
       "                                               way_toks  \n",
       "3523  [▁W, anaa, ▁sü, maa, ▁chain, ▁Apolos, ▁sulu, '...  \n",
       "975   [▁Ap, ünü, ins, ü, ▁tü, ▁kar, alo, ▁, ’, uta, ...  \n",
       "2803  [▁Chi, ▁la, ü, la, ash, ikai, ▁nap, üle, er, u...  \n",
       "7362  [▁¿, J, ame, er, ü, ▁e, era, ▁nuk, ua, ip, pa,...  \n",
       "985   [▁Ko, jos, ü, ▁ma, ▁, ’, in, ▁sir, um, akal, ü...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl.sample(5)[[LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_toks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc14ed5-88d6-41e9-a455-5d21864ce6cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "EbgRYDlTuC9z",
    "outputId": "9cb7aa33-4874-4e04-9687-89a5b4748c49",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_326004/105503015.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esp_toks</th>\n",
       "      <th>way_toks</th>\n",
       "      <th>esp_words</th>\n",
       "      <th>way_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.243400</td>\n",
       "      <td>72.408600</td>\n",
       "      <td>25.910800</td>\n",
       "      <td>36.495100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47.974413</td>\n",
       "      <td>103.070418</td>\n",
       "      <td>38.361494</td>\n",
       "      <td>51.161899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1390.000000</td>\n",
       "      <td>3173.000000</td>\n",
       "      <td>1149.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           esp_toks      way_toks     esp_words     way_words\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean      32.243400     72.408600     25.910800     36.495100\n",
       "std       47.974413    103.070418     38.361494     51.161899\n",
       "min        1.000000      1.000000      1.000000      1.000000\n",
       "25%       19.000000     39.000000     15.000000     20.000000\n",
       "50%       28.000000     65.000000     22.000000     33.000000\n",
       "75%       38.000000     89.000000     31.000000     45.000000\n",
       "max     1390.000000   3173.000000   1149.000000   1562.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = smpl[[LANGUAGE_FILE_ORIGIN_LABEL + '_toks', LANGUAGE_FILE_TARGET_LABEL + '_toks', LANGUAGE_FILE_ORIGIN_LABEL + '_words', LANGUAGE_FILE_TARGET_LABEL + '_words']].applymap(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752ed318-2232-45f6-8df2-71389512feee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUJQQzYDuEc5",
    "outputId": "f3f9a6e7-13fd-4b34-c762-5b4fbdb712ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2444000185250939\n",
      "1.9840636140194166\n"
     ]
    }
   ],
   "source": [
    "print(stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_ORIGIN_LABEL + \"_words\"]['mean'])\n",
    "print(stats[LANGUAGE_FILE_TARGET_LABEL + \"_toks\"]['mean'] / stats[LANGUAGE_FILE_TARGET_LABEL + \"_words\"]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054b068f-1948-4c66-8534-2e3c93f32e65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUXEaJlbuqJf",
    "outputId": "1262d9fd-f24a-4f3f-e8f2-dcfa2631703c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> 3\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.unk_token, tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b39a1-706d-4819-818c-14fbb7097d0d",
   "metadata": {
    "id": "27BIJ7HGvKs-"
   },
   "source": [
    "<p>One more check: how often does the token happen in the tokenizer output for quechua? If this is too often, we need to fix it somehow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f50508-b8ce-490f-ad65-2e8e6f878831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "72f5f3c369fd4f41ab100dcb6eedf9a1",
      "393fcfbd5db1453482e1ee15f1b8a6fe",
      "b4227e885a554b12a74f04856fea4334",
      "68cdca0e23494ba189ba3f068c67f78f",
      "cc675ce0a2c647bfb7edd6212bb3b77d",
      "b116254ca9584ef7bfb60dda9fc33c67",
      "4ce4e1969c844363a77758d472817b0e",
      "c8b5432bc4f04c6ba5153e32c0b92c6e",
      "53e9effbd74845d3933a296a547cd7e5",
      "8a7cfe54b0924f65967e65346dab3780",
      "9bc3474a77c64e7f82ba567d4ca97dab"
     ]
    },
    "id": "nAEe9lYNu6kv",
    "outputId": "ba9cb88c-a8e8-41e9-857c-89e363fb95ae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6037f41cc8694dc2a67a15fee4e37aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2806\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk = [text for text in tqdm(trans_df[LANGUAGE_FILE_TARGET_LABEL]) if tokenizer.unk_token_id in tokenizer(text).input_ids]\n",
    "print(len(texts_with_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1051da0-3e8f-4959-bc88-9539da859c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Je Pedro, wainma nünüikü namüin shii'iree naapaweein nümüin tü nümakat namüin. Müshi joo nia namüin:—Jiyu'laa suulia tü akuaippaa noo'ulakakat na wayuu kaainjaraliikana, suulia süsalajüin jia wanaa namaa.\",\n",
       " \"Narütkajaakalaka naya sümaa neme'erainpalain nia wainmatua sünain maa nümüin:—Pia Aluwataashikai saa'u tü wayuu judíokolüirua —müshii naya nümüin.Je nashe'ejakalaka nia sünain nu'upünaa.\",\n",
       " \"Nümakalaka joo namüin napüshua na nikirajüinkana: “Tamüsü jümüin tüü süma'inru'u yaayülin taya jümaa.\",\n",
       " \"“Jiakana kaainjaraliikana, ju'una yaajee toulia. Nnojoliishii jia te'raajüin. Nnojoishii tatüjaain aa'u jaleje'ewaliin jia”, meechi nia namüin.\",\n",
       " \"Je wane ashajuushikalia sünain maa:“Jiakana gentilekana jüpüshua,anakaja ju'waajüle chi Maleiwakai süka süpüshua jaa'in”.\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "s = random.sample(texts_with_unk, 5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b10e15-f64b-4ece-aba7-1d0b59f32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "\n",
    "mpn = MosesPunctNormalizer(lang=NORMALIZER_LANGUAGE)\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace 𝓕𝔯𝔞𝔫𝔠𝔢𝔰𝔠𝔞 by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35e3d20-2fc4-49ed-a1bc-0a45e78787c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b336f91760014012a1d1ee30d22e65d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2806 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "texts_with_unk_normed = [text for text in tqdm(texts_with_unk) if tokenizer.unk_token_id in tokenizer(preproc(text)).input_ids]\n",
    "print(len(texts_with_unk_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4f4e-e9df-44ef-8fd3-08dd2a163c37",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"3.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">3. Expanding the vocabulary</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "511a5896-6566-4b03-a068-7d5c693c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49e207d3e5249ed8f0d00f43b04a8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_texts = trans_df[LANGUAGE_FILE_TARGET_LABEL]\n",
    "all_text_normalized = [preproc(t) for t in tqdm(all_texts)]\n",
    "chars_cnt = Counter(c for t in all_text_normalized for c in t)\n",
    "required_chars = ''.join([\n",
    "    k for k, v in chars_cnt.most_common() \n",
    "    if v >= 3 and k not in ' '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b6a65a-7d54-482e-a5bc-364f8304a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_file = MODEL_SAVE_PATH + \"/all_texts_file.csv\"\n",
    "trans_df[LANGUAGE_FILE_TARGET_LABEL].to_csv(all_texts_file, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd32fcd4-2794-48fc-b4ac-056a838eb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: models/nllb_wayuu_esp_sin_dict_600M-V2/all_texts_file.csv\n",
      "  input_format: \n",
      "  model_prefix: models/nllb_wayuu_esp_sin_dict_600M-V2/spm_16k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2048\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 16768\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 128\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: ainüestkulj'mohpwryc.,JMNASú-\":OdTPC¿?EíWbéKgáIf23ó14LBGD5vYzFꞋꞌH70Rq6[]89Z¡!;)ñÉ(UxØVÜ/_\n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 2\n",
      "  bos_id: -1\n",
      "  eos_id: 1\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 0\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: models/nllb_wayuu_esp_sin_dict_600M-V2/all_texts_file.csv\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 7635 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=1437326\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=105\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 7635 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=927992\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 43311 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 7635\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 27060\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 27060 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=15090 obj=14.3611 num_tokens=72167 num_tokens/piece=4.78244\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12482 obj=11.107 num_tokens=72613 num_tokens/piece=5.81742\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9353 obj=11.0782 num_tokens=74947 num_tokens/piece=8.01315\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9319 obj=11.0264 num_tokens=74999 num_tokens/piece=8.04797\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=6988 obj=11.1552 num_tokens=79186 num_tokens/piece=11.3317\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=6986 obj=11.1129 num_tokens=79223 num_tokens/piece=11.3403\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5239 obj=11.3145 num_tokens=84191 num_tokens/piece=16.0701\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5239 obj=11.2641 num_tokens=84189 num_tokens/piece=16.0697\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3929 obj=11.5211 num_tokens=89641 num_tokens/piece=22.8152\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3929 obj=11.4635 num_tokens=89651 num_tokens/piece=22.8178\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2946 obj=11.7742 num_tokens=95778 num_tokens/piece=32.5112\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2946 obj=11.7078 num_tokens=95775 num_tokens/piece=32.5102\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2252 obj=12.0386 num_tokens=101850 num_tokens/piece=45.2265\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2252 obj=11.9674 num_tokens=101853 num_tokens/piece=45.2278\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: models/nllb_wayuu_esp_sin_dict_600M-V2/spm_16k.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: models/nllb_wayuu_esp_sin_dict_600M-V2/spm_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "SPM_PREFIX = MODEL_SAVE_PATH + '/spm_16k'\n",
    "with open(all_texts_file, 'w') as f:\n",
    "    for i, text in enumerate(all_texts):\n",
    "        print(text, file=f)\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=all_texts_file,\n",
    "    model_prefix=SPM_PREFIX,\n",
    "    vocab_size=2**11,  # 16K\n",
    "    character_coverage = 1,\n",
    "    num_threads=16,\n",
    "    train_extremely_large_corpus=False,\n",
    "    add_dummy_prefix=False,\n",
    "    max_sentencepiece_length=128,\n",
    "    max_sentence_length=4192*4,\n",
    "    pad_id=0,\n",
    "    eos_id=1,\n",
    "    unk_id=2,\n",
    "    bos_id=-1,\n",
    "    required_chars=required_chars,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1a7295-1315-46bb-8a92-b86cedac176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.19.4 in /home/americasnlp/uniandes/lib/python3.10/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d549217f-7f9d-42a2-adf4-285736e68461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-16 18:57:25--  https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4082 (4.0K) [text/plain]\n",
      "Saving to: ‘/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py’\n",
      "\n",
      "/home/americasnlp/u 100%[===================>]   3.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-16 18:57:25 (51.9 MB/s) - ‘/home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py’ saved [4082/4082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/protocolbuffers/protobuf/main/python/google/protobuf/internal/builder.py -O /home/americasnlp/uniandes/lib/python3.10/site-packages/google/protobuf/internal/builder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d6757a-3b7d-4c88-80c9-631b82652508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\n",
    "# At this step, the code may throw an error about protobuf. Do as it tells.\n",
    "from transformers import NllbTokenizer\n",
    "\n",
    "# reading the NLLB and the Tyvan sentencepiece models into a native format\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "sp_trained = spm.SentencePieceProcessor(model_file=f'{SPM_PREFIX}.model')\n",
    "added_spm = sp_pb2_model.ModelProto()\n",
    "added_spm.ParseFromString(sp_trained.serialized_model_proto())\n",
    "old_spm = sp_pb2_model.ModelProto()\n",
    "old_spm.ParseFromString(tokenizer.sp_model.serialized_model_proto())\n",
    "\n",
    "# adding the missing tokens to the NLLB sentencepiece model\n",
    "nllb_tokens_set = {p.piece for p in old_spm.pieces}\n",
    "prev_min_score = old_spm.pieces[-1].score\n",
    "for p in added_spm.pieces:\n",
    "    piece = p.piece\n",
    "    if piece not in nllb_tokens_set:\n",
    "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
    "        new_p.piece = piece\n",
    "        # for all new tokens, I'll set a lower score (priority)\n",
    "        new_p.score = p.score + prev_min_score\n",
    "        old_spm.pieces.append(new_p)\n",
    "\n",
    "# saving the result to disk\n",
    "NEW_SPM_NAME = MODEL_SAVE_PATH + '/spm_nllb_268k.model'\n",
    "with open(NEW_SPM_NAME, 'wb') as f:\n",
    "    f.write(old_spm.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4720efa3-81b5-4383-bbca-3f8f24a7d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256204 257724\n",
      "1519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 18:57:28.950298: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-16 18:57:29.107567: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-16 18:57:29.754091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-16 18:57:29.754149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-16 18:57:29.754154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 257724. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031caaeb8e0243bba26b9b3627540d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model_name = MODEL_USED\n",
    "\n",
    "# loading the tokenizers\n",
    "tokenizer_old = NllbTokenizer.from_pretrained(model_name)\n",
    "tokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file=NEW_SPM_NAME)\n",
    "print(len(tokenizer_old), len(tokenizer)) # 256204, 268559\n",
    "added_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_old.get_vocab()))\n",
    "print(len(added_vocab))  # 12355\n",
    "\n",
    "# loading and resizing the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# re-initializing the new embeddings\n",
    "for t in tqdm(added_vocab):\n",
    "    tt = tokenizer_old(t, add_special_tokens=False).input_ids\n",
    "    if len(tt) == 0:\n",
    "        tt = [tokenizer_old.unk_token_id]\n",
    "    idx = tokenizer.convert_tokens_to_ids(t)\n",
    "    model.model.shared.weight.data[idx] = model.model.shared.weight.data[tt].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e99a8-23e8-4b76-9f19-20317549985a",
   "metadata": {
    "id": "4hUhun80t5u9"
   },
   "source": [
    "<h1 id=\"4.-Adding-a-new-language-tag-to-the-tokenizer-and-model\">4. Adding a new language tag to the tokenizer and model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d246b9-c5b6-49ce-ba84-7460b3c55d9f",
   "metadata": {
    "id": "MhG4XWTP-g3w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import NllbTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762b6b50-4930-4973-8260-43c9668856c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257724\n",
      "['zul_Latn', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256203 + len(added_vocab) + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf439b8-1973-44e0-9493-244a18db0ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "7dd3365e006b453ca8fb8038e094555f",
      "65e9e61d0ed840ea99a697d92a2f84ed",
      "646b8db350624cff9cf98eeb99961eb0",
      "49042aac01e04d8b8ff687e7b3c65b50",
      "ef999d653d4c483da60affcb1c6436ce",
      "62200bb6090c4a559528c7d3634bf90f",
      "769a977aac144aee8a3a47f9555c74ff",
      "e92c4a40fb6446269715dcdad505840d",
      "9b9c762d29c1455d8a7a60471aac2768",
      "32a485a7ca9a4275861005ae43454f9c",
      "0fd340e45bc34a53ba447624a76f0ed8",
      "6d4ee6cf3eaf4000b818f7072ea977c2",
      "ce921fb96b494cac85032bcc268c06fe",
      "938bc56bc8e9463bb16a06451ae2e691",
      "7d3ee05a15df469c97c5405d77a96830",
      "f02efba55d154185acf4fed348c71e95",
      "517858e90b42466fb6a99cb203de3f82",
      "500ecd64fac7447da496601765a8b26f",
      "463dbd70326b433da342abb8a59a2f91",
      "fac5197c23204eb3a675c90f0181c70b",
      "63f837f0a30d40efb3495c24226b169f",
      "2a76969cc60643969569022a01a16205",
      "067d564db79a4db598e332299d63d343",
      "452e57ac9b844e97bbf8c5dc089786a8",
      "6416a6afe1164c8e9ca599532e8ea0a5",
      "73b8f217e8fe49a4912b5b1fdff576c5",
      "da272694ea8545b88488c001015ae33c",
      "45b4c2a49c3040fc813cf4a4e698ff7b",
      "ecf96c3403ac4b5b82f3f5dbe7105d50",
      "22cbd1147e914fd3af739378cdc50346",
      "23360f5724a541be9389160fe937bdae",
      "c51b0c36ad2740ecb87bb6b66e722048",
      "1bfec763db9b4eebbb5366215d0fe1a9"
     ]
    },
    "id": "GGh6UDG_-m1K",
    "outputId": "c998f43a-d42f-4b14-9788-4f6a5051ac9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = NllbTokenizer.from_pretrained(MODEL_USED)\n",
    "# print(len(tokenizer))\n",
    "# print(tokenizer.convert_ids_to_tokens([256202, 256203]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bcdb456-e0c0-4801-b2c3-cca71cc2c16d",
   "metadata": {
    "id": "d02fbR_L-nCh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\"\n",
    "    Add a new language token to the tokenizer vocabulary\n",
    "    (this should be done each time after its initialization)\n",
    "    \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b89f5f-cf1e-4778-8ae5-b3152528c3c3",
   "metadata": {
    "id": "jZ7YPnHQ-pDT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eccedb2f-fe03-451d-8ac0-9170aa2546bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppwnJUrj-rLu",
    "outputId": "0a4b124d-ef54-43ee-9dd7-6f203528507d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zul_Latn', 'way_Latn', '<mask>']\n",
      "[257722, 257723, 257724]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens([256202 + len(added_vocab) + 1, 256202 + len(added_vocab) + 2, 256202 + len(added_vocab) + 3])) # ['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>']\n",
    "print(tokenizer.convert_tokens_to_ids(['zul_Latn', LANGUAGE_TARGET_LABEL, '<mask>'])) # [256202, 256203, 256204]\n",
    "# this is consistent now, wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64650d20-39d9-4859-bd44-2bf0896b11df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktO8outV-xws",
    "outputId": "fda969b7-79ed-418c-8438-030fc1f7f4ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257723 257538\n"
     ]
    }
   ],
   "source": [
    "added_token_id = tokenizer.convert_tokens_to_ids(LANGUAGE_TARGET_LABEL)\n",
    "similar_lang_id = tokenizer.convert_tokens_to_ids(LANGUAGE_SIMILAR_LABEL)\n",
    "print(added_token_id, similar_lang_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8efbead8-e230-46fb-8d1e-e6706842adbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "d5069307780248518fcc722b22d0ffe1",
      "8f86365e49de4298a743b8d5da5f5eb4",
      "b9c52e8bd7d749f9bfdab5587dfa0b5f",
      "1bf15b3642a6413492ec3d4c7ebad2d1",
      "ba287c7028e241f4a2063d5c029c88b1",
      "968aeab383274f11895f24b8ca28ac4b",
      "1de256b621f6467a9ccd672c8b3fd1c1",
      "36ea07dad20741c892075b1329b578c3",
      "d5a5909d972d44e2a8aec8f7584fc26c",
      "6d11a1b7530d41e48ebccbe969c8fa86",
      "6d409089ab774ac1ac17b7870f15a894",
      "d9c75eef392f4cf0a3feccb1fada61ea",
      "0584fea072c44dd0a64ab40548d47efc",
      "18066a7e0d0f49928c2c54623120897a",
      "51c90465f2094d21ab0f6666948a29f6",
      "0813dadc9eda4e6f99961eef949f8858",
      "c2d7053e4c7d4a9383d232713992a93d",
      "826762c92ca94b5e8c41e67903d20417",
      "7fcf360674514ae4bce92903e490d153",
      "c10df72d15624d59aa79105c9bfdbdb4",
      "867b6d7491b349f4bf0b94079c730e3b",
      "d727aef5add542978b18ef55f3cf9a2d",
      "c4fc30af7c884b848e46bf306c1ed70c",
      "25eb4a883e444cc5a9829d1958fd7e9f",
      "4cb9aa537dde4ec195d5f070f903c13e",
      "e5765a961e544f3996ff90085d581136",
      "e095bfa167e5487eb03b2329aa3be27a",
      "52eb2135ad5d4f34b356b79c05cae023",
      "7e7789a6a4c54f828c768f73adc4e15f",
      "56c6235d267349478ba4a535df541450",
      "7d734ebe0a764685abcfc64cb7d0f566",
      "fee1b206fd1d43f2a53fcf1aeb503796",
      "a4759162233542e7a2bb0ea6b9048af4"
     ]
    },
    "id": "tLlwR3_R-tDL",
    "outputId": "0d473070-fdb6-4bdb-cb0a-ea2dcf44341b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 257725. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(257725, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_USED)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25d67f8-a2d7-4574-8eb9-a6ac4ab75f3e",
   "metadata": {
    "id": "lV-fIcWZ-3WJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moving the embedding for \"mask\" to its new position\n",
    "model.model.shared.weight.data[added_token_id+1] = model.model.shared.weight.data[added_token_id]\n",
    "# initializing new language token with a token of a similar language\n",
    "model.model.shared.weight.data[added_token_id] = model.model.shared.weight.data[similar_lang_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff788-d8b9-47b5-953a-49c393cc4ca2",
   "metadata": {
    "id": "5ssJCguZ-3oH"
   },
   "source": [
    "<h1 id=\"5.-Preparing-the-training-loop\">5. Preparing the training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd5a4b9-c7ba-402a-ab67-c966484042d8",
   "metadata": {
    "id": "OjuuYbpG-7nS"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Try to free GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78a989f-4f28-468c-a30b-f8b68704929c",
   "metadata": {
    "id": "olSkAk2p-9IE"
   },
   "outputs": [],
   "source": [
    "model.cuda(CUDA_CORE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af026ad7-b8ca-4ef7-af89-972c4b07f319",
   "metadata": {
    "id": "ScoroAeY-_-J"
   },
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    scale_parameter=False,\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    "    clip_threshold=1.0,\n",
    "    weight_decay=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "293dd71f-3fd0-4d15-a093-54a641cd4eee",
   "metadata": {
    "id": "t9cxb-64_Bco"
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\n",
    "max_length = 128\n",
    "warmup_steps = 1000\n",
    "training_steps = 57000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb98bc73-1879-41a3-bbef-2f8c99ff9652",
   "metadata": {
    "id": "1tbPSr7w_Hnp"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6a3246-6197-410a-82bb-3d2ab2658604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H15rBohL_MaC",
    "outputId": "89ee09d3-655a-4038-b97e-059e13015e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Entonces Pilato, queriendo contentar a la gente, ordenó que pusieran en libertad Barrabás y les entregó Jesús para que lo azotaran y lo crucificaran. 40.Los soldados se burlan de Jesús'], [\"Otta Pilato, süka nücheküin süpüleerua talatüinjatüin saa'in tü wayuukolüirua nüka, nüjütirakalaka joo Barrabás nanainmüin. Naapakalaka joo Jesús sümüin tü nusurulaatsekalüirua süpüla na'yaajüinjachin nia je süpüla nakacherüinjachin nia sünain kuruusa süpüla ouktaa.Mee'erapalashi Jesús sütüma wane surulaalüirua\"], 'spa_Latn', 'way_Latn')\n"
     ]
    }
   ],
   "source": [
    "LANGS = [(LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_ORIGIN_LABEL), (LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_TARGET_LABEL)]\n",
    "\n",
    "def get_batch_pairs(batch_size, data=df_train):\n",
    "    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n",
    "    xx, yy = [], []\n",
    "    for _ in range(batch_size):\n",
    "        item = data.iloc[random.randint(0, len(data)-1)]\n",
    "        xx.append(preproc(item[l1]))\n",
    "        yy.append(preproc(item[l2]))\n",
    "    return xx, yy, long1, long2\n",
    "\n",
    "print(get_batch_pairs(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe2618-3e6d-4869-9386-82ff272f7c75",
   "metadata": {
    "id": "V1BV9mcZwmLd"
   },
   "source": [
    "<h1 id=\"6.-The-training-loop\">6. The training loop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1edb73d-9bb5-4677-afba-7f5bf7a78b47",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "a7333450367f4d9b889827ca684618ba",
      "f10c62ba1c0d4a8abb5e2ac9ebb1b597",
      "bafb9ac089624cbe856f7e915ff2e33d",
      "70c2984da31e41f997de57d4d7c296b9",
      "f72f5732980148f3bf389e0d55077a69",
      "2430c208c59843fb81ab33724c2a06ff",
      "96145ae9b0f34c4abda7087504780826",
      "129499bfe1db45f3b6423f37d5196086",
      "057d5ee247d54cc486cc9266e562f1db",
      "10100514800a434f94dab81dc7e8126a",
      "843ab819836c400eb482b07d03f02209"
     ]
    },
    "id": "ahPBT-vt_c91",
    "outputId": "d545fe57-3d5e-418b-a92b-3cd58c428db2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f601a92840a74144a59003e67ccd9ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.255059242248535\n",
      "1000 4.61769328045845\n",
      "2000 2.8730146052837373\n",
      "3000 2.3457804584503172\n",
      "4000 1.9728317807912827\n",
      "5000 1.6823082365393638\n",
      "6000 1.4245621168613434\n",
      "7000 1.2377933974862099\n",
      "8000 1.045287535905838\n",
      "9000 0.8794476415514946\n",
      "10000 0.775309324875474\n",
      "11000 0.6344234156012535\n",
      "12000 0.5328614629283548\n",
      "13000 0.4656534615010023\n",
      "14000 0.3903649977296591\n",
      "15000 0.3483893230445683\n",
      "16000 0.3035135961510241\n",
      "17000 0.25073584866151216\n",
      "18000 0.21891477028280495\n",
      "19000 0.19439567876420916\n",
      "20000 0.16932959357090294\n",
      "21000 0.15290739954262972\n",
      "22000 0.13933739214576782\n",
      "23000 0.11892595013976097\n",
      "24000 0.11356523384340107\n",
      "25000 0.1002511387001723\n",
      "26000 0.09569441391155124\n",
      "27000 0.08615608764067292\n",
      "28000 0.08097338685020804\n",
      "29000 0.07370407083164901\n",
      "30000 0.06852359419502319\n",
      "31000 0.06480708236712962\n",
      "32000 0.06032537794485688\n",
      "33000 0.05721849623415619\n",
      "34000 0.053384654835797844\n",
      "35000 0.05025979612534866\n",
      "36000 0.04752822524309158\n",
      "37000 0.045940724199637774\n",
      "38000 0.04240512696513906\n",
      "39000 0.042000435876660046\n",
      "40000 0.04005690508335829\n",
      "41000 0.038488139308523385\n",
      "42000 0.03722824318101629\n",
      "43000 0.03537199365766719\n",
      "44000 0.034507945755962284\n",
      "45000 0.03325547024328262\n",
      "46000 0.03169149064947851\n",
      "47000 0.03252903172653168\n",
      "48000 0.029840535779483618\n",
      "49000 0.029754073475021868\n",
      "50000 0.030393226491753012\n",
      "51000 0.027499863052740693\n",
      "52000 0.027379642392974347\n",
      "53000 0.027254220784874633\n",
      "54000 0.025998271595453842\n",
      "55000 0.026628762412350626\n",
      "56000 0.024098941810429098\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "x, y, loss = None, None, None\n",
    "cleanup()\n",
    "\n",
    "tq = trange(len(losses), training_steps)\n",
    "for i in tq:\n",
    "    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n",
    "    try:\n",
    "        tokenizer.src_lang = lang1\n",
    "        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        tokenizer.src_lang = lang2\n",
    "        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        loss = model(**x, labels=y.input_ids).loss\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        x, y, loss = None, None, None\n",
    "        cleanup()\n",
    "        print('error', max(len(s) for s in xx + yy), e)\n",
    "        continue\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np.mean(losses[-1000:]))\n",
    "\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        model.save_pretrained(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ccfde3-03f3-4682-ae57-371824d2160d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "xXXT9pcd_9Au",
    "outputId": "58658ffc-f3d0-4a85-8884-cdca6ba08e17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(losses).ewm(100).mean().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04278e77-e247-4857-b53c-b74137ffd3f9",
   "metadata": {
    "id": "6MGVf4Vc_fS4"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=16, b=1.5, max_input_length=1024, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        **kwargs\n",
    "    )\n",
    "    #print(inputs.input_ids.shape[1], result.shape[1])\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3983c093-94e0-4217-b8db-6ae8672c695a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69XqtpbAgjN",
    "outputId": "2b963659-10e1-4cfc-fe20-ef136aef75e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Simón y los que estaban con él fueron en su busca']\n",
      "[\"Otta müshia Simón je na eekana nümaa, o'unüshii naya sünain achajawaa nüchiki Jesús.\"]\n",
      "[\"Otta Simón namaa na nikirajüinkana, o'unüsü nachikua sünain nachajaain nüchiki.\"]\n"
     ]
    }
   ],
   "source": [
    "xx, yy, lang1, lang2 = get_batch_pairs(1, data=df_dev)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.eval()\n",
    "print(translate(xx[0], lang1, lang2, no_repeat_ngram_size=3, num_beams=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee73419-1719-42a0-9682-5122ce1fb8f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCZR50GxAiPJ",
    "outputId": "4815110a-b8eb-4bc5-9453-977cb14d146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.4G\n",
      "4.0K drwxrwxr-x  2 americasnlp americasnlp 4.0K Mar 16 19:06 .\n",
      "4.0K drwxrwxr-x 10 americasnlp americasnlp 4.0K Mar 16 18:57 ..\n",
      "1.5M -rw-rw-r--  1 americasnlp americasnlp 1.5M Mar 16 18:57 all_texts_file.csv\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  896 Mar 17 03:05 config.json\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  184 Mar 17 03:05 generation_config.json\n",
      "2.3G -rw-rw-r--  1 americasnlp americasnlp 2.3G Mar 17 03:05 pytorch_model.bin\n",
      "4.7M -rw-rw-r--  1 americasnlp americasnlp 4.7M Mar 17 03:05 sentencepiece.bpe.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp 3.5K Mar 17 03:05 special_tokens_map.json\n",
      "268K -rw-rw-r--  1 americasnlp americasnlp 267K Mar 16 18:57 spm_16k.model\n",
      " 40K -rw-rw-r--  1 americasnlp americasnlp  37K Mar 16 18:57 spm_16k.vocab\n",
      "4.7M -rw-rw-r--  1 americasnlp americasnlp 4.7M Mar 16 18:57 spm_nllb_268k.model\n",
      "4.0K -rw-rw-r--  1 americasnlp americasnlp  570 Mar 17 03:05 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -alsh $MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68b0b-5303-4947-86d5-5d88fafabfae",
   "metadata": {
    "id": "0qubmjZNAxJB"
   },
   "source": [
    "<h1 id=\"7.-Using-the-model\">7. Testing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "685d8a57-9aaa-482b-a968-db94f3e4acb0",
   "metadata": {
    "id": "PKGZ8zuN2mV6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc4aaa6c-c1c9-4da1-9779-b0f18385f9ec",
   "metadata": {
    "id": "Wwb6ck8P25ZQ"
   },
   "outputs": [],
   "source": [
    "def fix_tokenizer(tokenizer, new_lang=LANGUAGE_TARGET_LABEL):\n",
    "    \"\"\" Add a new language token to the tokenizer vocabulary (this should be done each time after its initialization) \"\"\"\n",
    "    old_len = len(tokenizer) - int(new_lang in tokenizer.added_tokens_encoder)\n",
    "    tokenizer.lang_code_to_id[new_lang] = old_len-1\n",
    "    tokenizer.id_to_lang_code[old_len-1] = new_lang\n",
    "    # always move \"mask\" to the last position\n",
    "    tokenizer.fairseq_tokens_to_ids[\"<mask>\"] = len(tokenizer.sp_model) + len(tokenizer.lang_code_to_id) + tokenizer.fairseq_offset\n",
    "\n",
    "    tokenizer.fairseq_tokens_to_ids.update(tokenizer.lang_code_to_id)\n",
    "    tokenizer.fairseq_ids_to_tokens = {v: k for k, v in tokenizer.fairseq_tokens_to_ids.items()}\n",
    "    if new_lang not in tokenizer._additional_special_tokens:\n",
    "        tokenizer._additional_special_tokens.append(new_lang)\n",
    "    # clear the added token encoder; otherwise a new token may end up there by mistake\n",
    "    tokenizer.added_tokens_encoder = {}\n",
    "    tokenizer.added_tokens_decoder = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9fad130-1eab-4627-b161-15d773f81d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uY7nUGsX3NOM",
    "outputId": "84976f43-9775-443d-ba5e-7da564be2ed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_PATH).cuda(CUDA_CORE)\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "fix_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2828eaad-44ae-4d13-95e6-cdf6ed86a69d",
   "metadata": {
    "id": "ZIsPI6YT3UG0"
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL, a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    result = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8c25b0-6490-4a8e-b791-1b046f601e35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJwLBH8M9XWW",
    "outputId": "8cd3007f-6b6e-4364-ca99-991efe0d719e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Anoojaajeerü ma'i taa'in tü jayeechi aika tapüla\"]\n"
     ]
    }
   ],
   "source": [
    "t = \"las canciones de amor me gustan mucho\"\n",
    "print(translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9660905-98e0-4a04-a7d1-9f2256422e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9JFXvBS9xY7",
    "outputId": "09a8e62c-d727-4f72-8915-bed8a0e4498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Anoojashi taya ma 'in jayeechi tapüla\"]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aa0b34b-7e7b-4061-9cd2-8e983eeb8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Miguel está contento con la torcida [que ya llevo]']\n"
     ]
    }
   ],
   "source": [
    "t = \"kuyakuyllawan takitam anchata kuyani\"\n",
    "print(translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d83e1733-0c1b-4092-b998-7fe3f9c8dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['para yo cavar con la cazan [que yo tengo por qué guardar dinero]']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL, do_sample=True, num_beams=1, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300f15b3-10d3-42c3-8439-6e0ecd0b8e0f",
   "metadata": {
    "id": "JoWvizFCRngQ"
   },
   "outputs": [],
   "source": [
    "def batched_translate(texts, batch_size=8, **kwargs):\n",
    "    \"\"\"Translate texts in batches of similar length\"\"\"\n",
    "    idxs, texts2 = zip(*sorted(enumerate(texts), key=lambda p: len(p[1]), reverse=True))\n",
    "    results = []\n",
    "    for i in trange(0, len(texts2), batch_size):\n",
    "        results.extend(translate(texts2[i: i+batch_size], **kwargs))\n",
    "    return [p for i, p in sorted(zip(idxs, results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "708afaea-325c-4f63-aaac-4c068a4fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_TARGET_LABEL\"], src_lang=LANGUAGE_TARGET_LABEL, tgt_lang=LANGUAGE_ORIGIN_LABEL)\n",
    "# df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = batched_translate(df_test[\"LANGUAGE_FILE_ORIGIN_LABEL\"], src_lang=LANGUAGE_ORIGIN_LABEL, tgt_lang=LANGUAGE_TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b73f63e-dcfc-46d6-ad77-5771cccba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d9b55a108041abb9dca99294876264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a5a2c24a16474792d6ea143363c5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'] = [translate(t, LANGUAGE_TARGET_LABEL, LANGUAGE_ORIGIN_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_TARGET_LABEL])]\n",
    "df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'] = [translate(t, LANGUAGE_ORIGIN_LABEL, LANGUAGE_TARGET_LABEL)[0] for t in tqdm(df_test[LANGUAGE_FILE_ORIGIN_LABEL])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae4cdf58-ad8e-4e5b-8dc7-6dbcdaa8734a",
   "metadata": {
    "id": "FMRSCWW732ya"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)  # this metric is called ChrF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "944a2954-3215-4d09-97cb-69f219144d9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NKKUyXZ4oXr",
    "outputId": "c3d0a0b6-9782-4aa1-e948-b35b06364ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 14.38 39.6/16.5/10.9/8.3 (BP = 0.922 ratio = 0.925 hyp_len = 18028 ref_len = 19488)\n",
      "chrF2++ = 31.01\n",
      "BLEU = 17.30 45.9/22.0/14.5/11.0 (BP = 0.864 ratio = 0.873 hyp_len = 18253 ref_len = 20913)\n",
      "chrF2++ = 41.26\n"
     ]
    }
   ],
   "source": [
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_ORIGIN_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_ORIGIN_LABEL].tolist()]))\n",
    "print(bleu_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))\n",
    "print(chrf_calc.corpus_score(df_test[LANGUAGE_FILE_TARGET_LABEL + '_translated'].tolist(), [df_test[LANGUAGE_FILE_TARGET_LABEL].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "610641bc-64c7-4efe-9517-7cb192ee3876",
   "metadata": {
    "id": "svplVgTB5_Xq"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "863694ba-75e7-47de-8702-86537d61c625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "i3bMbXUv5TsV",
    "outputId": "45dd9c76-35ec-45bf-b878-abfa8f5b53c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>way</th>\n",
       "      <th>esp</th>\n",
       "      <th>way_translated</th>\n",
       "      <th>esp_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Ojutuushi taya sa a'ujee mootokaa aliikama 'inka, eweetüsü  wanee p üliikü tapüleeru wa</td>\n",
       "      <td>Antes de ayer  me caí de la moto, se me atravesó un burro</td>\n",
       "      <td>Antapa'a ma'i ka'ikat, o ajatteetaashi taya soo'omüin wane püliikü,</td>\n",
       "      <td>Yo me escondí en un chinchorro con una mochila, hay un poco de lavar mi ropaje.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>Ananajüsü tü wayuukolüirua naa'u Jesús wanaa sümaa nükachennüin sünain kuruusa. Otta na sülaülak...</td>\n",
       "      <td>La gente estaba allí mirando, mientras las autoridades se burlaban de Jesús, diciendo:—Puesto qu...</td>\n",
       "      <td>Je tü wattakat saalin wayuu, o'ttüshii naya sünain neme'erainpalain nia. Nasakirakalaka sünain m...</td>\n",
       "      <td>Allí tomaron la palabra Jesús y le dijeron: - ¡Adivina quién te ha pegado! Porque algunos de los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>Anakaja müleka jükaaliijale na wayuu eekai püreesain, müinjana aka püreesakai jia wanaa namaa. J...</td>\n",
       "      <td>Tengan siempre presentes a los encarcelados como si ustedes mismos se encontraran presos junto c...</td>\n",
       "      <td>Anakaja müleka eere jaa'in na wayuu püreesashiikana, müinjana aka jia naa'in nayakana püreesashi...</td>\n",
       "      <td>Traten a los que están en la cárcel como a prisioneros, y a los que lloran, como a complicados.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>Nüsouktakalaka Jesús namüin:—Shiimüin sünain niainjachin Elías antüin palajana süpüla yapainjatü...</td>\n",
       "      <td>Jesús les contestó:—Es cierto que Elías ha de venir y ha de ponerlo todo en orden.</td>\n",
       "      <td>- Shiimüin sünain niain Elías antüin süpüla anakatüinjatüin kasa nüpüla - nümakalaka Jesús namüin.</td>\n",
       "      <td>Jesús contestó: - Vino a ser el heredero de la casa de Dios.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>Katünayaa müshii naya maa aka saa'in sütüna wuchii. Aippiruasüwai natüna wane'ewai nakua. Je ko'...</td>\n",
       "      <td>Cada uno de los cuatro seres vivientes tenía seis alas y eran todo ojos por fuera y por dentro. ...</td>\n",
       "      <td>Je na pienchishii kato'uchiikana, eesü wane'ewai sükua'ipa maa aka aippiru'upünaa. Pasanainsü na...</td>\n",
       "      <td>Fueron vestidos de púrpura y ceñidas sus cabezas, ceñidas sus cabezas y ceñidas sus dientes. Dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>Ja'itaina jia aapüin süchiki kasachiki sainküin mmakat süpüshua, nnojo jainkuuin aa'in sütüma. J...</td>\n",
       "      <td>Llegarán a oídos de ustedes noticias de guerras y rumores de conflictos bélicos. No se alarmen, ...</td>\n",
       "      <td>Ja'itaina jia aapüin süchiki kasachiki sainküin mmakat süpüshua, nnojo jainkuuin aa'in sütüma. J...</td>\n",
       "      <td>Cuando oigan noticias de guerras y rumores de conflictos bélicos, no se alarmen. Aunque todo eso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>“ ‘Shiimüin ma'i tü tamakat jümüin: Chi wayuu eekai koo'omüin nütüma tü aapünakat nümüin, aapüne...</td>\n",
       "      <td>«Es cierto —asintió el rey—, pero yo les digo que a todo el que tiene, se le dará más. En cambio...</td>\n",
       "      <td>Shiimüin sünain naa'inrüin waneepia tü nuluwataakat anain. Otta chi wayuu eekai kama'anüin nütüm...</td>\n",
       "      <td>Porque a todo el que tiene, aún se le dará más, y tendrá de sobra; pero al que no tiene, hasta l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Tayakaa, talatüsü taya süka jemetüin jümüin</td>\n",
       "      <td>Yo, me alegro que les haya gustado.</td>\n",
       "      <td>Talatashaatasü ma'in taa'in anapü'üin jia.</td>\n",
       "      <td>Yo estoy contenta de estar con ustedes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>Je nüntapa nünain, nümaashi nia Antioquíamüin, eejanale naya kettatüin wane juya natüma sünain o...</td>\n",
       "      <td>Cuando lo encontró, lo llevó consigo Antioquía. Y a lo largo de todo un año trabajaron los dos j...</td>\n",
       "      <td>Je nüntapa nünain, naapaain nia nipialu'umüin. Eeshi nia sünain wane juya'a ma'i sünain ekirajaa...</td>\n",
       "      <td>A su llegada, se encontraron en Antioquía donde condujeron a la iglesia y enseñaron con gran ayu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>Eirakaataalasü joo taa'in iipünaamüin. Te'rataalakalaka joo chi Anneetchonkai sha'watüin cha'aya...</td>\n",
       "      <td>Volví a mirar, y vi al Cordero de pie sobre el monte de Sion. Lo acompañaban los ciento cuarenta...</td>\n",
       "      <td>Naakatawalaja'a joo chi Anneetchonkai sünain joyotüin yaa saa'u tü uuchikat Sion. Je nümaa chi A...</td>\n",
       "      <td>Vi entonces cómo el Cordero seguía en el cielo, y vi debajo de la montaña de Sion, el Cordero. H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      way  \\\n",
       "676               Ojutuushi taya sa a'ujee mootokaa aliikama 'inka, eweetüsü  wanee p üliikü tapüleeru wa   \n",
       "5447  Ananajüsü tü wayuukolüirua naa'u Jesús wanaa sümaa nükachennüin sünain kuruusa. Otta na sülaülak...   \n",
       "2925  Anakaja müleka jükaaliijale na wayuu eekai püreesain, müinjana aka püreesakai jia wanaa namaa. J...   \n",
       "6565  Nüsouktakalaka Jesús namüin:—Shiimüin sünain niainjachin Elías antüin palajana süpüla yapainjatü...   \n",
       "1670  Katünayaa müshii naya maa aka saa'in sütüna wuchii. Aippiruasüwai natüna wane'ewai nakua. Je ko'...   \n",
       "6786  Ja'itaina jia aapüin süchiki kasachiki sainküin mmakat süpüshua, nnojo jainkuuin aa'in sütüma. J...   \n",
       "5277  “ ‘Shiimüin ma'i tü tamakat jümüin: Chi wayuu eekai koo'omüin nütüma tü aapünakat nümüin, aapüne...   \n",
       "472                                                           Tayakaa, talatüsü taya süka jemetüin jümüin   \n",
       "3309  Je nüntapa nünain, nümaashi nia Antioquíamüin, eejanale naya kettatüin wane juya natüma sünain o...   \n",
       "1790  Eirakaataalasü joo taa'in iipünaamüin. Te'rataalakalaka joo chi Anneetchonkai sha'watüin cha'aya...   \n",
       "\n",
       "                                                                                                      esp  \\\n",
       "676                                             Antes de ayer  me caí de la moto, se me atravesó un burro   \n",
       "5447  La gente estaba allí mirando, mientras las autoridades se burlaban de Jesús, diciendo:—Puesto qu...   \n",
       "2925  Tengan siempre presentes a los encarcelados como si ustedes mismos se encontraran presos junto c...   \n",
       "6565                   Jesús les contestó:—Es cierto que Elías ha de venir y ha de ponerlo todo en orden.   \n",
       "1670  Cada uno de los cuatro seres vivientes tenía seis alas y eran todo ojos por fuera y por dentro. ...   \n",
       "6786  Llegarán a oídos de ustedes noticias de guerras y rumores de conflictos bélicos. No se alarmen, ...   \n",
       "5277  «Es cierto —asintió el rey—, pero yo les digo que a todo el que tiene, se le dará más. En cambio...   \n",
       "472                                                                   Yo, me alegro que les haya gustado.   \n",
       "3309  Cuando lo encontró, lo llevó consigo Antioquía. Y a lo largo de todo un año trabajaron los dos j...   \n",
       "1790  Volví a mirar, y vi al Cordero de pie sobre el monte de Sion. Lo acompañaban los ciento cuarenta...   \n",
       "\n",
       "                                                                                           way_translated  \\\n",
       "676                                   Antapa'a ma'i ka'ikat, o ajatteetaashi taya soo'omüin wane püliikü,   \n",
       "5447  Je tü wattakat saalin wayuu, o'ttüshii naya sünain neme'erainpalain nia. Nasakirakalaka sünain m...   \n",
       "2925  Anakaja müleka eere jaa'in na wayuu püreesashiikana, müinjana aka jia naa'in nayakana püreesashi...   \n",
       "6565   - Shiimüin sünain niain Elías antüin süpüla anakatüinjatüin kasa nüpüla - nümakalaka Jesús namüin.   \n",
       "1670  Je na pienchishii kato'uchiikana, eesü wane'ewai sükua'ipa maa aka aippiru'upünaa. Pasanainsü na...   \n",
       "6786  Ja'itaina jia aapüin süchiki kasachiki sainküin mmakat süpüshua, nnojo jainkuuin aa'in sütüma. J...   \n",
       "5277  Shiimüin sünain naa'inrüin waneepia tü nuluwataakat anain. Otta chi wayuu eekai kama'anüin nütüm...   \n",
       "472                                                            Talatashaatasü ma'in taa'in anapü'üin jia.   \n",
       "3309  Je nüntapa nünain, naapaain nia nipialu'umüin. Eeshi nia sünain wane juya'a ma'i sünain ekirajaa...   \n",
       "1790  Naakatawalaja'a joo chi Anneetchonkai sünain joyotüin yaa saa'u tü uuchikat Sion. Je nümaa chi A...   \n",
       "\n",
       "                                                                                           esp_translated  \n",
       "676                       Yo me escondí en un chinchorro con una mochila, hay un poco de lavar mi ropaje.  \n",
       "5447  Allí tomaron la palabra Jesús y le dijeron: - ¡Adivina quién te ha pegado! Porque algunos de los...  \n",
       "2925      Traten a los que están en la cárcel como a prisioneros, y a los que lloran, como a complicados.  \n",
       "6565                                         Jesús contestó: - Vino a ser el heredero de la casa de Dios.  \n",
       "1670  Fueron vestidos de púrpura y ceñidas sus cabezas, ceñidas sus cabezas y ceñidas sus dientes. Dan...  \n",
       "6786  Cuando oigan noticias de guerras y rumores de conflictos bélicos, no se alarmen. Aunque todo eso...  \n",
       "5277  Porque a todo el que tiene, aún se le dará más, y tendrá de sobra; pero al que no tiene, hasta l...  \n",
       "472                                                                Yo estoy contenta de estar con ustedes  \n",
       "3309  A su llegada, se encontraron en Antioquía donde condujeron a la iglesia y enseñaron con gran ayu...  \n",
       "1790  Vi entonces cómo el Cordero seguía en el cielo, y vi debajo de la montaña de Sion, el Cordero. H...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10, random_state=42)[[LANGUAGE_FILE_TARGET_LABEL, LANGUAGE_FILE_ORIGIN_LABEL, LANGUAGE_FILE_TARGET_LABEL + '_translated', LANGUAGE_FILE_ORIGIN_LABEL + '_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710b76-1ba5-45f8-8cf7-22b33768938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776cf77-7387-40e4-8941-ab345fb844ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
